{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kapitola 32: Dropout - Jak zabranit preuceni neuronove site\n",
    "\n",
    "## Cile kapitoly\n",
    "- Pochopit problem preuceni (overfitting)\n",
    "- Naucit se pouzivat Dropout jako regularizacni techniku\n",
    "- Vizualizovat rozdil mezi modelem s a bez Dropoutu\n",
    "- Experimentovat s parametrem dropout rate\n",
    "\n",
    "## Predpoklady\n",
    "- PyTorch zaklady (kapitola 31)\n",
    "- Zpetna propagace a ucici krivka"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Co je preuceni (Overfitting)?\n",
    "\n",
    "Predstavte si studenta, ktery se uci na zkousku:\n",
    "\n",
    "- **Dobre uceni**: Student pochopi principy a dokaze resit i nove ulohy\n",
    "- **Preuceni**: Student se nauci odpovedi nazpamet, ale nerozumi principum\n",
    "\n",
    "### Preucena neuronova sit:\n",
    "- Ma **vysokou presnost na trenovacich datech** (viděl je mnohokrát)\n",
    "- Ma **nizkou presnost na novych datech** (nedokaze generalizovat)\n",
    "\n",
    "Je to jako kdyz si sit \"zapamatovala\" trenovaci data vcetne sumu, misto toho aby se naucila obecne vzory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instalace knihoven\n",
    "!pip install torch scikit-learn numpy matplotlib -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_moons\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "print(f\"PyTorch verze: {torch.__version__}\")\n",
    "print(\"Knihovny uspesne nacteny!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Co je Dropout?\n",
    "\n",
    "**Dropout** je regularizacni technika, ktera behem trenovani **nahodne vypina neurony**.\n",
    "\n",
    "### Analogie: Tym expertu\n",
    "\n",
    "Predstavte si tym 5 expertu:\n",
    "- Bez Dropoutu: Vsichni se spolehou na experta #3 (nejlepsi), ostatni zleniví\n",
    "- S Dropoutem: Expert #3 muze \"onemocnet\" -> ostatni se musi take naucit jeho praci\n",
    "\n",
    "**Vysledek**: Tym je robustnejsi a nespolcha na jednotlivce!\n",
    "\n",
    "### Jak to funguje?\n",
    "1. Behem **trenovani**: Nahodne vypneme `p%` neuronu v kazdem kroku\n",
    "2. Behem **testovani**: Pouzijeme vsechny neurony (Dropout je vypnuty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vizualizace Dropout\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Bez Dropoutu\n",
    "ax1 = axes[0]\n",
    "neurons_positions = [(0, 0), (0, 1), (0, 2), (1, 0), (1, 1), (1, 2), (2, 1)]\n",
    "for i, (x, y) in enumerate(neurons_positions):\n",
    "    circle = plt.Circle((x, y), 0.15, color='#3498db', ec='black', linewidth=2)\n",
    "    ax1.add_patch(circle)\n",
    "ax1.set_xlim(-0.5, 2.5)\n",
    "ax1.set_ylim(-0.5, 2.5)\n",
    "ax1.set_aspect('equal')\n",
    "ax1.axis('off')\n",
    "ax1.set_title('Bez Dropoutu - vsechny neurony aktivni', fontsize=14)\n",
    "\n",
    "# S Dropoutem\n",
    "ax2 = axes[1]\n",
    "dropout_mask = [True, False, True, True, False, True, True]  # False = vypnuty\n",
    "for i, ((x, y), active) in enumerate(zip(neurons_positions, dropout_mask)):\n",
    "    color = '#3498db' if active else '#e74c3c'\n",
    "    alpha = 1.0 if active else 0.3\n",
    "    circle = plt.Circle((x, y), 0.15, color=color, ec='black', linewidth=2, alpha=alpha)\n",
    "    ax2.add_patch(circle)\n",
    "    if not active:\n",
    "        ax2.plot([x-0.1, x+0.1], [y-0.1, y+0.1], 'r-', linewidth=3)\n",
    "        ax2.plot([x-0.1, x+0.1], [y+0.1, y-0.1], 'r-', linewidth=3)\n",
    "ax2.set_xlim(-0.5, 2.5)\n",
    "ax2.set_ylim(-0.5, 2.5)\n",
    "ax2.set_aspect('equal')\n",
    "ax2.axis('off')\n",
    "ax2.set_title('S Dropoutem (p=0.3) - nektere neurony vypnuty', fontsize=14)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Modre = aktivni neurony\")\n",
    "print(\"Cervene s X = vypnute neurony (dropout)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Priprava dat - Dataset \"Dva mesice\" s sumem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vytvoreni datasetu s vetsim sumem (zamerně obtiznejsi)\n",
    "X, y = make_moons(n_samples=500, noise=0.35, random_state=42)\n",
    "\n",
    "# Rozdeleni na trenovaci a testovaci data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Konverze na PyTorch tenzory\n",
    "X_train_t = torch.from_numpy(X_train).float()\n",
    "X_test_t = torch.from_numpy(X_test).float()\n",
    "y_train_t = torch.from_numpy(y_train).float().view(-1, 1)\n",
    "y_test_t = torch.from_numpy(y_test).float().view(-1, 1)\n",
    "\n",
    "# Vizualizace\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.scatter(X_train[:, 0], X_train[:, 1], c=y_train, cmap='coolwarm', edgecolors='black', alpha=0.7)\n",
    "plt.title(f'Trenovaci data ({len(X_train)} vzorku)', fontsize=14)\n",
    "plt.xlabel('X1')\n",
    "plt.ylabel('X2')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.scatter(X_test[:, 0], X_test[:, 1], c=y_test, cmap='coolwarm', edgecolors='black', alpha=0.7)\n",
    "plt.title(f'Testovaci data ({len(X_test)} vzorku)', fontsize=14)\n",
    "plt.xlabel('X1')\n",
    "plt.ylabel('X2')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Trenovaci data: {len(X_train)} vzorku\")\n",
    "print(f\"Testovaci data: {len(X_test)} vzorku\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Definice site - S dropoutem a bez\n",
    "\n",
    "Vytvorime **zamerne prilis velkou sit**, ktera bude mit tendenci se preucit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MoonNet(nn.Module):\n",
    "    \"\"\"Neuronova sit pro klasifikaci - s moznosti Dropoutu\"\"\"\n",
    "    \n",
    "    def __init__(self, use_dropout=False, dropout_rate=0.5):\n",
    "        super(MoonNet, self).__init__()\n",
    "        self.use_dropout = use_dropout\n",
    "        \n",
    "        # Zamerne prilis velka architektura (128 neuronu)\n",
    "        self.layer1 = nn.Linear(2, 128)\n",
    "        self.layer2 = nn.Linear(128, 128)\n",
    "        self.layer3 = nn.Linear(128, 1)\n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(p=dropout_rate)  # p = pravdepodobnost vypnuti\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Vrstva 1\n",
    "        x = self.relu(self.layer1(x))\n",
    "        if self.use_dropout:\n",
    "            x = self.dropout(x)  # Dropout po prvni vrstve\n",
    "        \n",
    "        # Vrstva 2\n",
    "        x = self.relu(self.layer2(x))\n",
    "        if self.use_dropout:\n",
    "            x = self.dropout(x)  # Dropout po druhe vrstve\n",
    "        \n",
    "        # Vystupni vrstva\n",
    "        x = self.sigmoid(self.layer3(x))\n",
    "        return x\n",
    "\n",
    "# Ukazka architektury\n",
    "model_example = MoonNet(use_dropout=True, dropout_rate=0.5)\n",
    "print(\"Architektura site:\")\n",
    "print(model_example)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Funkce pro trenovani a vyhodnoceni"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate(model, model_name, epochs=3000, verbose=True):\n",
    "    \"\"\"Trenuje model a vraci historii trenovani a testovani\"\"\"\n",
    "    \n",
    "    criterion = nn.BCELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "    \n",
    "    train_losses = []\n",
    "    test_losses = []\n",
    "    train_accs = []\n",
    "    test_accs = []\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        # ===== TRENOVANI =====\n",
    "        model.train()  # Zapneme trenovaci rezim (Dropout aktivni)\n",
    "        outputs = model(X_train_t)\n",
    "        loss = criterion(outputs, y_train_t)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # ===== VYHODNOCENI =====\n",
    "        model.eval()  # Vypneme trenovaci rezim (Dropout NEaktivni)\n",
    "        with torch.no_grad():\n",
    "            # Trenovaci presnost\n",
    "            train_pred = torch.round(model(X_train_t))\n",
    "            train_acc = (train_pred.eq(y_train_t).sum() / len(y_train_t)).item()\n",
    "            \n",
    "            # Testovaci presnost\n",
    "            test_pred = torch.round(model(X_test_t))\n",
    "            test_acc = (test_pred.eq(y_test_t).sum() / len(y_test_t)).item()\n",
    "            \n",
    "            # Testovaci loss\n",
    "            test_loss = criterion(model(X_test_t), y_test_t)\n",
    "        \n",
    "        train_losses.append(loss.item())\n",
    "        test_losses.append(test_loss.item())\n",
    "        train_accs.append(train_acc)\n",
    "        test_accs.append(test_acc)\n",
    "        \n",
    "        if verbose and (epoch + 1) % 500 == 0:\n",
    "            print(f'Epocha {epoch+1:4d}/{epochs} | '\n",
    "                  f'Train Loss: {loss.item():.4f} | Test Loss: {test_loss.item():.4f} | '\n",
    "                  f'Train Acc: {train_acc:.2%} | Test Acc: {test_acc:.2%}')\n",
    "    \n",
    "    return {\n",
    "        'train_losses': train_losses,\n",
    "        'test_losses': test_losses,\n",
    "        'train_accs': train_accs,\n",
    "        'test_accs': test_accs,\n",
    "        'final_train_acc': train_accs[-1],\n",
    "        'final_test_acc': test_accs[-1]\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Experiment: Model BEZ Dropoutu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"TRENOVANI MODELU BEZ DROPOUTU\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "torch.manual_seed(42)\n",
    "model_bez_dropout = MoonNet(use_dropout=False)\n",
    "results_bez = train_and_evaluate(model_bez_dropout, \"Bez Dropoutu\")\n",
    "\n",
    "print(\"\\n\" + \"-\"*40)\n",
    "print(f\"Finalni presnost na TRENOVACICH datech: {results_bez['final_train_acc']:.2%}\")\n",
    "print(f\"Finalni presnost na TESTOVACICH datech: {results_bez['final_test_acc']:.2%}\")\n",
    "print(f\"Rozdil (gap): {results_bez['final_train_acc'] - results_bez['final_test_acc']:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Experiment: Model S Dropoutem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"TRENOVANI MODELU S DROPOUTEM (p=0.5)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "torch.manual_seed(42)\n",
    "model_s_dropout = MoonNet(use_dropout=True, dropout_rate=0.5)\n",
    "results_s = train_and_evaluate(model_s_dropout, \"S Dropoutem\")\n",
    "\n",
    "print(\"\\n\" + \"-\"*40)\n",
    "print(f\"Finalni presnost na TRENOVACICH datech: {results_s['final_train_acc']:.2%}\")\n",
    "print(f\"Finalni presnost na TESTOVACICH datech: {results_s['final_test_acc']:.2%}\")\n",
    "print(f\"Rozdil (gap): {results_s['final_train_acc'] - results_s['final_test_acc']:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Porovnani vysledku"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Porovnani ucicich krivek\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# Loss - bez dropoutu\n",
    "axes[0, 0].plot(results_bez['train_losses'], 'b-', label='Train Loss', alpha=0.7)\n",
    "axes[0, 0].plot(results_bez['test_losses'], 'r-', label='Test Loss', alpha=0.7)\n",
    "axes[0, 0].set_title('BEZ Dropoutu - Loss', fontsize=14)\n",
    "axes[0, 0].set_xlabel('Epocha')\n",
    "axes[0, 0].set_ylabel('Loss')\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Loss - s dropoutem\n",
    "axes[0, 1].plot(results_s['train_losses'], 'b-', label='Train Loss', alpha=0.7)\n",
    "axes[0, 1].plot(results_s['test_losses'], 'r-', label='Test Loss', alpha=0.7)\n",
    "axes[0, 1].set_title('S Dropoutem - Loss', fontsize=14)\n",
    "axes[0, 1].set_xlabel('Epocha')\n",
    "axes[0, 1].set_ylabel('Loss')\n",
    "axes[0, 1].legend()\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# Accuracy - bez dropoutu\n",
    "axes[1, 0].plot(results_bez['train_accs'], 'b-', label='Train Accuracy', alpha=0.7)\n",
    "axes[1, 0].plot(results_bez['test_accs'], 'r-', label='Test Accuracy', alpha=0.7)\n",
    "axes[1, 0].set_title('BEZ Dropoutu - Presnost', fontsize=14)\n",
    "axes[1, 0].set_xlabel('Epocha')\n",
    "axes[1, 0].set_ylabel('Presnost')\n",
    "axes[1, 0].legend()\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Accuracy - s dropoutem\n",
    "axes[1, 1].plot(results_s['train_accs'], 'b-', label='Train Accuracy', alpha=0.7)\n",
    "axes[1, 1].plot(results_s['test_accs'], 'r-', label='Test Accuracy', alpha=0.7)\n",
    "axes[1, 1].set_title('S Dropoutem - Presnost', fontsize=14)\n",
    "axes[1, 1].set_xlabel('Epocha')\n",
    "axes[1, 1].set_ylabel('Presnost')\n",
    "axes[1, 1].legend()\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nPOZOROVANI:\")\n",
    "print(\"- BEZ Dropoutu: Velka mezera mezi train a test (preuceni!)\")\n",
    "print(\"- S Dropoutem: Mensi mezera, lepsi generalizace\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Souhrn vysledku\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"SOUHRN VYSLEDKU\")\n",
    "print(\"=\"*60)\n",
    "print(f\"{'Model':<20} | {'Train Acc':>12} | {'Test Acc':>12} | {'Gap':>12}\")\n",
    "print(\"-\"*60)\n",
    "\n",
    "gap_bez = results_bez['final_train_acc'] - results_bez['final_test_acc']\n",
    "gap_s = results_s['final_train_acc'] - results_s['final_test_acc']\n",
    "\n",
    "print(f\"{'Bez Dropoutu':<20} | {results_bez['final_train_acc']:>11.2%} | {results_bez['final_test_acc']:>11.2%} | {gap_bez:>11.2%}\")\n",
    "print(f\"{'S Dropoutem (0.5)':<20} | {results_s['final_train_acc']:>11.2%} | {results_s['final_test_acc']:>11.2%} | {gap_s:>11.2%}\")\n",
    "print(\"-\"*60)\n",
    "\n",
    "print(f\"\\nZlepseni testovaci presnosti: {results_s['final_test_acc'] - results_bez['final_test_acc']:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Vizualizace rozhodovaci hranice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_decision_boundary(model, X, y, title):\n",
    "    \"\"\"Vizualizuje rozhodovaci hranici modelu\"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    # Vytvoreni mrizky\n",
    "    x_min, x_max = X[:, 0].min() - 0.5, X[:, 0].max() + 0.5\n",
    "    y_min, y_max = X[:, 1].min() - 0.5, X[:, 1].max() + 0.5\n",
    "    xx, yy = np.meshgrid(np.linspace(x_min, x_max, 200),\n",
    "                         np.linspace(y_min, y_max, 200))\n",
    "    \n",
    "    # Predikce na mrizce\n",
    "    grid = torch.from_numpy(np.c_[xx.ravel(), yy.ravel()]).float()\n",
    "    with torch.no_grad():\n",
    "        Z = model(grid).numpy()\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    \n",
    "    # Vizualizace\n",
    "    plt.contourf(xx, yy, Z, levels=50, cmap='coolwarm', alpha=0.6)\n",
    "    plt.contour(xx, yy, Z, levels=[0.5], colors='black', linewidths=2)\n",
    "    plt.scatter(X[:, 0], X[:, 1], c=y, cmap='coolwarm', edgecolors='black', alpha=0.8)\n",
    "    plt.title(title, fontsize=14)\n",
    "    plt.xlabel('X1')\n",
    "    plt.ylabel('X2')\n",
    "\n",
    "# Porovnani rozhodovacich hranic\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plot_decision_boundary(model_bez_dropout, X_test, y_test, \n",
    "                       f'BEZ Dropoutu\\nTest Acc: {results_bez[\"final_test_acc\"]:.1%}')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plot_decision_boundary(model_s_dropout, X_test, y_test,\n",
    "                       f'S Dropoutem (p=0.5)\\nTest Acc: {results_s[\"final_test_acc\"]:.1%}')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nVsimnete si:\")\n",
    "print(\"- BEZ Dropoutu: Hranice je 'kostrbata', snazi se obkreslit kazdy bod\")\n",
    "print(\"- S Dropoutem: Hranice je hladsi, lepe vystihuje obecny tvar\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Experiment: Ruzne hodnoty Dropout rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testovani ruznych dropout rates\n",
    "dropout_rates = [0.0, 0.2, 0.5, 0.7, 0.9]\n",
    "results_all = {}\n",
    "\n",
    "print(\"Testovani ruznych hodnot dropout rate...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for rate in dropout_rates:\n",
    "    torch.manual_seed(42)\n",
    "    model = MoonNet(use_dropout=(rate > 0), dropout_rate=rate)\n",
    "    results = train_and_evaluate(model, f\"Dropout={rate}\", epochs=2000, verbose=False)\n",
    "    results_all[rate] = results\n",
    "    print(f\"Dropout {rate}: Train Acc = {results['final_train_acc']:.2%}, \"\n",
    "          f\"Test Acc = {results['final_test_acc']:.2%}\")\n",
    "\n",
    "# Vizualizace\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "train_accs = [results_all[r]['final_train_acc'] for r in dropout_rates]\n",
    "test_accs = [results_all[r]['final_test_acc'] for r in dropout_rates]\n",
    "\n",
    "x = np.arange(len(dropout_rates))\n",
    "width = 0.35\n",
    "\n",
    "plt.bar(x - width/2, train_accs, width, label='Train Accuracy', color='#3498db')\n",
    "plt.bar(x + width/2, test_accs, width, label='Test Accuracy', color='#e74c3c')\n",
    "\n",
    "plt.xlabel('Dropout Rate', fontsize=12)\n",
    "plt.ylabel('Presnost', fontsize=12)\n",
    "plt.title('Vliv Dropout Rate na presnost', fontsize=14)\n",
    "plt.xticks(x, [f'p={r}' for r in dropout_rates])\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3, axis='y')\n",
    "plt.ylim(0.5, 1.0)\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nPozorovani:\")\n",
    "print(\"- p=0.0: Velky gap mezi train a test (preuceni)\")\n",
    "print(\"- p=0.5: Optimalni - maly gap, dobra testovaci presnost\")\n",
    "print(\"- p=0.9: Prilis vysoke - model se neuci dostatecne\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Dulezite: train() vs eval() rezimy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrace rozdilu mezi train() a eval()\n",
    "model_demo = MoonNet(use_dropout=True, dropout_rate=0.5)\n",
    "\n",
    "# Vstup pro testovani\n",
    "test_input = torch.tensor([[0.5, 0.5]])\n",
    "\n",
    "print(\"Demonstrace rozdilu mezi train() a eval() rezimy:\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Train rezim (Dropout aktivni)\n",
    "model_demo.train()\n",
    "print(\"\\nTrain rezim (Dropout AKTIVNI):\")\n",
    "outputs_train = []\n",
    "for i in range(5):\n",
    "    with torch.no_grad():\n",
    "        out = model_demo(test_input).item()\n",
    "        outputs_train.append(out)\n",
    "        print(f\"  Pokus {i+1}: {out:.4f}\")\n",
    "print(f\"  -> Vystupy se LISI (nahodne neurony vypnute)\")\n",
    "\n",
    "# Eval rezim (Dropout neaktivni)\n",
    "model_demo.eval()\n",
    "print(\"\\nEval rezim (Dropout NEAKTIVNI):\")\n",
    "outputs_eval = []\n",
    "for i in range(5):\n",
    "    with torch.no_grad():\n",
    "        out = model_demo(test_input).item()\n",
    "        outputs_eval.append(out)\n",
    "        print(f\"  Pokus {i+1}: {out:.4f}\")\n",
    "print(f\"  -> Vystupy jsou STEJNE (vsechny neurony aktivni)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Shrnuti kapitoly\n",
    "\n",
    "### Co jsme se naucili:\n",
    "\n",
    "1. **Preuceni (Overfitting)** - model se nauci trenovaci data \"nazpamet\" a nedokaze generalizovat\n",
    "\n",
    "2. **Dropout** je regularizacni technika:\n",
    "   - Behem trenovani nahodne vypina neurony\n",
    "   - Nutí sit rozdelovat znalosti mezi vice neuronu\n",
    "   - Vysledek: Robustnejsi model s lepsi generalizaci\n",
    "\n",
    "3. **Pouziti v PyTorch**:\n",
    "   - `nn.Dropout(p=0.5)` - vytvoreni vrstvy\n",
    "   - `model.train()` - aktivuje Dropout\n",
    "   - `model.eval()` - deaktivuje Dropout\n",
    "\n",
    "4. **Typicke hodnoty Dropout rate**:\n",
    "   - p=0.2-0.5 pro skryte vrstvy\n",
    "   - Vyssi hodnoty mohou bránit uceni\n",
    "\n",
    "### Prakticka doporuceni:\n",
    "- Pouzivejte Dropout kdyz vidite velky rozdil mezi train a test presnosti\n",
    "- Zacinajte s p=0.5 a experimentujte\n",
    "- Vzdy prepinajte mezi `train()` a `eval()` rezimy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Kviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"KVIZ - Dropout a Preuceni\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "questions = [\n",
    "    {\n",
    "        \"question\": \"1. Co je preuceni (overfitting)?\",\n",
    "        \"options\": [\"a) Model se neuci vubec\", \"b) Model ma vysokou testovaci presnost\", \n",
    "                   \"c) Model si zapamatoval trenovaci data, ale nedokaze generalizovat\", \n",
    "                   \"d) Model ma nizkou trenovaci presnost\"],\n",
    "        \"answer\": \"c\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"2. Co dela Dropout behem trenovani?\",\n",
    "        \"options\": [\"a) Pridava nove neurony\", \"b) Nahodne vypina neurony\", \n",
    "                   \"c) Zvysuje learning rate\", \"d) Meni aktivacni funkce\"],\n",
    "        \"answer\": \"b\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"3. Kdyz zavolame model.eval(), co se stane s Dropoutem?\",\n",
    "        \"options\": [\"a) Zustane aktivni\", \"b) Deaktivuje se\", \n",
    "                   \"c) Zvysi se dropout rate\", \"d) Smaze se\"],\n",
    "        \"answer\": \"b\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"4. Typicka hodnota dropout rate pro skryte vrstvy je:\",\n",
    "        \"options\": [\"a) 0.01\", \"b) 0.2-0.5\", \"c) 0.95\", \"d) 1.0\"],\n",
    "        \"answer\": \"b\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"5. Jake je hlavni 'znamení' preuceni?\",\n",
    "        \"options\": [\"a) Nizka presnost na train i test\", \n",
    "                   \"b) Vysoka presnost na train, nizka na test\", \n",
    "                   \"c) Stejna presnost na train i test\", \n",
    "                   \"d) Model se vubec neuci\"],\n",
    "        \"answer\": \"b\"\n",
    "    }\n",
    "]\n",
    "\n",
    "for q in questions:\n",
    "    print(f\"\\n{q['question']}\")\n",
    "    for opt in q['options']:\n",
    "        print(f\"   {opt}\")\n",
    "\n",
    "print(\"\\n\" + \"-\"*60)\n",
    "print(\"ODPOVEDI: 1-c, 2-b, 3-b, 4-b, 5-b\")\n",
    "print(\"-\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14. Vase vyzva\n",
    "\n",
    "1. Zkuste zmenit architekturu site (mensi/vetsi) a sledujte vliv na preuceni\n",
    "2. Experimentujte s ruznymi dropout rates a najdete optimalni hodnotu\n",
    "3. Pridejte Dropout pouze po prvni nebo pouze po druhe vrstve - jaky je rozdil?\n",
    "\n",
    "**Tip:** Dropout neni jedina regularizacni technika. Dalsi zahrnuji L1/L2 regularizaci, Early Stopping, a Data Augmentation!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
