{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4fb2df3c",
   "metadata": {},
   "source": [
    "# üìö Kapitola 35: RAG (Retrieval Augmented Generation)\n",
    "\n",
    "<div style=\"background: linear-gradient(90deg, #667eea 0%, #764ba2 100%); padding: 20px; border-radius: 10px; margin: 20px 0;\">\n",
    "    <h2 style=\"color: white; margin: 0;\">Blok 4 | EXPERT</h2>\n",
    "    <p style=\"color: white; margin: 10px 0;\">üìñ V√Ωukov√° kapitola</p>\n",
    "</div>\n",
    "\n",
    "## üéØ Co se nauƒç√≠te\n",
    "\n",
    "V t√©to kapitole se zamƒõ≈ô√≠me na n√°sleduj√≠c√≠ t√©mata:\n",
    "\n",
    "- **RAG architecture**\n",
    "- **Vector databases: ChromaDB, Pinecone, Weaviate**\n",
    "- **Embeddings models**\n",
    "- **Document chunking strategies**\n",
    "- **Similarity search algorithms**\n",
    "- **Reranking techniques**\n",
    "- **Hybrid search implementation**\n",
    "\n",
    "## ‚ö†Ô∏è P≈ôedpoklady\n",
    "Tato kapitola navazuje na kapitoly: 33\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1c7a526",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚öôÔ∏è Inicializace prost≈ôed√≠\n",
    "# Tento k√≥d nastavuje prost≈ôed√≠ pro kapitolu 35\n",
    "\n",
    "import sys\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "# Informace o prost≈ôed√≠\n",
    "print(\"=\" * 60)\n",
    "print(f\"üìö KAPITOLA 35: RAG (Retrieval Augmented Generation)\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"üêç Python verze: {sys.version}\")\n",
    "print(f\"üìÖ Datum spu≈°tƒõn√≠: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(f\"üíª OS: {os.name}\")\n",
    "print(f\"üìÅ Pracovn√≠ adres√°≈ô: {os.getcwd()}\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Instalace pot≈ôebn√Ωch knihoven (odkomentujte podle pot≈ôeby)\n",
    "# !pip install requests pandas numpy matplotlib\n",
    "# !pip install beautifulsoup4 sqlalchemy fastapi\n",
    "\n",
    "# Import z√°kladn√≠ch knihoven\n",
    "import json\n",
    "import csv\n",
    "import time\n",
    "import random\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Optional, Any\n",
    "\n",
    "print(\"‚úÖ Prost≈ôed√≠ p≈ôipraveno!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75e89916",
   "metadata": {},
   "source": [
    "## üìñ Teoretick√° ƒç√°st\n",
    "\n",
    "<div style=\"background: #f0f4ff; padding: 20px; border-left: 5px solid #4a69bd; margin: 20px 0; border-radius: 5px;\">\n",
    "    <h3 style=\"color: #2c3e50; margin-top: 0;\">üéì Z√°kladn√≠ teorie a koncepty</h3>\n",
    "</div>\n",
    "\n",
    "# RAG (Retrieval Augmented Generation) ‚Äì Detailn√≠ teoretick√Ω v√Ωklad\n",
    "\n",
    "---\n",
    "\n",
    "## 1. √övod a motivace\n",
    "\n",
    "RAG (Retrieval Augmented Generation) je modern√≠ p≈ô√≠stup k generov√°n√≠ textu, kter√Ω kombinuje siln√© str√°nky vyhled√°vac√≠ch syst√©m≈Ø s pokroƒçil√Ωmi modely jazykov√©ho zpracov√°n√≠. V souƒçasn√© dobƒõ je kl√≠ƒçov√Ω pro vytv√°≈ôen√≠ p≈ôesn√Ωch, kontextu√°lnƒõ relevantn√≠ch a aktualizovan√Ωch odpovƒõd√≠, zejm√©na ve velk√Ωch jazykov√Ωch modelech (LLMs). RAG je z√°sadn√≠ pro aplikace jako nap≈ô√≠klad inteligentn√≠ asistenti, automatick√° dokumentace, podpora v√Ωvoj√°≈ô≈Ø nebo v√Ωzkumn√© n√°stroje.\n",
    "\n",
    "V praxi se RAG pou≈æ√≠v√° v syst√©mech typu chatbot≈Ø, kde je d≈Øle≈æit√©, aby odpovƒõdi byly nejen gramaticky spr√°vn√©, ale tak√© zalo≈æen√© na aktu√°ln√≠ch datech ‚Äì tedy nap≈ô√≠klad vnit≈ôn√≠ datab√°zi firemn√≠ch dokument≈Ø, technick√© dokumentace, nebo novinky z oboru. Student po prozkoum√°n√≠ t√©to kapitoly nauƒç√≠:\n",
    "\n",
    "- Jak funguje architektura RAG\n",
    "- Jak√Ωm zp≈Øsobem se vyu≈æ√≠vaj√≠ embeddingy a datab√°ze vektor≈Ø\n",
    "- Jak√© algoritmy se pou≈æ√≠vaj√≠ pro vyhled√°v√°n√≠ podobn√Ωch dokument≈Ø\n",
    "- Jak implementovat efektivn√≠ hybridn√≠ vyhled√°v√°n√≠\n",
    "\n",
    "---\n",
    "\n",
    "## 2. Hlavn√≠ koncepty\n",
    "\n",
    "### RAG Architecture\n",
    "\n",
    "RAG architektura je slo≈æena ze dvou hlavn√≠ch souƒç√°st√≠:\n",
    "\n",
    "1. **Retrieval (vyhled√°v√°n√≠)** ‚Äì syst√©m, kter√Ω najde relevantn√≠ dokumenty z datab√°ze podle zad√°n√≠ u≈æivatele.\n",
    "2. **Generation (generov√°n√≠)** ‚Äì model, kter√Ω vytvo≈ô√≠ odpovƒõƒè na z√°kladƒõ vstupu a relevantn√≠ho kontextu.\n",
    "\n",
    "Struktura RAG syst√©mu m≈Ø≈æe b√Ωt zn√°zornƒõna n√°sleduj√≠c√≠m zp≈Øsobem:\n",
    "\n",
    "```\n",
    "[User Query] ‚Üí [Embedding Model] ‚Üí [Vector Database] ‚Üí [Retrieved Docs]\n",
    "                              ‚Üì\n",
    "                        [LLM Input] ‚Üí [LLM] ‚Üí [Response]\n",
    "```\n",
    "\n",
    "Kl√≠ƒçov√° v√Ωhoda RAG je schopnost pou≈æ√≠t aktu√°ln√≠ informace z extern√≠ch zdroj≈Ø, a ne jen informace, kter√© byly p≈ôed tr√©ninkem modelu. To umo≈æ≈àuje generovat odpovƒõdi s vysokou p≈ôesnost√≠ a aktualizovanost√≠.\n",
    "\n",
    "---\n",
    "\n",
    "### Vector Databases: ChromaDB, Pinecone, Weaviate\n",
    "\n",
    "Pro ukl√°d√°n√≠ a vyhled√°v√°n√≠ vektorov√Ωch reprezentac√≠ dokument≈Ø se pou≈æ√≠vaj√≠ tzv. **vector databases**. Mezi nejroz≈°√≠≈ôenƒõj≈°√≠ pat≈ô√≠:\n",
    "\n",
    "- **ChromaDB**: Open-source ≈ôe≈°en√≠, vhodn√© pro lok√°ln√≠ a v√Ωvojov√© prost≈ôed√≠.\n",
    "- **Pinecone**: Cloudov√° platforma pro vyhled√°v√°n√≠ vektor≈Ø s velkou ≈°k√°lou a integrac√≠ s LLM modely.\n",
    "- **Weaviate**: Roz≈°i≈ôiteln√Ω syst√©m, kter√Ω podporuje semantick√© vyhled√°v√°n√≠ a pln√© textov√© indexy.\n",
    "\n",
    "Ka≈æd√° z tƒõchto datab√°z√≠ m√° vlastn√≠ siln√© str√°nky ‚Äì nap≈ô. Pinecone pro rychl√© vyhled√°v√°n√≠ v velk√Ωch datech, ChromaDB pro jednoduchou integraci do lok√°ln√≠ch projekt≈Ø.\n",
    "\n",
    "---\n",
    "\n",
    "### Embeddings Models\n",
    "\n",
    "Embeddings jsou ƒç√≠seln√© reprezentace textu ve vektorov√©m prostoru. Jejich √∫kolem je zachytit v√Ωznamovou podobnost mezi dokumenty nebo fr√°zemi. V RAG syst√©mech se pou≈æ√≠vaj√≠ modely jako:\n",
    "\n",
    "- **Sentence Transformers** (nap≈ô. `all-MiniLM-L6-v2`)\n",
    "- **OpenAI Embeddings**\n",
    "- **BGE (Bidirectional Guided Embeddings)**\n",
    "\n",
    "Tyto modely p≈ôev√°dƒõj√≠ text na vektorov√© reprezentace, kter√© jsou pak ukl√°d√°ny do datab√°ze a slou≈æ√≠ k vyhled√°v√°n√≠ podobn√Ωch dokument≈Ø.\n",
    "\n",
    "---\n",
    "\n",
    "### Document Chunking Strategies\n",
    "\n",
    "Dokumenty se p≈ôed ulo≈æen√≠m rozdƒõluj√≠ na **chunky** (√∫seky), kter√© se n√°slednƒõ vektorizuj√≠. ƒåast√© strategie:\n",
    "\n",
    "- **P≈ôesn√© dƒõlen√≠ podle d√©lky (fixed-length chunking)**\n",
    "- **Dƒõlen√≠ podle oddƒõlovaƒç≈Ø (e.g., odstavce, novely)**\n",
    "- **Dynamick√© dƒõlen√≠ (semantic chunking)** ‚Äì vyu≈æit√≠ modelu k vytvo≈ôen√≠ smyslupln√Ωch √∫sek≈Ø\n",
    "\n",
    "Prvn√≠ dvƒõ strategie jsou jednoduch√©, ale mohou v√©st ke ztr√°tƒõ kontextu. Semantic chunking je efektivnƒõj≈°√≠, proto≈æe udr≈æuje v√Ωznamovou spojitost.\n",
    "\n",
    "---\n",
    "\n",
    "### Similarity Search Algorithms\n",
    "\n",
    "Vektorov√° datab√°ze pou≈æ√≠v√° algoritmy na hled√°n√≠ podobn√Ωch vektor≈Ø. Mezi nejƒçastƒõj≈°√≠ pat≈ô√≠:\n",
    "\n",
    "- **Cosine similarity**: Nejƒçastƒõj≈°√≠ metoda pro porovn√°n√≠ vektor≈Ø.\n",
    "- **Euclidean distance**\n",
    "- **Inner product**\n",
    "\n",
    "Pou≈æit√≠ tƒõchto algoritm≈Ø je kl√≠ƒçov√© pro efektivn√≠ vyhled√°v√°n√≠ relevantn√≠ho obsahu. V√Ωbƒõr z√°vis√≠ na rychlosti, p≈ôesnosti a velikosti dat.\n",
    "\n",
    "---\n",
    "\n",
    "### Reranking Techniques\n",
    "\n",
    "Po poƒç√°teƒçn√≠m vyhled√°n√≠ dokument≈Ø se ƒçasto pou≈æ√≠vaj√≠ **reranking** techniky, kter√© up≈ôednost≈àuj√≠ nejrelevantnƒõj≈°√≠ dokumenty. Nap≈ô√≠klad:\n",
    "\n",
    "- **Cross-encoder models** (nap≈ô. `cross-encoder/ms-marco-MiniLM-L-6-v2`)\n",
    "- **Hybrid reranking** ‚Äì kombinace BM25 a vektorov√©ho vyhled√°v√°n√≠\n",
    "\n",
    "Reranking poskytuje lep≈°√≠ kvalitu odpovƒõdi, proto≈æe model m≈Ø≈æe p≈ôehodnotit v√Ωsledky z poƒç√°teƒçn√≠ho vyhled√°v√°n√≠.\n",
    "\n",
    "---\n",
    "\n",
    "### Hybrid Search Implementation\n",
    "\n",
    "Hybrid search kombinuje r≈Øzn√© metody vyhled√°v√°n√≠:\n",
    "\n",
    "- **Vektorov√© vyhled√°v√°n√≠** (nap≈ô. podobnost vektor≈Ø)\n",
    "- **Textov√© vyhled√°v√°n√≠** (nap≈ô. BM25, full-text search)\n",
    "\n",
    "Implementace hybridn√≠ho vyhled√°v√°n√≠ m≈Ø≈æe b√Ωt nap≈ô√≠klad:\n",
    "\n",
    "```python\n",
    "# Pseudok√≥d\n",
    "retrieved_docs = vector_search(query, top_k=10)\n",
    "reranked_docs = rerank(query, retrieved_docs, top_k=5)\n",
    "```\n",
    "\n",
    "Tento p≈ô√≠stup zvy≈°uje p≈ôesnost a z√°rove≈à umo≈æ≈àuje efektivn√≠ vyhled√°v√°n√≠ i na velk√Ωch datech.\n",
    "\n",
    "---\n",
    "\n",
    "## 3. D≈Øle≈æit√© detaily\n",
    "\n",
    "### ƒåast√© chyby a jak se jim vyhnout\n",
    "\n",
    "- **Nedostateƒçn√© chunking strategie** ‚Äì m≈Ø≈æe v√©st ke ztr√°tƒõ kontextu.\n",
    "- **≈†patn√° volba embedding modelu** ‚Äì pro konkr√©tn√≠ dom√©nu m≈Ø≈æe b√Ωt model neefektivn√≠.\n",
    "- **Chybƒõj√≠c√≠ reranking** ‚Äì v√Ωsledky mohou b√Ωt nep≈ôesn√©, i kdy≈æ se nach√°z√≠ bl√≠zko.\n",
    "\n",
    "### Best practices\n",
    "\n",
    "- Vyu≈æ√≠vejte **semantic chunking** pro zachov√°n√≠ kontextu.\n",
    "- Pou≈æ√≠vejte **reranking modely** v p≈ô√≠padƒõ vysok√© p≈ôesnosti.\n",
    "- Implementujte **cache mechanismus** pro zrychlen√≠ opakovan√Ωch dotaz≈Ø.\n",
    "\n",
    "### Performance tipy\n",
    "\n",
    "- P≈ôedvytvo≈ôte embeddingy offline, aby se minimalizoval ƒças odpovƒõdi.\n",
    "- Vyu≈æ√≠vejte **indexov√°n√≠** a **vyhled√°v√°n√≠ na rozd√≠ln√Ωch √∫rovn√≠ch** (nap≈ô. dokument vs. odstavec).\n",
    "- Zva≈æte pou≈æit√≠ **in-memory cache** pro bƒõ≈æn√© dotazy.\n",
    "\n",
    "---\n",
    "\n",
    "## 4. Propojen√≠ s p≈ôedchoz√≠mi kapitolami\n",
    "\n",
    "Tato kapitola vyu≈æ√≠v√° znalosti z p≈ôedchoz√≠ch t√©mat jako jsou:\n",
    "\n",
    "- **Jazykov√© modely a jejich fungov√°n√≠**\n",
    "- **Embeddingy a jejich role v NLP**\n",
    "- **Textov√© indexace a vyhled√°v√°n√≠**\n",
    "\n",
    "RAG roz≈°i≈ôuje tyto koncepty t√≠m, ≈æe ukazuje, jak lze vyu≈æ√≠t vektorov√© reprezentace a vyhled√°vac√≠ syst√©my ve spolupr√°ci s LLM pro vytv√°≈ôen√≠ p≈ôesn√Ωch a kontextu√°lnƒõ relevantn√≠ch odpovƒõd√≠.\n",
    "\n",
    "---\n",
    "\n",
    "Tato kapitola je kl√≠ƒçov√° pro studenty, kte≈ô√≠ chtƒõj√≠ porozumƒõt pokroƒçil√Ωm aplikac√≠m jazykov√©ho modelu v praxi. RAG je nejen teoretick√Ω koncept, ale i praktick√Ω n√°stroj, kter√Ω se pou≈æ√≠v√° ve velk√Ωch syst√©mech AI ‚Äì od intern√≠ch asistent≈Ø a≈æ po v√Ωzkumn√© n√°stroje.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4094a0f",
   "metadata": {},
   "source": [
    "## üíª Praktick√© p≈ô√≠klady\n",
    "\n",
    "<div style=\"background: #e8f5e9; padding: 20px; border-left: 5px solid #4caf50; margin: 20px 0; border-radius: 5px;\">\n",
    "    <h3 style=\"color: #2c3e50; margin-top: 0;\">üë®‚Äçüíª Hands-on p≈ô√≠klady ke spu≈°tƒõn√≠</h3>\n",
    "    <p>N√°sleduj√≠c√≠ p≈ô√≠klady si m≈Ø≈æete hned vyzkou≈°et. Ka≈æd√Ω p≈ô√≠klad je samostatnƒõ spustiteln√Ω.</p>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc0ab628",
   "metadata": {},
   "source": [
    "### P≈ô√≠klad 1\n",
    "\n",
    "P≈ô√≠klad 1: Z√°kladn√≠ struktura RAG syst√©mu**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c2ae504",
   "metadata": {},
   "source": [
    "### P≈ô√≠klad 2\n",
    "\n",
    "### **1. N√°zev p≈ô√≠kladu**\n",
    "Z√°kladn√≠ RAG architektura s jednoduch√Ωm vektorov√Ωm vyhled√°v√°n√≠m"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2407e26e",
   "metadata": {},
   "source": [
    "### P≈ô√≠klad 3\n",
    "\n",
    "### **2. Co demonstruje**\n",
    "Tento p≈ô√≠klad ukazuje z√°kladn√≠ komponenty RAG syst√©mu: vytv√°≈ôen√≠ embedding≈Ø, ukl√°d√°n√≠ dokument≈Ø do vektorov√© datab√°ze a jednoduch√© vyhled√°v√°n√≠ podle podobnosti."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f4efa98",
   "metadata": {},
   "source": [
    "### P≈ô√≠klad 4\n",
    "\n",
    "### **3. Kompletn√≠ spustiteln√Ω k√≥d**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ac30c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instalace pot≈ôebn√Ωch knihoven:\n",
    "# pip install sentence-transformers chromadb\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import chromadb\n",
    "import numpy as np\n",
    "\n",
    "# Inicializace modelu pro vytv√°≈ôen√≠ embedding≈Ø\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# Vytvo≈ôen√≠ jednoduch√©ho dokumentu\n",
    "documents = [\n",
    "    \"Praha je hlavn√≠ mƒõsto ƒåesk√© republiky.\",\n",
    "    \"V√≠tejte v Praze, kter√° m√° bohatou historii.\",\n",
    "    \"ƒåesk√° republika se nach√°z√≠ v Evropƒõ.\"\n",
    "]\n",
    "\n",
    "# Vytvo≈ôen√≠ embedding≈Ø pro dokumenty\n",
    "embeddings = model.encode(documents)\n",
    "\n",
    "# Vytvo≈ôen√≠ klienta ChromaDB (lok√°ln√≠ datab√°ze)\n",
    "client = chromadb.Client()\n",
    "collection = client.create_collection(\"rag_docs\")\n",
    "\n",
    "# Ulo≈æen√≠ dokument≈Ø do kolekce\n",
    "for i, (doc, emb) in enumerate(zip(documents, embeddings)):\n",
    "    collection.add(\n",
    "        ids=[f\"doc_{i}\"],\n",
    "        documents=[doc],\n",
    "        embeddings=[emb.tolist()]\n",
    "    )\n",
    "\n",
    "# Vyhled√°n√≠ podobn√Ωch dokument≈Ø k dotazu\n",
    "query = \"Kde se nach√°z√≠ hlavn√≠ mƒõsto ƒåR?\"\n",
    "query_embedding = model.encode([query])\n",
    "\n",
    "# Hled√°n√≠ nejbli≈æ≈°√≠ch dokument≈Ø (similarity search)\n",
    "results = collection.query(\n",
    "    query_embeddings=query_embedding.tolist(),\n",
    "    n_results=2\n",
    ")\n",
    "\n",
    "print(\"Dotaz:\", query)\n",
    "print(\"Nalezen√© dokumenty:\")\n",
    "for i, doc in enumerate(results['documents'][0]):\n",
    "    print(f\"{i+1}. {doc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad422b80",
   "metadata": {},
   "source": [
    "### P≈ô√≠klad 5\n",
    "\n",
    "### **4. Oƒçek√°van√Ω v√Ωstup**\n",
    "```\n",
    "Dotaz: Kde se nach√°z√≠ hlavn√≠ mƒõsto ƒåR?\n",
    "Nalezen√© dokumenty:\n",
    "1. Praha je hlavn√≠ mƒõsto ƒåesk√© republiky.\n",
    "2. V√≠tejte v Praze, kter√° m√° bohatou historii.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f75d31e3",
   "metadata": {},
   "source": [
    "### P≈ô√≠klad 6\n",
    "\n",
    "### **5. Vysvƒõtlen√≠**\n",
    "Tento k√≥d demonstruje z√°kladn√≠ RAG workflow:\n",
    "1. Pou≈æit√≠ `SentenceTransformer` pro vytvo≈ôen√≠ embedding≈Ø z textu.\n",
    "2. Vytvo≈ôen√≠ lok√°ln√≠ ChromaDB kolekce a ulo≈æen√≠ dokument≈Ø s jejich embeddingy.\n",
    "3. Dotazov√°n√≠ na podobn√© dokumenty pomoc√≠ `collection.query()`.\n",
    "\n",
    "---\n",
    "\n",
    "## **"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39ab7283",
   "metadata": {},
   "source": [
    "### P≈ô√≠klad 7\n",
    "\n",
    "P≈ô√≠klad 2: Pou≈æit√≠ r≈Øzn√Ωch vektorov√Ωch datab√°z√≠ (ChromaDB vs Weaviate)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc5eeb42",
   "metadata": {},
   "source": [
    "### P≈ô√≠klad 8\n",
    "\n",
    "### **1. N√°zev p≈ô√≠kladu**\n",
    "Porovn√°n√≠ vektorov√Ωch datab√°z√≠ ‚Äì ChromaDB vs Weaviate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "941d18ed",
   "metadata": {},
   "source": [
    "### P≈ô√≠klad 9\n",
    "\n",
    "### **2. Co demonstruje**\n",
    "Porovn√°n√≠ z√°kladn√≠ch funkc√≠ dvou popul√°rn√≠ch vektorov√Ωch datab√°z√≠: ChromaDB (lok√°ln√≠) a Weaviate (s√≠≈•ov√°)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d43dcf4d",
   "metadata": {},
   "source": [
    "### P≈ô√≠klad 10\n",
    "\n",
    "### **3. Kompletn√≠ spustiteln√Ω k√≥d**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dea11eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instalace pot≈ôebn√Ωch knihoven:\n",
    "# pip install chromadb weaviate-client sentence-transformers\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import chromadb\n",
    "import weaviate\n",
    "\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "documents = [\n",
    "    \"Koƒçka je mil√° zv√≠≈ôe.\",\n",
    "    \"Pes bƒõ≈æ√≠ po ulici.\",\n",
    "    \"Stromy rostou v lese.\"\n",
    "]\n",
    "\n",
    "# ChromaDB\n",
    "chroma_client = chromadb.Client()\n",
    "chroma_collection = chroma_client.create_collection(\"chroma_docs\")\n",
    "embeddings = model.encode(documents)\n",
    "for i, (doc, emb) in enumerate(zip(documents, embeddings)):\n",
    "    chroma_collection.add(\n",
    "        ids=[f\"doc_{i}\"],\n",
    "        documents=[doc],\n",
    "        embeddings=[emb.tolist()]\n",
    "    )\n",
    "\n",
    "# Weaviate\n",
    "weaviate_client = weaviate.Client(\"http://localhost:8080\")\n",
    "schema = {\n",
    "    \"class\": \"Document\",\n",
    "    \"properties\": [\n",
    "        {\"name\": \"text\", \"dataType\": [\"text\"]}\n",
    "    ]\n",
    "}\n",
    "weaviate_client.schema.delete_class(\"Document\")\n",
    "weaviate_client.schema.create_class(schema)\n",
    "\n",
    "for i, doc in enumerate(documents):\n",
    "    weaviate_client.data_object.create(\n",
    "        class_name=\"Document\",\n",
    "        data_object={\"text\": doc},\n",
    "        vector=model.encode([doc])[0].tolist()\n",
    "    )\n",
    "\n",
    "print(\"ChromaDB a Weaviate inicializov√°ny.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c975445",
   "metadata": {},
   "source": [
    "### P≈ô√≠klad 11\n",
    "\n",
    "### **4. Oƒçek√°van√Ω v√Ωstup**\n",
    "Zobrazen√≠ zpr√°vy: `ChromaDB a Weaviate inicializov√°ny.`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98886297",
   "metadata": {},
   "source": [
    "### P≈ô√≠klad 12\n",
    "\n",
    "### **5. Vysvƒõtlen√≠**\n",
    "Tento p≈ô√≠klad ukazuje z√°kladn√≠ inicializaci dvou r≈Øzn√Ωch vektorov√Ωch datab√°z√≠:\n",
    "- **ChromaDB**: lok√°ln√≠, jednoduch√© pou≈æit√≠ (ide√°ln√≠ pro testovac√≠ prost≈ôed√≠).\n",
    "- **Weaviate**: s√≠≈•ov√° datab√°ze (vy≈æaduje spu≈°tƒõn√Ω Weaviate server).\n",
    "\n",
    "---\n",
    "\n",
    "## **"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2224a657",
   "metadata": {},
   "source": [
    "### P≈ô√≠klad 13\n",
    "\n",
    "P≈ô√≠klad 3: Chunking strategie ‚Äì rozdƒõlen√≠ dokumentu na ƒç√°sti**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aacda46e",
   "metadata": {},
   "source": [
    "### P≈ô√≠klad 14\n",
    "\n",
    "### **1. N√°zev p≈ô√≠kladu**\n",
    "Rozdƒõlen√≠ dokumentu na chunky pomoc√≠ r≈Øzn√Ωch strategi√≠"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ed79966",
   "metadata": {},
   "source": [
    "### P≈ô√≠klad 15\n",
    "\n",
    "### **2. Co demonstruje**\n",
    "Tento p≈ô√≠klad ukazuje, jak lze rozdƒõlit text na ƒç√°sti (chunking), co≈æ je kl√≠ƒçov√© pro efektivn√≠ pr√°ci s velk√Ωmi dokumenty v RAG syst√©mech."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4550c8ba",
   "metadata": {},
   "source": [
    "### P≈ô√≠klad 16\n",
    "\n",
    "### **3. Kompletn√≠ spustiteln√Ω k√≥d**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d25c5a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import re\n",
    "\n",
    "# Vstupn√≠ dokument\n",
    "document = \"\"\"\n",
    "V√≠t√°me v√°s v historick√©m mƒõstƒõ Praze, kter√© je zn√°m√© svou bohatou kulturou a architekturou.\n",
    "Praha m√° nƒõkolik nejv√Ωznamnƒõj≈°√≠ pam√°tek jako jsou pra≈æsk√Ω hrad, karl≈Øv most a staromƒõstsk√© n√°mƒõst√≠.\n",
    "Tato mƒõsto je souƒç√°st√≠ Evropy a pat≈ô√≠ mezi nejnav≈°tƒõvovanƒõj≈°√≠ destinace v ƒåesk√© republice.\n",
    "\"\"\"\n",
    "\n",
    "# Strategie 1: Rozdƒõlen√≠ podle odstavc≈Ø\n",
    "def chunk_by_paragraphs(text):\n",
    "    return [p.strip() for p in text.split('\\n\\n') if p.strip()]\n",
    "\n",
    "# Strategie 2: Rozdƒõlen√≠ podle slov (nap≈ô. ka≈æd√Ωch 50 slov)\n",
    "def chunk_by_words(text, max_words=50):\n",
    "    words = text.split()\n",
    "    chunks = []\n",
    "    for i in range(0, len(words), max_words):\n",
    "        chunks.append(' '.join(words[i:i+max_words]))\n",
    "    return chunks\n",
    "\n",
    "# Rozdƒõlen√≠ dokumentu\n",
    "paragraph_chunks = chunk_by_paragraphs(document)\n",
    "word_chunks = chunk_by_words(document)\n",
    "\n",
    "print(\"Rozdƒõlen√≠ podle odstavc≈Ø:\")\n",
    "for i, chunk in enumerate(paragraph_chunks):\n",
    "    print(f\"{i+1}. {chunk}\")\n",
    "\n",
    "print(\"\\nRozdƒõlen√≠ podle slov (50 slov):\")\n",
    "for i, chunk in enumerate(word_chunks):\n",
    "    print(f\"{i+1}. {chunk}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "001fab0c",
   "metadata": {},
   "source": [
    "### P≈ô√≠klad 17\n",
    "\n",
    "### **4. Oƒçek√°van√Ω v√Ωstup**\n",
    "```\n",
    "Rozdƒõlen√≠ podle odstavc≈Ø:\n",
    "1. V√≠t√°me v√°s v historick√©m mƒõstƒõ Praze, kter√© je zn√°m√© svou bohatou kulturou a architekturou.\n",
    "2. Praha m√° nƒõkolik nejv√Ωznamnƒõj≈°√≠ pam√°tek jako jsou pra≈æsk√Ω hrad, karl≈Øv most a staromƒõstsk√© n√°mƒõst√≠.\n",
    "3. Tato mƒõsto je souƒç√°st√≠ Evropy a pat≈ô√≠ mezi nejnav≈°tƒõvovanƒõj≈°√≠ destinace v ƒåesk√© republice.\n",
    "\n",
    "Rozdƒõlen√≠ podle slov (50 slov):\n",
    "1. V√≠t√°me v√°s v historick√©m mƒõstƒõ Praze, kter√© je zn√°m√© svou bohatou kulturou a architekturou. Praha m√° nƒõkolik nejv√Ωznamnƒõj≈°√≠ pam√°tek jako jsou pra≈æsk√Ω hrad, karl≈Øv most a staromƒõstsk√© n√°mƒõst√≠.\n",
    "2. Tato mƒõsto je souƒç√°st√≠ Evropy a pat≈ô√≠ mezi nejnav≈°tƒõvovanƒõj≈°√≠ destinace v ƒåesk√© republice.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1006a410",
   "metadata": {},
   "source": [
    "### P≈ô√≠klad 18\n",
    "\n",
    "### **5. Vysvƒõtlen√≠**\n",
    "Rozdƒõlen√≠ dokument≈Ø (chunking) je d≈Øle≈æit√© pro zlep≈°en√≠ p≈ôesnosti vyhled√°v√°n√≠:\n",
    "- **Podle odstavc≈Ø** zachov√°v√° kontext.\n",
    "- **Podle slov** umo≈æ≈àuje detailnƒõj≈°√≠ kontrolu, ale m≈Ø≈æe ztratit souvislost.\n",
    "\n",
    "---\n",
    "\n",
    "## **"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa3ebc02",
   "metadata": {},
   "source": [
    "### P≈ô√≠klad 19\n",
    "\n",
    "P≈ô√≠klad 4: Implementace similarity search algoritm≈Ø (cosine similarity)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3973ad9",
   "metadata": {},
   "source": [
    "### P≈ô√≠klad 20\n",
    "\n",
    "### **1. N√°zev p≈ô√≠kladu**\n",
    "V√Ωpoƒçet podobnosti mezi dokumenty pomoc√≠ cosine similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8af207f0",
   "metadata": {},
   "source": [
    "### P≈ô√≠klad 21\n",
    "\n",
    "### **2. Co demonstruje**\n",
    "Demonstruje v√Ωpoƒçet podobnosti mezi dokumenty pomoc√≠ kosinov√© vzd√°lenosti a vektorov√© datab√°ze."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb043af0",
   "metadata": {},
   "source": [
    "### P≈ô√≠klad 22\n",
    "\n",
    "### **3. Kompletn√≠ spustiteln√Ω k√≥d**\n",
    "```python\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# Dokumenty\n",
    "documents = [\n",
    "    \"Koƒçka je mil√° zv√≠≈ôe.\",\n",
    "    \"Pes bƒõ≈æ√≠ po ulici.\",\n",
    "    \"Stromy rostou v lese.\",\n",
    "    \"V√≠tejte v Praze.\"\n",
    "]\n",
    "\n",
    "# Vytvo≈ôen√≠ embedding≈Ø\n",
    "embeddings = model.encode(documents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3eebc58",
   "metadata": {},
   "source": [
    "## üéØ Cviƒçen√≠ a √∫koly\n",
    "\n",
    "<div style=\"background: #fff3e0; padding: 20px; border-left: 5px solid #ff9800; margin: 20px 0; border-radius: 5px;\">\n",
    "    <h3 style=\"color: #2c3e50; margin-top: 0;\">‚úçÔ∏è Praktick√° cviƒçen√≠ k procviƒçen√≠</h3>\n",
    "    <p>Vy≈ôe≈°te n√°sleduj√≠c√≠ √∫koly. Zaƒçnƒõte od jednodu≈°≈°≈°√≠ch a postupujte k slo≈æitƒõj≈°√≠m.</p>\n",
    "</div>\n",
    "\n",
    "# Cviƒçen√≠ k kapitƒõ: RAG (Retrieval Augmented Generation)\n",
    "\n",
    "---\n",
    "\n",
    "## 1. **N√°zev √∫kolu**  \n",
    "RAG Pipeline ‚Äì Implementace jednoduch√©ho retrieval + generation syst√©mu\n",
    "\n",
    "### 2. **Detailn√≠ zad√°n√≠**  \n",
    "Vytvo≈ôte jednoduch√Ω RAG pipeline, kter√Ω vezme u≈æivatelsk√Ω dotaz a pomoc√≠ vyhled√°v√°n√≠ v dokumentech (retrieval) p≈ôiprav√≠ kontext pro generov√°n√≠ odpovƒõdi (generation). Pou≈æijte klasick√Ω p≈ô√≠stup s embeddingy a FAISS indexem.\n",
    "\n",
    "### 3. **Vstupn√≠ data/po≈æadavky**  \n",
    "- Datab√°ze dokument≈Ø (nap≈ô. kr√°tk√© texty o historii, vƒõdƒõ, atd.)\n",
    "- Dotaz od u≈æivatele (nap≈ô. \"Kdo byl Albert Einstein?\")\n",
    "- Embedding model (nap≈ô. sentence-transformers/all-MiniLM-L6-v2)\n",
    "\n",
    "### 4. **Oƒçek√°van√Ω v√Ωstup**  \n",
    "- Nalezen√© relevantn√≠ dokumenty z datab√°ze\n",
    "- Generovan√° odpovƒõƒè na dotaz, kter√° vyu≈æ√≠v√° kontext z nalezen√Ωch dokument≈Ø\n",
    "\n",
    "### 5. **Hints/N√°povƒõda**  \n",
    "1. Nejprve vytvo≈ôte vektorovou reprezentaci dokument≈Ø pomoc√≠ embedding modelu.\n",
    "2. Pou≈æijte FAISS k indexov√°n√≠ a vyhled√°v√°n√≠ podobn√Ωch dokument≈Ø.\n",
    "3. P≈ôeddejte nejrelevantnƒõj≈°√≠ dokumenty do generativn√≠ho modelu (nap≈ô. LLaMA, GPT-2).\n",
    "4. Spojujte v√Ωstup z retrieval a generation do jedn√© odpovƒõdi.\n",
    "\n",
    "### 6. **Kostra ≈ôe≈°en√≠**  \n",
    "```python\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from faiss import IndexFlatIP\n",
    "import numpy as np\n",
    "\n",
    "# Naƒçti dokumenty\n",
    "documents = [\"...\", \"...\"]  # seznam dokument≈Ø\n",
    "\n",
    "# Vytvo≈ô embeddingy\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "embeddings = model.encode(documents)\n",
    "\n",
    "# Indexuj do FAISS\n",
    "index = IndexFlatIP(384)  # dimenze embeddingu\n",
    "index.add(np.array(embeddings))\n",
    "\n",
    "# Najdi nejbl√≠≈æe dokumenty\n",
    "query = \"Kdo byl Albert Einstein?\"\n",
    "query_embedding = model.encode([query])\n",
    "scores, indices = index.search(query_embedding, k=2)\n",
    "\n",
    "# Vytiskni relevantn√≠ dokumenty a vygeneruj odpovƒõƒè\n",
    "```\n",
    "\n",
    "### 7. **Bonusov√© roz≈°√≠≈ôen√≠**  \n",
    "Implementujte mo≈ænost p≈ôid√°n√≠ ‚Äûprompt engineeringu‚Äú pro lep≈°√≠ generov√°n√≠ odpovƒõdi, nap≈ô. p≈ôed√°vejte do modelu prompt jako:  \n",
    "`\"Odpovƒõz na ot√°zku: {question} pouze z n√°sleduj√≠c√≠ho kontextu: {context}\"`\n",
    "\n",
    "---\n",
    "\n",
    "## 2. **N√°zev √∫kolu**  \n",
    "RAG s vlastn√≠m datov√Ωm setem ‚Äì Inference a vyhodnocen√≠\n",
    "\n",
    "### 2. **Detailn√≠ zad√°n√≠**  \n",
    "Zad√°n√≠: P≈ôipravte testovac√≠ dataset (nap≈ô. 10 ot√°zek a odpovƒõd√≠) a ovƒõ≈ôte, jak dob≈ôe v√°≈° RAG syst√©m odpov√≠d√° na tyto ot√°zky. Implementujte metriku pro vyhodnocen√≠ odpovƒõd√≠ (nap≈ô. ROUGE nebo BLEU).\n",
    "\n",
    "### 3. **Vstupn√≠ data/po≈æadavky**  \n",
    "- Dataset s ot√°zkami a odpovƒõƒèmi (nap≈ô. Q&A z Wikipedie)\n",
    "- Vlastn√≠ RAG pipeline\n",
    "\n",
    "### 4. **Oƒçek√°van√Ω v√Ωstup**  \n",
    "- Vyhodnocen√≠ v√Ωsledk≈Ø (nap≈ô. pr≈Ømƒõrn√° ROUGE sk√≥re)\n",
    "- Seznam ot√°zek + odpovƒõdi + p≈ôesnost\n",
    "\n",
    "### 5. **Hints/N√°povƒõda**  \n",
    "1. Vytvo≈ôte dataset jako seznam slovn√≠k≈Ø `{\"question\": \"...\", \"answer\": \"...\"}`\n",
    "2. Pou≈æijte knihovnu `rouge-score` nebo `nltk.translate.bleu_score`\n",
    "3. Pro ka≈ædou ot√°zku spus≈•te RAG pipeline a porovnejte v√Ωsledky\n",
    "4. Vypi≈°te pr≈Ømƒõrn√© sk√≥re z testovac√≠ho setu\n",
    "\n",
    "### 6. **Kostra ≈ôe≈°en√≠**  \n",
    "```python\n",
    "from rouge_score import rouge_scorer\n",
    "\n",
    "test_dataset = [\n",
    "    {\"question\": \"Kdo byl Newton?\", \"answer\": \"Isaac Newton\"},\n",
    "    ...\n",
    "]\n",
    "\n",
    "scorer = rouge_scorer.RougeScorer(['rouge1'], use_stemmer=True)\n",
    "scores = []\n",
    "\n",
    "for item in test_dataset:\n",
    "    response = rag_pipeline(item[\"question\"])\n",
    "    score = scorer.score(item[\"answer\"], response)\n",
    "    scores.append(score['rouge1'].fmeasure)\n",
    "```\n",
    "\n",
    "### 7. **Bonusov√© roz≈°√≠≈ôen√≠**  \n",
    "P≈ôidejte mo≈ænost logov√°n√≠ v√Ωsledk≈Ø do souboru (nap≈ô. JSON) a vizualizaci pr≈Ømƒõrn√Ωch sk√≥re pomoc√≠ matplotlib.\n",
    "\n",
    "---\n",
    "\n",
    "## 3. **N√°zev √∫kolu**  \n",
    "RAG s dynamick√Ωm vyhled√°v√°n√≠m ‚Äì RAG s filtrac√≠ podle kategorie\n",
    "\n",
    "### 2. **Detailn√≠ zad√°n√≠**  \n",
    "Vytvo≈ôte RAG pipeline, kter√° umo≈æ≈àuje filtrovat dokumenty podle kategorie (nap≈ô. ‚Äûhistorie‚Äú, ‚Äûtechnologie‚Äú) p≈ôed vyhled√°v√°n√≠m a generov√°n√≠m.\n",
    "\n",
    "### 3. **Vstupn√≠ data/po≈æadavky**  \n",
    "- Dokumenty s metadata (nap≈ô. `{\"text\": \"...\", \"category\": \"historie\"}`)\n",
    "- Dotaz od u≈æivatele\n",
    "- Mo≈ænost zadat filtr kategorie\n",
    "\n",
    "### 4. **Oƒçek√°van√Ω v√Ωstup**  \n",
    "- Filtrov√°n√≠ dokument≈Ø podle kategorie\n",
    "- Nalezen√© odpovƒõdi z vybran√©ho podskupinu dokument≈Ø\n",
    "\n",
    "### 5. **Hints/N√°povƒõda**  \n",
    "1. P≈ôidejte metadata do indexu (nap≈ô. pomoc√≠ FAISS s vlastn√≠mi ID).\n",
    "2. P≈ôed vyhled√°v√°n√≠m filtrovat dokumenty podle kategorie.\n",
    "3. Vyu≈æijte nap≈ô. `filter` parametr p≈ôi vyhled√°v√°n√≠.\n",
    "4. V√Ωstup z√°vis√≠ na tom, jak√Ω filtr je zad√°n.\n",
    "\n",
    "### 6. **Kostra ≈ôe≈°en√≠**  \n",
    "```python\n",
    "# P≈ôid√°n√≠ metadata do dokument≈Ø\n",
    "documents_with_metadata = [\n",
    "    {\"text\": \"...\", \"category\": \"historie\"},\n",
    "    ...\n",
    "]\n",
    "\n",
    "# Filtrov√°n√≠ podle kategorie\n",
    "filtered_docs = [doc for doc in documents_with_metadata if doc[\"category\"] == \"historie\"]\n",
    "```\n",
    "\n",
    "### 7. **Bonusov√© roz≈°√≠≈ôen√≠**  \n",
    "Implementujte multi-kategorick√© vyhled√°v√°n√≠ (nap≈ô. hledej dokumenty ve v√≠ce kategori√≠ch).\n",
    "\n",
    "---\n",
    "\n",
    "## 4. **N√°zev √∫kolu**  \n",
    "RAG s vlastn√≠m generativn√≠m modelem ‚Äì Fine-tuning a pou≈æit√≠ LLM\n",
    "\n",
    "### 2. **Detailn√≠ zad√°n√≠**  \n",
    "Pou≈æijte mal√Ω LLM (nap≈ô. GPT-2 nebo Mistral) a p≈ôizp≈Øsobte ho pro generov√°n√≠ odpovƒõd√≠ na z√°kladƒõ kontextu z RAG pipeline. Vyu≈æijte nap≈ô. `transformers` knihovnu.\n",
    "\n",
    "### 3. **Vstupn√≠ data/po≈æadavky**  \n",
    "- RAG pipeline s v√Ωstupem dokument≈Ø\n",
    "- Generativn√≠ model (nap≈ô. `gpt2`, `mistralai/Mistral-7B-v0.1`)\n",
    "- Instrukce pro generov√°n√≠\n",
    "\n",
    "### 4. **Oƒçek√°van√Ω v√Ωstup**  \n",
    "- Nalezen√© dokumenty + odpovƒõƒè vygenerovan√° LLM modelem\n",
    "- Zlep≈°en√° kvalita odpovƒõdi\n",
    "\n",
    "### 5. **Hints/N√°povƒõda**  \n",
    "1. Vytvo≈ôte prompt: ‚ÄûPou≈æij n√°sleduj√≠c√≠ informace: [context] odpovƒõz na ot√°zku: [question].‚Äú\n",
    "2. Pou≈æijte `transformers` k naƒçten√≠ modelu a generov√°n√≠.\n",
    "3. P≈ôedej\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92af89d4",
   "metadata": {},
   "source": [
    "## üìö Dal≈°√≠ zdroje a materi√°ly\n",
    "\n",
    "<div style=\"background: #e3f2fd; padding: 20px; border-left: 5px solid #2196f3; margin: 20px 0; border-radius: 5px;\">\n",
    "    <h3 style=\"color: #2c3e50; margin-top: 0;\">üîó Doporuƒçen√© materi√°ly k dal≈°√≠mu studiu</h3>\n",
    "</div>\n",
    "\n",
    "# Doporuƒçen√© zdroje pro kapitolu: RAG (Retrieval Augmented Generation)\n",
    "\n",
    "---\n",
    "\n",
    "## üìö 5 doporuƒçen√Ωch ƒçl√°nk≈Ø/tutori√°l≈Ø\n",
    "\n",
    "1. **\"Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks\"**  \n",
    "   *Popis:* P≈Øvodn√≠ vƒõdeck√Ω ƒçl√°nek od Google, kter√Ω zav√°d√≠ koncept RAG. Vysvƒõtluje, jak kombinovat retrieval a generativn√≠ modely pro zlep≈°en√≠ p≈ôesnosti odpovƒõd√≠.  \n",
    "   *Odkaz:* [https://arxiv.org/abs/2005.11401](https://arxiv.org/abs/2005.11401)\n",
    "\n",
    "2. **\"A Gentle Introduction to Retrieval-Augmented Generation (RAG)\"**  \n",
    "   *Popis:* Jednoduch√Ω a p≈ôehledn√Ω √∫vod do RAG, vhodn√Ω pro zaƒç√°teƒçn√≠ky. Vysvƒõtluje principy a praktick√© aplikace.  \n",
    "   *Odkaz:* [https://www.pinecone.io/learn/retrieval-augmented-generation/](https://www.pinecone.io/learn/retrieval-augmented-generation/)\n",
    "\n",
    "3. **\"Understanding Retrieval-Augmented Generation (RAG) with Hugging Face Transformers\"**  \n",
    "   *Popis:* Tutori√°l zamƒõ≈ôen√Ω na implementaci RAG pomoc√≠ knihovny Hugging Face, vƒçetnƒõ praktick√©ho k√≥du a p≈ô√≠klad≈Ø.  \n",
    "   *Odkaz:* [https://huggingface.co/blog/retrieval-augmented-generation](https://huggingface.co/blog/retrieval-augmented-generation)\n",
    "\n",
    "4. **\"Building RAG Systems with LangChain and Vector Stores\"**  \n",
    "   *Popis:* Detailn√≠ n√°vod na tvorbu RAG syst√©mu pomoc√≠ LangChain a vektorov√Ωch datab√°z√≠ (nap≈ô. Chroma, FAISS).  \n",
    "   *Odkaz:* [https://docs.langchain.com/docs/](https://docs.langchain.com/docs/)\n",
    "\n",
    "5. **\"RAG Explained: How to Build a Question-Answering System with Transformers\"**  \n",
    "   *Popis:* Praktick√Ω pr≈Øvodce s k√≥dem v Pythonu ‚Äì jak vytvo≈ôit jednoduch√Ω RAG syst√©m od nuly.  \n",
    "   *Odkaz:* [https://towardsdatascience.com/rag-explained-7b82610e6c9c](https://towardsdatascience.com/rag-explained-7b82610e6c9c)\n",
    "\n",
    "---\n",
    "\n",
    "## üé• 3 YouTube videa\n",
    "\n",
    "1. **\"What is Retrieval-Augmented Generation (RAG)? | Explained in 5 Minutes\"**  \n",
    "   *D√©lka:* 5 min  \n",
    "   *Popis:* Struƒçn√Ω v√Ωklad konceptu RAG s ilustrac√≠ principu pr√°ce syst√©mu.\n",
    "\n",
    "2. **\"How to Build a RAG System with Hugging Face Transformers | Full Tutorial\"**  \n",
    "   *D√©lka:* 20 min  \n",
    "   *Popis:* Kompletn√≠ pr≈Øvodce tvorbou RAG syst√©mu pomoc√≠ Hugging Face model≈Ø a Pythonu.\n",
    "\n",
    "3. **\"RAG vs. Traditional LLMs ‚Äì Practical Use Cases & Limitations\"**  \n",
    "   *D√©lka:* 15 min  \n",
    "   *Popis:* Srovn√°n√≠ RAG s bƒõ≈æn√Ωmi generativn√≠mi modely, diskuze o jejich pou≈æit√≠ v praxi.\n",
    "\n",
    "---\n",
    "\n",
    "## üìñ 3 knihy nebo ofici√°ln√≠ dokumentace\n",
    "\n",
    "1. **\"Transformers Book by Hugging Face\"**  \n",
    "   *Popis:* Komplexn√≠ p≈ô√≠ruƒçka k model≈Øm Transformers, vƒçetnƒõ kapitoly o RAG syst√©mech a jejich implementaci.\n",
    "\n",
    "2. **\"LangChain Documentation ‚Äì RAG Guide\"**  \n",
    "   *Popis:* Ofici√°ln√≠ dokumentace pro LangChain s podrobn√Ωmi p≈ô√≠klady pro tvorbu RAG syst√©m≈Ø.\n",
    "\n",
    "3. **\"Deep Learning with Python by Fran√ßois Chollet\" (kapitola o textov√Ωch gener√°torech)**  \n",
    "   *Popis:* P≈ôehled pokroƒçil√Ωch technik zpracov√°n√≠ jazyka, vƒçetnƒõ\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28a4233a",
   "metadata": {},
   "source": [
    "## üìù Shrnut√≠ kapitoly\n",
    "\n",
    "<div style=\"background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); padding: 30px; border-radius: 10px; color: white; margin: 30px 0;\">\n",
    "    <h3 style=\"color: white; margin-top: 0;\">‚úÖ Co jste se nauƒçili</h3>\n",
    "    <ul style=\"list-style: none; padding-left: 0;\">\n",
    "        <li>‚úì RAG architecture</li>\n",
    "<li>‚úì Vector databases: ChromaDB, Pinecone, Weaviate</li>\n",
    "<li>‚úì Embeddings models</li>\n",
    "<li>‚úì Document chunking strategies</li>\n",
    "<li>‚úì Similarity search algorithms</li>\n",
    "    </ul>\n",
    "    \n",
    "    <h3 style=\"color: white;\">üéØ Kl√≠ƒçov√© dovednosti</h3>\n",
    "    <p>Po dokonƒçen√≠ t√©to kapitoly byste mƒõli b√Ωt schopni prakticky pou≈æ√≠t v≈°echny probran√© koncepty.</p>\n",
    "    \n",
    "    <h3 style='color: white;'>‚û°Ô∏è Dal≈°√≠ kapitola</h3><p>Kapitola 36 - pokraƒçujte ve studiu!</p>\n",
    "</div>\n",
    "\n",
    "---\n",
    "\n",
    "*üìÖ Notebook vygenerov√°n: 2025-09-29 13:26:59*  \n",
    "*ü§ñ Gener√°tor: Comprehensive Colab Generator v2.0*  \n",
    "*üìö Uƒçebnice programov√°n√≠ - Od z√°klad≈Ø k AI*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd6993ae",
   "metadata": {},
   "source": [
    "## üß™ Sandbox - Prostor pro experimenty\n",
    "\n",
    "Pou≈æijte n√°sleduj√≠c√≠ bu≈àky pro vlastn√≠ experimenty a testov√°n√≠:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84866f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üß™ Zde m≈Ø≈æete experimentovat s k√≥dem z kapitoly\n",
    "# Napi≈°te sv≈Øj k√≥d zde:\n",
    "\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
