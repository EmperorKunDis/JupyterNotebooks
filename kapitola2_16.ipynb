{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 16. Time Series Analysis s Transformery\n",
    "\n",
    "**Autor:** Praut s.r.o. - AI Integration & Business Automation\n",
    "\n",
    "V tomto notebooku se naučíme používat Transformer modely pro analýzu časových řad - predikci, detekci anomálií a klasifikaci sekvencí.\n",
    "\n",
    "## Obsah\n",
    "1. Úvod do Time Series Transformerů\n",
    "2. Příprava dat pro časové řady\n",
    "3. Predikce časových řad (Forecasting)\n",
    "4. Klasifikace časových řad\n",
    "5. Produkční pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instalace knihoven\n",
    "!pip install transformers accelerate torch pandas numpy scikit-learn matplotlib gluonts pytorch-forecasting -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "from typing import List, Dict, Tuple, Optional\n",
    "from dataclasses import dataclass\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Kontrola GPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Používám zařízení: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Úvod do Time Series Transformerů\n",
    "\n",
    "Transformery pro časové řady využívají attention mechanismus k zachycení dlouhodobých závislostí v datech:\n",
    "\n",
    "| Model | Použití | Výhody |\n",
    "|-------|---------|--------|\n",
    "| Informer | Dlouhodobé predikce | Efektivní attention O(L log L) |\n",
    "| Autoformer | Sezónní data | Auto-correlation mechanism |\n",
    "| TimeSeriesTransformer | Obecné | HuggingFace integrace |\n",
    "| PatchTST | Multivariate | Patch-based tokenizace |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generování syntetických dat pro demonstraci\n",
    "\n",
    "def generate_sales_data(\n",
    "    start_date: str = '2023-01-01',\n",
    "    periods: int = 365,\n",
    "    freq: str = 'D'\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Generuje syntetická data prodejů s trendem, sezónností a šumem.\n",
    "    Simuluje reálné e-commerce prodeje.\n",
    "    \"\"\"\n",
    "    np.random.seed(42)\n",
    "    dates = pd.date_range(start=start_date, periods=periods, freq=freq)\n",
    "    \n",
    "    # Základní trend (růst)\n",
    "    trend = np.linspace(100, 150, periods)\n",
    "    \n",
    "    # Týdenní sezónnost (vyšší prodeje o víkendu)\n",
    "    day_of_week = np.array([d.dayofweek for d in dates])\n",
    "    weekly_pattern = np.where(day_of_week >= 5, 1.3, 1.0)  # Víkend +30%\n",
    "    \n",
    "    # Měsíční sezónnost (vyšší prodeje před svátky)\n",
    "    month = np.array([d.month for d in dates])\n",
    "    monthly_pattern = np.where(np.isin(month, [11, 12]), 1.5, 1.0)  # Vánoce +50%\n",
    "    monthly_pattern = np.where(np.isin(month, [1, 2]), 0.8, monthly_pattern)  # Leden/únor -20%\n",
    "    \n",
    "    # Náhodný šum\n",
    "    noise = np.random.normal(0, 10, periods)\n",
    "    \n",
    "    # Kombinace všech komponent\n",
    "    sales = trend * weekly_pattern * monthly_pattern + noise\n",
    "    sales = np.maximum(sales, 0)  # Prodeje nemohou být záporné\n",
    "    \n",
    "    # Vytvoření DataFrame\n",
    "    df = pd.DataFrame({\n",
    "        'date': dates,\n",
    "        'sales': sales.round(2),\n",
    "        'day_of_week': day_of_week,\n",
    "        'month': month,\n",
    "        'is_weekend': (day_of_week >= 5).astype(int),\n",
    "        'is_holiday_season': np.isin(month, [11, 12]).astype(int)\n",
    "    })\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Generování dat\n",
    "sales_data = generate_sales_data(periods=365*2)  # 2 roky dat\n",
    "print(f\"Vygenerováno {len(sales_data)} záznamů\")\n",
    "print(f\"\\nPrvních 5 řádků:\")\n",
    "print(sales_data.head())\n",
    "\n",
    "# Vizualizace\n",
    "plt.figure(figsize=(14, 5))\n",
    "plt.plot(sales_data['date'], sales_data['sales'], alpha=0.7)\n",
    "plt.title('Syntetická data prodejů')\n",
    "plt.xlabel('Datum')\n",
    "plt.ylabel('Prodeje')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Příprava dat pro časové řady"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class TimeSeriesConfig:\n",
    "    \"\"\"Konfigurace pro zpracování časových řad.\"\"\"\n",
    "    sequence_length: int = 30  # Délka vstupní sekvence (lookback)\n",
    "    prediction_horizon: int = 7  # Kolik kroků predikovat dopředu\n",
    "    stride: int = 1  # Krok mezi sekvencemi\n",
    "    train_ratio: float = 0.7\n",
    "    val_ratio: float = 0.15\n",
    "    test_ratio: float = 0.15\n",
    "    scale_data: bool = True\n",
    "\n",
    "\n",
    "class TimeSeriesPreprocessor:\n",
    "    \"\"\"\n",
    "    Předzpracování časových řad pro Transformer modely.\n",
    "    Vytváří sliding window sekvence pro supervised learning.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, config: TimeSeriesConfig):\n",
    "        self.config = config\n",
    "        self.scaler = StandardScaler() if config.scale_data else None\n",
    "        self.feature_columns = None\n",
    "        \n",
    "    def create_sequences(\n",
    "        self,\n",
    "        data: np.ndarray,\n",
    "        target_idx: int = 0\n",
    "    ) -> Tuple[np.ndarray, np.ndarray]:\n",
    "        \"\"\"\n",
    "        Vytvoří sekvence pro predikci.\n",
    "        \n",
    "        Args:\n",
    "            data: Data tvaru (n_samples, n_features)\n",
    "            target_idx: Index cílové proměnné\n",
    "            \n",
    "        Returns:\n",
    "            X: Vstupní sekvence (n_sequences, seq_length, n_features)\n",
    "            y: Cílové hodnoty (n_sequences, prediction_horizon)\n",
    "        \"\"\"\n",
    "        seq_len = self.config.sequence_length\n",
    "        pred_horizon = self.config.prediction_horizon\n",
    "        stride = self.config.stride\n",
    "        \n",
    "        X, y = [], []\n",
    "        \n",
    "        for i in range(0, len(data) - seq_len - pred_horizon + 1, stride):\n",
    "            # Vstupní sekvence\n",
    "            X.append(data[i:i + seq_len])\n",
    "            # Cílové hodnoty (pouze target proměnná)\n",
    "            y.append(data[i + seq_len:i + seq_len + pred_horizon, target_idx])\n",
    "        \n",
    "        return np.array(X), np.array(y)\n",
    "    \n",
    "    def prepare_data(\n",
    "        self,\n",
    "        df: pd.DataFrame,\n",
    "        target_column: str,\n",
    "        feature_columns: Optional[List[str]] = None\n",
    "    ) -> Dict[str, torch.Tensor]:\n",
    "        \"\"\"\n",
    "        Kompletní příprava dat včetně škálování a rozdělení.\n",
    "        \"\"\"\n",
    "        # Určení feature sloupců\n",
    "        if feature_columns is None:\n",
    "            feature_columns = [target_column]\n",
    "        self.feature_columns = feature_columns\n",
    "        \n",
    "        # Extrakce dat\n",
    "        data = df[feature_columns].values.astype(np.float32)\n",
    "        target_idx = feature_columns.index(target_column)\n",
    "        \n",
    "        # Škálování\n",
    "        if self.scaler:\n",
    "            data = self.scaler.fit_transform(data)\n",
    "        \n",
    "        # Vytvoření sekvencí\n",
    "        X, y = self.create_sequences(data, target_idx)\n",
    "        \n",
    "        # Rozdělení na train/val/test\n",
    "        n_samples = len(X)\n",
    "        train_end = int(n_samples * self.config.train_ratio)\n",
    "        val_end = train_end + int(n_samples * self.config.val_ratio)\n",
    "        \n",
    "        result = {\n",
    "            'X_train': torch.FloatTensor(X[:train_end]),\n",
    "            'y_train': torch.FloatTensor(y[:train_end]),\n",
    "            'X_val': torch.FloatTensor(X[train_end:val_end]),\n",
    "            'y_val': torch.FloatTensor(y[train_end:val_end]),\n",
    "            'X_test': torch.FloatTensor(X[val_end:]),\n",
    "            'y_test': torch.FloatTensor(y[val_end:])\n",
    "        }\n",
    "        \n",
    "        print(f\"Připraveno:\")\n",
    "        print(f\"  Train: {result['X_train'].shape[0]} sekvencí\")\n",
    "        print(f\"  Val: {result['X_val'].shape[0]} sekvencí\")\n",
    "        print(f\"  Test: {result['X_test'].shape[0]} sekvencí\")\n",
    "        print(f\"  Vstupní tvar: {result['X_train'].shape}\")\n",
    "        print(f\"  Výstupní tvar: {result['y_train'].shape}\")\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    def inverse_transform_target(\n",
    "        self,\n",
    "        scaled_values: np.ndarray,\n",
    "        target_idx: int = 0\n",
    "    ) -> np.ndarray:\n",
    "        \"\"\"Převede škálované hodnoty zpět na původní měřítko.\"\"\"\n",
    "        if self.scaler is None:\n",
    "            return scaled_values\n",
    "        \n",
    "        # Vytvoříme dummy array pro inverse transform\n",
    "        n_features = len(self.feature_columns)\n",
    "        dummy = np.zeros((len(scaled_values), n_features))\n",
    "        dummy[:, target_idx] = scaled_values.flatten()\n",
    "        \n",
    "        return self.scaler.inverse_transform(dummy)[:, target_idx]\n",
    "\n",
    "\n",
    "# Použití\n",
    "config = TimeSeriesConfig(\n",
    "    sequence_length=30,\n",
    "    prediction_horizon=7,\n",
    "    stride=1\n",
    ")\n",
    "\n",
    "preprocessor = TimeSeriesPreprocessor(config)\n",
    "prepared_data = preprocessor.prepare_data(\n",
    "    sales_data,\n",
    "    target_column='sales',\n",
    "    feature_columns=['sales', 'day_of_week', 'is_weekend', 'is_holiday_season']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Predikce časových řad (Forecasting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    \"\"\"Pozicové kódování pro Transformer.\"\"\"\n",
    "    \n",
    "    def __init__(self, d_model: int, max_len: int = 5000, dropout: float = 0.1):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        \n",
    "        # Vytvoření pozicového kódování\n",
    "        position = torch.arange(max_len).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2) * (-math.log(10000.0) / d_model))\n",
    "        \n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        \n",
    "        self.register_buffer('pe', pe.unsqueeze(0))\n",
    "    \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"x: Tensor tvaru (batch, seq_len, d_model)\"\"\"\n",
    "        x = x + self.pe[:, :x.size(1)]\n",
    "        return self.dropout(x)\n",
    "\n",
    "\n",
    "class TimeSeriesTransformer(nn.Module):\n",
    "    \"\"\"\n",
    "    Transformer model pro predikci časových řad.\n",
    "    Encoder-only architektura s attention mechanismem.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        n_features: int,\n",
    "        d_model: int = 64,\n",
    "        n_heads: int = 4,\n",
    "        n_layers: int = 2,\n",
    "        d_ff: int = 256,\n",
    "        dropout: float = 0.1,\n",
    "        prediction_horizon: int = 7\n",
    "    ):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.n_features = n_features\n",
    "        self.d_model = d_model\n",
    "        self.prediction_horizon = prediction_horizon\n",
    "        \n",
    "        # Input projection\n",
    "        self.input_projection = nn.Linear(n_features, d_model)\n",
    "        \n",
    "        # Positional encoding\n",
    "        self.positional_encoding = PositionalEncoding(d_model, dropout=dropout)\n",
    "        \n",
    "        # Transformer encoder\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=d_model,\n",
    "            nhead=n_heads,\n",
    "            dim_feedforward=d_ff,\n",
    "            dropout=dropout,\n",
    "            activation='gelu',\n",
    "            batch_first=True\n",
    "        )\n",
    "        self.transformer_encoder = nn.TransformerEncoder(\n",
    "            encoder_layer,\n",
    "            num_layers=n_layers\n",
    "        )\n",
    "        \n",
    "        # Output layers\n",
    "        self.output_projection = nn.Sequential(\n",
    "            nn.Linear(d_model, d_ff),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(d_ff, prediction_horizon)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: Input tensor (batch, seq_len, n_features)\n",
    "            \n",
    "        Returns:\n",
    "            predictions: (batch, prediction_horizon)\n",
    "        \"\"\"\n",
    "        # Project input to d_model dimensions\n",
    "        x = self.input_projection(x)\n",
    "        \n",
    "        # Add positional encoding\n",
    "        x = self.positional_encoding(x)\n",
    "        \n",
    "        # Transformer encoding\n",
    "        x = self.transformer_encoder(x)\n",
    "        \n",
    "        # Use last position for prediction\n",
    "        x = x[:, -1, :]  # (batch, d_model)\n",
    "        \n",
    "        # Project to prediction horizon\n",
    "        predictions = self.output_projection(x)\n",
    "        \n",
    "        return predictions\n",
    "\n",
    "\n",
    "# Vytvoření modelu\n",
    "n_features = prepared_data['X_train'].shape[2]\n",
    "model = TimeSeriesTransformer(\n",
    "    n_features=n_features,\n",
    "    d_model=64,\n",
    "    n_heads=4,\n",
    "    n_layers=2,\n",
    "    prediction_horizon=config.prediction_horizon\n",
    ").to(device)\n",
    "\n",
    "print(f\"Model vytvořen\")\n",
    "print(f\"Počet parametrů: {sum(p.numel() for p in model.parameters()):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "\n",
    "class TimeSeriesTrainer:\n",
    "    \"\"\"\n",
    "    Trainer pro trénování Time Series Transformer modelu.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        model: nn.Module,\n",
    "        device: torch.device,\n",
    "        learning_rate: float = 1e-3,\n",
    "        weight_decay: float = 1e-5\n",
    "    ):\n",
    "        self.model = model\n",
    "        self.device = device\n",
    "        self.optimizer = torch.optim.AdamW(\n",
    "            model.parameters(),\n",
    "            lr=learning_rate,\n",
    "            weight_decay=weight_decay\n",
    "        )\n",
    "        self.scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "            self.optimizer, mode='min', factor=0.5, patience=5\n",
    "        )\n",
    "        self.criterion = nn.MSELoss()\n",
    "        self.history = {'train_loss': [], 'val_loss': []}\n",
    "        \n",
    "    def train_epoch(self, dataloader: DataLoader) -> float:\n",
    "        \"\"\"Trénuje jednu epochu.\"\"\"\n",
    "        self.model.train()\n",
    "        total_loss = 0\n",
    "        \n",
    "        for X_batch, y_batch in dataloader:\n",
    "            X_batch = X_batch.to(self.device)\n",
    "            y_batch = y_batch.to(self.device)\n",
    "            \n",
    "            self.optimizer.zero_grad()\n",
    "            predictions = self.model(X_batch)\n",
    "            loss = self.criterion(predictions, y_batch)\n",
    "            loss.backward()\n",
    "            \n",
    "            # Gradient clipping\n",
    "            torch.nn.utils.clip_grad_norm_(self.model.parameters(), max_norm=1.0)\n",
    "            \n",
    "            self.optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "        \n",
    "        return total_loss / len(dataloader)\n",
    "    \n",
    "    @torch.no_grad()\n",
    "    def evaluate(self, dataloader: DataLoader) -> float:\n",
    "        \"\"\"Evaluuje model na validačních datech.\"\"\"\n",
    "        self.model.eval()\n",
    "        total_loss = 0\n",
    "        \n",
    "        for X_batch, y_batch in dataloader:\n",
    "            X_batch = X_batch.to(self.device)\n",
    "            y_batch = y_batch.to(self.device)\n",
    "            \n",
    "            predictions = self.model(X_batch)\n",
    "            loss = self.criterion(predictions, y_batch)\n",
    "            total_loss += loss.item()\n",
    "        \n",
    "        return total_loss / len(dataloader)\n",
    "    \n",
    "    def train(\n",
    "        self,\n",
    "        train_data: Dict[str, torch.Tensor],\n",
    "        n_epochs: int = 50,\n",
    "        batch_size: int = 32,\n",
    "        early_stopping_patience: int = 10\n",
    "    ) -> Dict:\n",
    "        \"\"\"Kompletní trénování s early stopping.\"\"\"\n",
    "        # Vytvoření DataLoaderů\n",
    "        train_dataset = TensorDataset(train_data['X_train'], train_data['y_train'])\n",
    "        val_dataset = TensorDataset(train_data['X_val'], train_data['y_val'])\n",
    "        \n",
    "        train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "        val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "        \n",
    "        best_val_loss = float('inf')\n",
    "        patience_counter = 0\n",
    "        best_model_state = None\n",
    "        \n",
    "        for epoch in range(n_epochs):\n",
    "            train_loss = self.train_epoch(train_loader)\n",
    "            val_loss = self.evaluate(val_loader)\n",
    "            \n",
    "            self.history['train_loss'].append(train_loss)\n",
    "            self.history['val_loss'].append(val_loss)\n",
    "            \n",
    "            self.scheduler.step(val_loss)\n",
    "            \n",
    "            # Early stopping\n",
    "            if val_loss < best_val_loss:\n",
    "                best_val_loss = val_loss\n",
    "                patience_counter = 0\n",
    "                best_model_state = self.model.state_dict().copy()\n",
    "            else:\n",
    "                patience_counter += 1\n",
    "            \n",
    "            if (epoch + 1) % 10 == 0:\n",
    "                print(f\"Epoch {epoch+1}/{n_epochs} - Train Loss: {train_loss:.6f}, Val Loss: {val_loss:.6f}\")\n",
    "            \n",
    "            if patience_counter >= early_stopping_patience:\n",
    "                print(f\"Early stopping v epoše {epoch+1}\")\n",
    "                break\n",
    "        \n",
    "        # Načtení nejlepšího modelu\n",
    "        if best_model_state:\n",
    "            self.model.load_state_dict(best_model_state)\n",
    "        \n",
    "        return self.history\n",
    "\n",
    "\n",
    "# Trénování\n",
    "trainer = TimeSeriesTrainer(model, device, learning_rate=1e-3)\n",
    "history = trainer.train(prepared_data, n_epochs=100, batch_size=32, early_stopping_patience=15)\n",
    "\n",
    "# Vizualizace loss\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.plot(history['train_loss'], label='Train Loss')\n",
    "plt.plot(history['val_loss'], label='Val Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training History')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluace na testovacích datech\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate_model(\n",
    "    model: nn.Module,\n",
    "    X_test: torch.Tensor,\n",
    "    y_test: torch.Tensor,\n",
    "    preprocessor: TimeSeriesPreprocessor\n",
    ") -> Dict:\n",
    "    \"\"\"Kompletní evaluace modelu s metrikami.\"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    # Predikce\n",
    "    X_test_device = X_test.to(device)\n",
    "    predictions = model(X_test_device).cpu().numpy()\n",
    "    actuals = y_test.numpy()\n",
    "    \n",
    "    # Inverse transform (zpět na původní měřítko)\n",
    "    predictions_original = np.array([\n",
    "        preprocessor.inverse_transform_target(pred) for pred in predictions\n",
    "    ])\n",
    "    actuals_original = np.array([\n",
    "        preprocessor.inverse_transform_target(act) for act in actuals\n",
    "    ])\n",
    "    \n",
    "    # Metriky\n",
    "    mae = mean_absolute_error(actuals_original.flatten(), predictions_original.flatten())\n",
    "    mse = mean_squared_error(actuals_original.flatten(), predictions_original.flatten())\n",
    "    rmse = np.sqrt(mse)\n",
    "    \n",
    "    # MAPE (Mean Absolute Percentage Error)\n",
    "    mape = np.mean(np.abs((actuals_original - predictions_original) / (actuals_original + 1e-8))) * 100\n",
    "    \n",
    "    results = {\n",
    "        'MAE': mae,\n",
    "        'MSE': mse,\n",
    "        'RMSE': rmse,\n",
    "        'MAPE': mape,\n",
    "        'predictions': predictions_original,\n",
    "        'actuals': actuals_original\n",
    "    }\n",
    "    \n",
    "    print(f\"Výsledky evaluace:\")\n",
    "    print(f\"  MAE: {mae:.2f}\")\n",
    "    print(f\"  RMSE: {rmse:.2f}\")\n",
    "    print(f\"  MAPE: {mape:.2f}%\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "# Evaluace\n",
    "results = evaluate_model(\n",
    "    model,\n",
    "    prepared_data['X_test'],\n",
    "    prepared_data['y_test'],\n",
    "    preprocessor\n",
    ")\n",
    "\n",
    "# Vizualizace predikcí\n",
    "plt.figure(figsize=(14, 5))\n",
    "\n",
    "# Zobrazení několika predikcí\n",
    "n_show = 5\n",
    "for i in range(n_show):\n",
    "    idx = i * 20\n",
    "    if idx < len(results['predictions']):\n",
    "        x = range(idx, idx + config.prediction_horizon)\n",
    "        plt.plot(x, results['actuals'][idx], 'b-', alpha=0.5, label='Skutečnost' if i == 0 else '')\n",
    "        plt.plot(x, results['predictions'][idx], 'r--', alpha=0.5, label='Predikce' if i == 0 else '')\n",
    "\n",
    "plt.xlabel('Čas')\n",
    "plt.ylabel('Prodeje')\n",
    "plt.title('Porovnání predikcí vs skutečnost')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Klasifikace časových řad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_activity_data(n_samples: int = 1000, seq_length: int = 100) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Generuje syntetická data aktivit (chůze, běh, stání).\n",
    "    Simuluje data z akcelerometru.\n",
    "    \"\"\"\n",
    "    np.random.seed(42)\n",
    "    \n",
    "    X = []\n",
    "    y = []\n",
    "    \n",
    "    for _ in range(n_samples):\n",
    "        activity = np.random.choice([0, 1, 2])  # 0=stání, 1=chůze, 2=běh\n",
    "        \n",
    "        if activity == 0:  # Stání - nízká variance\n",
    "            x = np.random.normal(0, 0.1, (seq_length, 3))\n",
    "        elif activity == 1:  # Chůze - střední variance, periodická\n",
    "            t = np.linspace(0, 4*np.pi, seq_length)\n",
    "            x = np.column_stack([\n",
    "                0.5 * np.sin(t) + np.random.normal(0, 0.2, seq_length),\n",
    "                0.3 * np.cos(t) + np.random.normal(0, 0.2, seq_length),\n",
    "                0.2 * np.sin(2*t) + np.random.normal(0, 0.1, seq_length)\n",
    "            ])\n",
    "        else:  # Běh - vysoká variance, rychlejší periodicita\n",
    "            t = np.linspace(0, 8*np.pi, seq_length)\n",
    "            x = np.column_stack([\n",
    "                1.0 * np.sin(t) + np.random.normal(0, 0.4, seq_length),\n",
    "                0.6 * np.cos(t) + np.random.normal(0, 0.3, seq_length),\n",
    "                0.5 * np.sin(2*t) + np.random.normal(0, 0.2, seq_length)\n",
    "            ])\n",
    "        \n",
    "        X.append(x)\n",
    "        y.append(activity)\n",
    "    \n",
    "    return np.array(X, dtype=np.float32), np.array(y)\n",
    "\n",
    "\n",
    "class TimeSeriesClassifier(nn.Module):\n",
    "    \"\"\"\n",
    "    Transformer model pro klasifikaci časových řad.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        n_features: int,\n",
    "        n_classes: int,\n",
    "        d_model: int = 64,\n",
    "        n_heads: int = 4,\n",
    "        n_layers: int = 2,\n",
    "        dropout: float = 0.1\n",
    "    ):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.input_projection = nn.Linear(n_features, d_model)\n",
    "        self.positional_encoding = PositionalEncoding(d_model, dropout=dropout)\n",
    "        \n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=d_model,\n",
    "            nhead=n_heads,\n",
    "            dim_feedforward=d_model * 4,\n",
    "            dropout=dropout,\n",
    "            activation='gelu',\n",
    "            batch_first=True\n",
    "        )\n",
    "        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=n_layers)\n",
    "        \n",
    "        # Global average pooling + classification head\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(d_model, d_model),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(d_model, n_classes)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        # Input projection\n",
    "        x = self.input_projection(x)\n",
    "        x = self.positional_encoding(x)\n",
    "        \n",
    "        # Transformer\n",
    "        x = self.transformer(x)\n",
    "        \n",
    "        # Global average pooling\n",
    "        x = x.mean(dim=1)\n",
    "        \n",
    "        # Classification\n",
    "        return self.classifier(x)\n",
    "\n",
    "\n",
    "# Generování dat\n",
    "X_activity, y_activity = generate_activity_data(n_samples=1000, seq_length=100)\n",
    "print(f\"Data aktivit: {X_activity.shape}\")\n",
    "print(f\"Distribuce tříd: {np.bincount(y_activity)}\")\n",
    "\n",
    "# Rozdělení dat\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_activity, y_activity, test_size=0.2, random_state=42, stratify=y_activity\n",
    ")\n",
    "\n",
    "# Konverze na tensory\n",
    "X_train_t = torch.FloatTensor(X_train)\n",
    "y_train_t = torch.LongTensor(y_train)\n",
    "X_test_t = torch.FloatTensor(X_test)\n",
    "y_test_t = torch.LongTensor(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trénování klasifikátoru\n",
    "\n",
    "classifier = TimeSeriesClassifier(\n",
    "    n_features=3,\n",
    "    n_classes=3,\n",
    "    d_model=64,\n",
    "    n_heads=4,\n",
    "    n_layers=2\n",
    ").to(device)\n",
    "\n",
    "optimizer = torch.optim.AdamW(classifier.parameters(), lr=1e-3)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "train_dataset = TensorDataset(X_train_t, y_train_t)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "# Training loop\n",
    "n_epochs = 30\n",
    "for epoch in range(n_epochs):\n",
    "    classifier.train()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for X_batch, y_batch in train_loader:\n",
    "        X_batch = X_batch.to(device)\n",
    "        y_batch = y_batch.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = classifier(X_batch)\n",
    "        loss = criterion(outputs, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        correct += (predicted == y_batch).sum().item()\n",
    "        total += y_batch.size(0)\n",
    "    \n",
    "    if (epoch + 1) % 5 == 0:\n",
    "        acc = 100 * correct / total\n",
    "        print(f\"Epoch {epoch+1}/{n_epochs} - Loss: {total_loss/len(train_loader):.4f}, Acc: {acc:.1f}%\")\n",
    "\n",
    "# Evaluace\n",
    "classifier.eval()\n",
    "with torch.no_grad():\n",
    "    X_test_device = X_test_t.to(device)\n",
    "    outputs = classifier(X_test_device)\n",
    "    _, predicted = outputs.max(1)\n",
    "    \n",
    "    accuracy = (predicted.cpu() == y_test_t).float().mean().item() * 100\n",
    "    print(f\"\\nTest Accuracy: {accuracy:.1f}%\")\n",
    "\n",
    "# Confusion matrix\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "y_pred = predicted.cpu().numpy()\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(\n",
    "    y_test, y_pred,\n",
    "    target_names=['Stání', 'Chůze', 'Běh']\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Produkční pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import json\n",
    "\n",
    "\n",
    "class ProductionTimeSeriesForecaster:\n",
    "    \"\"\"\n",
    "    Produkční pipeline pro predikci časových řad.\n",
    "    Zahrnuje předzpracování, predikci a post-processing.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        model: nn.Module,\n",
    "        preprocessor: TimeSeriesPreprocessor,\n",
    "        device: torch.device\n",
    "    ):\n",
    "        self.model = model\n",
    "        self.preprocessor = preprocessor\n",
    "        self.device = device\n",
    "        self.model.eval()\n",
    "        \n",
    "        # Statistiky\n",
    "        self.prediction_count = 0\n",
    "        self.prediction_history = []\n",
    "        \n",
    "    @torch.no_grad()\n",
    "    def predict(\n",
    "        self,\n",
    "        recent_data: pd.DataFrame,\n",
    "        target_column: str,\n",
    "        feature_columns: Optional[List[str]] = None,\n",
    "        return_confidence: bool = True\n",
    "    ) -> Dict:\n",
    "        \"\"\"\n",
    "        Vytvoří predikci na základě nejnovějších dat.\n",
    "        \n",
    "        Args:\n",
    "            recent_data: DataFrame s nejnovějšími daty\n",
    "            target_column: Název cílového sloupce\n",
    "            feature_columns: Seznam feature sloupců\n",
    "            return_confidence: Zda vrátit odhad spolehlivosti\n",
    "        \"\"\"\n",
    "        if feature_columns is None:\n",
    "            feature_columns = self.preprocessor.feature_columns\n",
    "        \n",
    "        # Kontrola délky dat\n",
    "        seq_len = self.preprocessor.config.sequence_length\n",
    "        if len(recent_data) < seq_len:\n",
    "            raise ValueError(f\"Potřeba alespoň {seq_len} záznamů, poskytnuto {len(recent_data)}\")\n",
    "        \n",
    "        # Příprava dat\n",
    "        data = recent_data[feature_columns].tail(seq_len).values.astype(np.float32)\n",
    "        \n",
    "        # Škálování\n",
    "        if self.preprocessor.scaler:\n",
    "            data = self.preprocessor.scaler.transform(data)\n",
    "        \n",
    "        # Predikce\n",
    "        X = torch.FloatTensor(data).unsqueeze(0).to(self.device)\n",
    "        predictions_scaled = self.model(X).cpu().numpy()[0]\n",
    "        \n",
    "        # Inverse transform\n",
    "        target_idx = feature_columns.index(target_column)\n",
    "        predictions = self.preprocessor.inverse_transform_target(\n",
    "            predictions_scaled, target_idx\n",
    "        )\n",
    "        \n",
    "        # Vytvoření datumů pro predikce\n",
    "        last_date = recent_data['date'].iloc[-1]\n",
    "        prediction_dates = pd.date_range(\n",
    "            start=last_date + timedelta(days=1),\n",
    "            periods=len(predictions),\n",
    "            freq='D'\n",
    "        )\n",
    "        \n",
    "        result = {\n",
    "            'predictions': predictions.tolist(),\n",
    "            'dates': prediction_dates.strftime('%Y-%m-%d').tolist(),\n",
    "            'timestamp': datetime.now().isoformat(),\n",
    "            'model_type': 'TimeSeriesTransformer'\n",
    "        }\n",
    "        \n",
    "        # Odhad spolehlivosti na základě variance v historických datech\n",
    "        if return_confidence:\n",
    "            historical_std = recent_data[target_column].std()\n",
    "            result['confidence_interval'] = {\n",
    "                'lower': (predictions - 1.96 * historical_std).tolist(),\n",
    "                'upper': (predictions + 1.96 * historical_std).tolist()\n",
    "            }\n",
    "        \n",
    "        # Uložení do historie\n",
    "        self.prediction_count += 1\n",
    "        self.prediction_history.append({\n",
    "            'timestamp': result['timestamp'],\n",
    "            'predictions': result['predictions']\n",
    "        })\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    def get_statistics(self) -> Dict:\n",
    "        \"\"\"Vrátí statistiky použití.\"\"\"\n",
    "        return {\n",
    "            'total_predictions': self.prediction_count,\n",
    "            'prediction_horizon': self.preprocessor.config.prediction_horizon,\n",
    "            'sequence_length': self.preprocessor.config.sequence_length,\n",
    "            'features_used': self.preprocessor.feature_columns\n",
    "        }\n",
    "    \n",
    "    def save_model(self, path: str):\n",
    "        \"\"\"Uloží model a preprocessor.\"\"\"\n",
    "        torch.save({\n",
    "            'model_state_dict': self.model.state_dict(),\n",
    "            'scaler': self.preprocessor.scaler,\n",
    "            'config': self.preprocessor.config,\n",
    "            'feature_columns': self.preprocessor.feature_columns\n",
    "        }, path)\n",
    "        print(f\"Model uložen do: {path}\")\n",
    "\n",
    "\n",
    "# Použití produkční pipeline\n",
    "forecaster = ProductionTimeSeriesForecaster(model, preprocessor, device)\n",
    "\n",
    "# Simulace real-time predikce\n",
    "recent_data = sales_data.tail(60)  # Poslední 2 měsíce\n",
    "\n",
    "prediction_result = forecaster.predict(\n",
    "    recent_data,\n",
    "    target_column='sales',\n",
    "    feature_columns=['sales', 'day_of_week', 'is_weekend', 'is_holiday_season']\n",
    ")\n",
    "\n",
    "print(\"Predikce prodejů na příštích 7 dní:\")\n",
    "for date, pred, lower, upper in zip(\n",
    "    prediction_result['dates'],\n",
    "    prediction_result['predictions'],\n",
    "    prediction_result['confidence_interval']['lower'],\n",
    "    prediction_result['confidence_interval']['upper']\n",
    "):\n",
    "    print(f\"  {date}: {pred:.1f} (95% CI: {lower:.1f} - {upper:.1f})\")\n",
    "\n",
    "print(f\"\\nStatistiky: {forecaster.get_statistics()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vizualizace predikcí s confidence intervals\n",
    "\n",
    "plt.figure(figsize=(14, 6))\n",
    "\n",
    "# Historická data\n",
    "plt.plot(\n",
    "    recent_data['date'].values[-30:],\n",
    "    recent_data['sales'].values[-30:],\n",
    "    'b-',\n",
    "    label='Historická data',\n",
    "    linewidth=2\n",
    ")\n",
    "\n",
    "# Predikce\n",
    "pred_dates = pd.to_datetime(prediction_result['dates'])\n",
    "predictions = prediction_result['predictions']\n",
    "lower = prediction_result['confidence_interval']['lower']\n",
    "upper = prediction_result['confidence_interval']['upper']\n",
    "\n",
    "plt.plot(pred_dates, predictions, 'r-', label='Predikce', linewidth=2)\n",
    "plt.fill_between(pred_dates, lower, upper, alpha=0.3, color='red', label='95% CI')\n",
    "\n",
    "plt.xlabel('Datum')\n",
    "plt.ylabel('Prodeje')\n",
    "plt.title('Predikce prodejů s confidence intervaly')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shrnutí\n",
    "\n",
    "V tomto notebooku jsme se naučili:\n",
    "\n",
    "1. **Příprava dat** - Vytváření sliding window sekvencí pro supervised learning\n",
    "2. **Time Series Transformer** - Encoder-only architektura s attention pro predikci\n",
    "3. **Klasifikace sekvencí** - Rozpoznávání vzorů v časových řadách\n",
    "4. **Produkční pipeline** - Real-time predikce s confidence intervaly\n",
    "\n",
    "### Klíčové poznatky\n",
    "\n",
    "- Transformery excellují v zachycení dlouhodobých závislostí díky attention\n",
    "- Správná normalizace dat je kritická pro stabilní trénování\n",
    "- Prediction horizon volíme podle business požadavků (kratší = přesnější)\n",
    "- Confidence intervaly pomáhají s rozhodováním v nejistých situacích\n",
    "\n",
    "### Praktické tipy\n",
    "\n",
    "- Pro kratší sekvence (<100) stačí menší modely (d_model=64, n_layers=2)\n",
    "- Multivariate features výrazně zlepšují predikce\n",
    "- Sezónnost a trendy jsou dobré explicitně zakódovat jako features\n",
    "- Regularizace (dropout, weight decay) prevence overfittingu"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  },
  "colab": {
   "provenance": [],
   "gpuType": "T4"
  },
  "accelerator": "GPU"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
