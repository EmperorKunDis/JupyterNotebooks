{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üé® Notebook 10: Segmentace Obr√°zk≈Ø\n",
    "\n",
    "**Autor:** Praut s.r.o. - AI Integration & Business Automation\n",
    "\n",
    "V tomto notebooku se nauƒç√≠me pou≈æ√≠vat modely pro segmentaci obr√°zk≈Ø - od s√©mantick√© segmentace a≈æ po instance segmentation. Uk√°≈æeme si praktick√© aplikace jako odstranƒõn√≠ pozad√≠, segmentaci produkt≈Ø a automatickou editaci.\n",
    "\n",
    "## Co se nauƒç√≠te:\n",
    "- S√©mantick√° segmentace s SegFormer\n",
    "- Instance segmentation s Mask2Former\n",
    "- Panoptick√° segmentace\n",
    "- Odstranƒõn√≠ pozad√≠ (background removal)\n",
    "- Praktick√© automatizace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instalace pot≈ôebn√Ωch knihoven\n",
    "!pip install -q transformers accelerate torch torchvision pillow requests matplotlib scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import pipeline\n",
    "from transformers import SegformerImageProcessor, SegformerForSemanticSegmentation\n",
    "from transformers import AutoImageProcessor, Mask2FormerForUniversalSegmentation\n",
    "from PIL import Image\n",
    "import requests\n",
    "from io import BytesIO\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import numpy as np\n",
    "from scipy import ndimage\n",
    "\n",
    "# Detekce za≈ô√≠zen√≠\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Pou≈æ√≠v√°m za≈ô√≠zen√≠: {device}\")\n",
    "if device == \"cuda\":\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Pomocn√© funkce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(source):\n",
    "    \"\"\"Naƒçte obr√°zek z URL nebo lok√°ln√≠ cesty.\"\"\"\n",
    "    if source.startswith('http'):\n",
    "        response = requests.get(source, timeout=10)\n",
    "        image = Image.open(BytesIO(response.content))\n",
    "    else:\n",
    "        image = Image.open(source)\n",
    "    \n",
    "    if image.mode != 'RGB':\n",
    "        image = image.convert('RGB')\n",
    "    return image\n",
    "\n",
    "# Barevn√° paleta pro segmentaci\n",
    "def create_color_palette(num_classes):\n",
    "    \"\"\"Vytvo≈ô√≠ barevnou paletu pro vizualizaci.\"\"\"\n",
    "    np.random.seed(42)\n",
    "    palette = np.random.randint(0, 255, size=(num_classes, 3), dtype=np.uint8)\n",
    "    palette[0] = [0, 0, 0]  # Pozad√≠ ƒçern√©\n",
    "    return palette\n",
    "\n",
    "def visualize_segmentation(image, segmentation_map, labels=None, alpha=0.5):\n",
    "    \"\"\"\n",
    "    Vizualizuje segmentaƒçn√≠ masku p≈ôes obr√°zek.\n",
    "    \"\"\"\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "    \n",
    "    # Origin√°l\n",
    "    axes[0].imshow(image)\n",
    "    axes[0].set_title('Origin√°l')\n",
    "    axes[0].axis('off')\n",
    "    \n",
    "    # Segmentaƒçn√≠ maska\n",
    "    num_classes = int(segmentation_map.max()) + 1\n",
    "    palette = create_color_palette(num_classes)\n",
    "    colored_mask = palette[segmentation_map]\n",
    "    \n",
    "    axes[1].imshow(colored_mask)\n",
    "    axes[1].set_title('Segmentaƒçn√≠ maska')\n",
    "    axes[1].axis('off')\n",
    "    \n",
    "    # Overlay\n",
    "    overlay = np.array(image.resize((segmentation_map.shape[1], segmentation_map.shape[0])))\n",
    "    overlay = (overlay * (1 - alpha) + colored_mask * alpha).astype(np.uint8)\n",
    "    \n",
    "    axes[2].imshow(overlay)\n",
    "    axes[2].set_title('P≈ôekryv')\n",
    "    axes[2].axis('off')\n",
    "    \n",
    "    # Legenda\n",
    "    if labels:\n",
    "        unique_classes = np.unique(segmentation_map)\n",
    "        patches_list = []\n",
    "        for cls in unique_classes:\n",
    "            if cls < len(labels):\n",
    "                color = palette[cls] / 255.0\n",
    "                patches_list.append(mpatches.Patch(color=color, label=labels[cls]))\n",
    "        if patches_list:\n",
    "            fig.legend(handles=patches_list, loc='center right', bbox_to_anchor=(1.15, 0.5))\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "print(\"‚úÖ Pomocn√© funkce p≈ôipraveny\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. S√©mantick√° segmentace s SegFormer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naƒçten√≠ SegFormer modelu (ADE20K dataset - 150 t≈ô√≠d)\n",
    "segformer_processor = SegformerImageProcessor.from_pretrained(\"nvidia/segformer-b0-finetuned-ade-512-512\")\n",
    "segformer_model = SegformerForSemanticSegmentation.from_pretrained(\"nvidia/segformer-b0-finetuned-ade-512-512\")\n",
    "\n",
    "if device == \"cuda\":\n",
    "    segformer_model = segformer_model.to(device)\n",
    "\n",
    "# ADE20K labels (prvn√≠ch 20)\n",
    "ADE20K_LABELS = [\n",
    "    'wall', 'building', 'sky', 'floor', 'tree', 'ceiling', 'road', 'bed',\n",
    "    'windowpane', 'grass', 'cabinet', 'sidewalk', 'person', 'earth',\n",
    "    'door', 'table', 'mountain', 'plant', 'curtain', 'chair', 'car',\n",
    "    'water', 'painting', 'sofa', 'shelf', 'house', 'sea', 'mirror',\n",
    "    'rug', 'field', 'armchair', 'seat', 'fence', 'desk', 'rock',\n",
    "    'wardrobe', 'lamp', 'bathtub', 'railing', 'cushion', 'base',\n",
    "    'box', 'column', 'signboard', 'chest of drawers', 'counter',\n",
    "    'sand', 'sink', 'skyscraper', 'fireplace'\n",
    "]\n",
    "\n",
    "print(\"‚úÖ SegFormer model naƒçten\")\n",
    "print(f\"   Poƒçet t≈ô√≠d: {segformer_model.config.num_labels}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def segment_image_segformer(image):\n",
    "    \"\"\"\n",
    "    Provede s√©mantickou segmentaci pomoc√≠ SegFormer.\n",
    "    \"\"\"\n",
    "    if isinstance(image, str):\n",
    "        image = load_image(image)\n",
    "    \n",
    "    # P≈ô√≠prava vstupu\n",
    "    inputs = segformer_processor(images=image, return_tensors=\"pt\")\n",
    "    if device == \"cuda\":\n",
    "        inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "    \n",
    "    # Inference\n",
    "    with torch.no_grad():\n",
    "        outputs = segformer_model(**inputs)\n",
    "    \n",
    "    # Post-processing\n",
    "    logits = outputs.logits\n",
    "    \n",
    "    # Upsampling na p≈Øvodn√≠ velikost\n",
    "    upsampled_logits = torch.nn.functional.interpolate(\n",
    "        logits,\n",
    "        size=image.size[::-1],\n",
    "        mode='bilinear',\n",
    "        align_corners=False\n",
    "    )\n",
    "    \n",
    "    # Argmax pro z√≠sk√°n√≠ t≈ô√≠d\n",
    "    segmentation = upsampled_logits.argmax(dim=1)[0].cpu().numpy()\n",
    "    \n",
    "    return segmentation\n",
    "\n",
    "# Test\n",
    "test_url = \"https://upload.wikimedia.org/wikipedia/commons/thumb/4/47/PNG_transparency_demonstration_1.png/300px-PNG_transparency_demonstration_1.png\"\n",
    "room_url = \"https://upload.wikimedia.org/wikipedia/commons/thumb/0/0c/GoldenGateBridge-001.jpg/1280px-GoldenGateBridge-001.jpg\"\n",
    "\n",
    "try:\n",
    "    image = load_image(room_url)\n",
    "    segmentation = segment_image_segformer(image)\n",
    "    \n",
    "    print(f\"Velikost segmentace: {segmentation.shape}\")\n",
    "    print(f\"Unik√°tn√≠ t≈ô√≠dy: {np.unique(segmentation)}\")\n",
    "    \n",
    "    visualize_segmentation(image, segmentation, ADE20K_LABELS)\n",
    "except Exception as e:\n",
    "    print(f\"Chyba: {e}\")\n",
    "    # Z√°lo≈æn√≠ test\n",
    "    cat_url = \"https://upload.wikimedia.org/wikipedia/commons/thumb/4/4d/Cat_November_2010-1a.jpg/1200px-Cat_November_2010-1a.jpg\"\n",
    "    image = load_image(cat_url)\n",
    "    segmentation = segment_image_segformer(image)\n",
    "    visualize_segmentation(image, segmentation, ADE20K_LABELS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Pipeline API pro segmentaci"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jednodu≈°≈°√≠ p≈ô√≠stup pomoc√≠ pipeline\n",
    "segmenter = pipeline(\n",
    "    \"image-segmentation\",\n",
    "    model=\"nvidia/segformer-b0-finetuned-ade-512-512\",\n",
    "    device=0 if device == \"cuda\" else -1\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Segmentation pipeline p≈ôipraven\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test pipeline\n",
    "cat_url = \"https://upload.wikimedia.org/wikipedia/commons/thumb/4/4d/Cat_November_2010-1a.jpg/1200px-Cat_November_2010-1a.jpg\"\n",
    "image = load_image(cat_url)\n",
    "\n",
    "results = segmenter(image)\n",
    "\n",
    "print(f\"Nalezeno {len(results)} segment≈Ø:\")\n",
    "for r in results[:10]:  # Prvn√≠ch 10\n",
    "    if r['score'] is not None:\n",
    "        print(f\"  - {r['label']}: {r['score']:.1%}\")\n",
    "    else:\n",
    "        print(f\"  - {r['label']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Odstranƒõn√≠ pozad√≠ (Background Removal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BackgroundRemover:\n",
    "    \"\"\"\n",
    "    T≈ô√≠da pro odstranƒõn√≠ pozad√≠ z obr√°zk≈Ø.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        # Pou≈æijeme segmentaci pro detekci objekt≈Ø\n",
    "        self.segmenter = segmenter\n",
    "        \n",
    "        # T≈ô√≠dy, kter√© chceme zachovat (pop≈ôed√≠)\n",
    "        self.foreground_classes = [\n",
    "            'person', 'cat', 'dog', 'car', 'bird', 'horse', 'sheep', 'cow',\n",
    "            'elephant', 'bear', 'zebra', 'giraffe', 'chair', 'couch', 'bed',\n",
    "            'dining table', 'toilet', 'tv', 'laptop', 'cell phone', 'book',\n",
    "            'bottle', 'cup', 'plant'\n",
    "        ]\n",
    "    \n",
    "    def remove_background(self, image, target_class=None, background_color=(255, 255, 255)):\n",
    "        \"\"\"\n",
    "        Odstran√≠ pozad√≠ z obr√°zku.\n",
    "        \n",
    "        Args:\n",
    "            image: Obr√°zek nebo URL\n",
    "            target_class: Konkr√©tn√≠ t≈ô√≠da k zachov√°n√≠ (None = v≈°echny pop≈ôed√≠)\n",
    "            background_color: Barva nov√©ho pozad√≠ (RGB) nebo None pro pr≈Øhlednost\n",
    "        \"\"\"\n",
    "        if isinstance(image, str):\n",
    "            image = load_image(image)\n",
    "        \n",
    "        # Segmentace\n",
    "        results = self.segmenter(image)\n",
    "        \n",
    "        # Vytvo≈ôen√≠ masky\n",
    "        mask = np.zeros((image.size[1], image.size[0]), dtype=np.uint8)\n",
    "        \n",
    "        for segment in results:\n",
    "            label = segment['label'].lower()\n",
    "            segment_mask = np.array(segment['mask'])\n",
    "            \n",
    "            # Filtrov√°n√≠ podle t≈ô√≠dy\n",
    "            if target_class:\n",
    "                if label == target_class.lower():\n",
    "                    mask = np.maximum(mask, segment_mask)\n",
    "            else:\n",
    "                # Zachovat v≈°echny pop≈ôed√≠ t≈ô√≠dy\n",
    "                for fg_class in self.foreground_classes:\n",
    "                    if fg_class in label:\n",
    "                        mask = np.maximum(mask, segment_mask)\n",
    "                        break\n",
    "        \n",
    "        # Aplikace masky\n",
    "        image_array = np.array(image)\n",
    "        \n",
    "        if background_color is None:\n",
    "            # Pr≈Øhledn√© pozad√≠ (RGBA)\n",
    "            result = np.zeros((image.size[1], image.size[0], 4), dtype=np.uint8)\n",
    "            result[:, :, :3] = image_array\n",
    "            result[:, :, 3] = mask * 255\n",
    "            return Image.fromarray(result, 'RGBA')\n",
    "        else:\n",
    "            # Barevn√© pozad√≠\n",
    "            result = np.array([\n",
    "                [background_color if m == 0 else tuple(p) \n",
    "                 for m, p in zip(mask_row, image_row)]\n",
    "                for mask_row, image_row in zip(mask, image_array)\n",
    "            ], dtype=np.uint8)\n",
    "            return Image.fromarray(result)\n",
    "    \n",
    "    def get_mask(self, image, target_class=None):\n",
    "        \"\"\"\n",
    "        Vr√°t√≠ pouze masku bez aplikace.\n",
    "        \"\"\"\n",
    "        if isinstance(image, str):\n",
    "            image = load_image(image)\n",
    "        \n",
    "        results = self.segmenter(image)\n",
    "        mask = np.zeros((image.size[1], image.size[0]), dtype=np.uint8)\n",
    "        \n",
    "        for segment in results:\n",
    "            label = segment['label'].lower()\n",
    "            segment_mask = np.array(segment['mask'])\n",
    "            \n",
    "            if target_class:\n",
    "                if label == target_class.lower():\n",
    "                    mask = np.maximum(mask, segment_mask)\n",
    "            else:\n",
    "                for fg_class in self.foreground_classes:\n",
    "                    if fg_class in label:\n",
    "                        mask = np.maximum(mask, segment_mask)\n",
    "                        break\n",
    "        \n",
    "        return mask\n",
    "\n",
    "# Test\n",
    "bg_remover = BackgroundRemover()\n",
    "print(\"‚úÖ BackgroundRemover p≈ôipraven\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test odstranƒõn√≠ pozad√≠\n",
    "try:\n",
    "    mask = bg_remover.get_mask(image)\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "    \n",
    "    axes[0].imshow(image)\n",
    "    axes[0].set_title('Origin√°l')\n",
    "    axes[0].axis('off')\n",
    "    \n",
    "    axes[1].imshow(mask, cmap='gray')\n",
    "    axes[1].set_title('Maska')\n",
    "    axes[1].axis('off')\n",
    "    \n",
    "    # Aplikace masky\n",
    "    masked = np.array(image) * np.expand_dims(mask, -1)\n",
    "    axes[2].imshow(masked)\n",
    "    axes[2].set_title('S odstranƒõn√Ωm pozad√≠m')\n",
    "    axes[2].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "except Exception as e:\n",
    "    print(f\"Chyba p≈ôi odstranƒõn√≠ pozad√≠: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Instance Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instance segmentation pipeline\n",
    "instance_segmenter = pipeline(\n",
    "    \"image-segmentation\",\n",
    "    model=\"facebook/mask2former-swin-base-coco-instance\",\n",
    "    device=0 if device == \"cuda\" else -1\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Instance segmentation pipeline p≈ôipraven\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_instances(image, segments):\n",
    "    \"\"\"\n",
    "    Vizualizuje jednotliv√© instance.\n",
    "    \"\"\"\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 7))\n",
    "    \n",
    "    # Origin√°l\n",
    "    axes[0].imshow(image)\n",
    "    axes[0].set_title('Origin√°l')\n",
    "    axes[0].axis('off')\n",
    "    \n",
    "    # Instance\n",
    "    overlay = np.array(image).copy().astype(float)\n",
    "    \n",
    "    colors = plt.cm.tab20(np.linspace(0, 1, len(segments)))\n",
    "    legend_patches = []\n",
    "    \n",
    "    for i, segment in enumerate(segments):\n",
    "        mask = np.array(segment['mask'])\n",
    "        color = colors[i][:3]\n",
    "        \n",
    "        # Aplikace barvy na masku\n",
    "        for c in range(3):\n",
    "            overlay[:, :, c] = np.where(\n",
    "                mask > 0,\n",
    "                overlay[:, :, c] * 0.5 + color[c] * 255 * 0.5,\n",
    "                overlay[:, :, c]\n",
    "            )\n",
    "        \n",
    "        # Legenda\n",
    "        score = segment.get('score', None)\n",
    "        label = segment['label']\n",
    "        if score:\n",
    "            legend_patches.append(mpatches.Patch(color=color, label=f\"{label}: {score:.1%}\"))\n",
    "        else:\n",
    "            legend_patches.append(mpatches.Patch(color=color, label=label))\n",
    "    \n",
    "    axes[1].imshow(overlay.astype(np.uint8))\n",
    "    axes[1].set_title('Instance Segmentation')\n",
    "    axes[1].axis('off')\n",
    "    axes[1].legend(handles=legend_patches, loc='upper right', fontsize=8)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Test\n",
    "try:\n",
    "    instances = instance_segmenter(image)\n",
    "    print(f\"Nalezeno {len(instances)} instanc√≠\")\n",
    "    \n",
    "    for inst in instances[:5]:\n",
    "        score = inst.get('score', 'N/A')\n",
    "        if isinstance(score, float):\n",
    "            print(f\"  - {inst['label']}: {score:.1%}\")\n",
    "        else:\n",
    "            print(f\"  - {inst['label']}\")\n",
    "    \n",
    "    visualize_instances(image, instances[:10])\n",
    "except Exception as e:\n",
    "    print(f\"Chyba: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Praktick√° automatizace: Product Image Processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProductImageProcessor:\n",
    "    \"\"\"\n",
    "    Procesor produktov√Ωch obr√°zk≈Ø pro e-commerce.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.segmenter = segmenter\n",
    "    \n",
    "    def extract_product(self, image, padding=10):\n",
    "        \"\"\"\n",
    "        Extrahuje produkt z obr√°zku.\n",
    "        \"\"\"\n",
    "        if isinstance(image, str):\n",
    "            image = load_image(image)\n",
    "        \n",
    "        # Segmentace\n",
    "        results = self.segmenter(image)\n",
    "        \n",
    "        # Najdi nejvƒõt≈°√≠ segment (pravdƒõpodobnƒõ produkt)\n",
    "        largest_segment = None\n",
    "        largest_area = 0\n",
    "        \n",
    "        for segment in results:\n",
    "            mask = np.array(segment['mask'])\n",
    "            area = mask.sum()\n",
    "            if area > largest_area:\n",
    "                largest_area = area\n",
    "                largest_segment = segment\n",
    "        \n",
    "        if largest_segment is None:\n",
    "            return None, None\n",
    "        \n",
    "        mask = np.array(largest_segment['mask'])\n",
    "        \n",
    "        # Najdi bounding box\n",
    "        rows = np.any(mask, axis=1)\n",
    "        cols = np.any(mask, axis=0)\n",
    "        \n",
    "        if not rows.any() or not cols.any():\n",
    "            return None, None\n",
    "        \n",
    "        y1, y2 = np.where(rows)[0][[0, -1]]\n",
    "        x1, x2 = np.where(cols)[0][[0, -1]]\n",
    "        \n",
    "        # P≈ôidej padding\n",
    "        y1 = max(0, y1 - padding)\n",
    "        y2 = min(image.size[1], y2 + padding)\n",
    "        x1 = max(0, x1 - padding)\n",
    "        x2 = min(image.size[0], x2 + padding)\n",
    "        \n",
    "        # O≈ô√≠znut√≠\n",
    "        cropped = image.crop((x1, y1, x2, y2))\n",
    "        cropped_mask = mask[y1:y2, x1:x2]\n",
    "        \n",
    "        return cropped, cropped_mask\n",
    "    \n",
    "    def create_product_image(self, image, background_color=(255, 255, 255), size=(800, 800)):\n",
    "        \"\"\"\n",
    "        Vytvo≈ô√≠ profesion√°ln√≠ produktov√Ω obr√°zek.\n",
    "        \"\"\"\n",
    "        # Extrahuj produkt\n",
    "        product, mask = self.extract_product(image)\n",
    "        \n",
    "        if product is None:\n",
    "            return None\n",
    "        \n",
    "        # Vytvo≈ô nov√© pozad√≠\n",
    "        result = Image.new('RGB', size, background_color)\n",
    "        \n",
    "        # ≈†k√°lov√°n√≠ produktu\n",
    "        product_ratio = product.size[0] / product.size[1]\n",
    "        target_size = int(size[0] * 0.8)  # 80% velikosti\n",
    "        \n",
    "        if product_ratio > 1:\n",
    "            new_width = target_size\n",
    "            new_height = int(target_size / product_ratio)\n",
    "        else:\n",
    "            new_height = target_size\n",
    "            new_width = int(target_size * product_ratio)\n",
    "        \n",
    "        product = product.resize((new_width, new_height), Image.Resampling.LANCZOS)\n",
    "        \n",
    "        # Centrov√°n√≠\n",
    "        x = (size[0] - new_width) // 2\n",
    "        y = (size[1] - new_height) // 2\n",
    "        \n",
    "        result.paste(product, (x, y))\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    def batch_process(self, images, output_dir=None):\n",
    "        \"\"\"\n",
    "        D√°vkov√© zpracov√°n√≠ produktov√Ωch obr√°zk≈Ø.\n",
    "        \"\"\"\n",
    "        results = []\n",
    "        \n",
    "        for i, img_source in enumerate(images):\n",
    "            try:\n",
    "                processed = self.create_product_image(img_source)\n",
    "                \n",
    "                if processed and output_dir:\n",
    "                    output_path = f\"{output_dir}/product_{i:04d}.jpg\"\n",
    "                    processed.save(output_path, quality=95)\n",
    "                \n",
    "                results.append({\n",
    "                    \"index\": i,\n",
    "                    \"status\": \"success\",\n",
    "                    \"image\": processed\n",
    "                })\n",
    "            except Exception as e:\n",
    "                results.append({\n",
    "                    \"index\": i,\n",
    "                    \"status\": \"error\",\n",
    "                    \"error\": str(e)\n",
    "                })\n",
    "        \n",
    "        return results\n",
    "\n",
    "# Test\n",
    "processor = ProductImageProcessor()\n",
    "print(\"‚úÖ ProductImageProcessor p≈ôipraven\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test extrakce produktu\n",
    "try:\n",
    "    product, mask = processor.extract_product(image)\n",
    "    \n",
    "    if product:\n",
    "        fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "        \n",
    "        axes[0].imshow(image)\n",
    "        axes[0].set_title('Origin√°l')\n",
    "        axes[0].axis('off')\n",
    "        \n",
    "        axes[1].imshow(product)\n",
    "        axes[1].set_title('Extrahovan√Ω produkt')\n",
    "        axes[1].axis('off')\n",
    "        \n",
    "        # Profesion√°ln√≠ obr√°zek\n",
    "        pro_image = processor.create_product_image(image)\n",
    "        if pro_image:\n",
    "            axes[2].imshow(pro_image)\n",
    "            axes[2].set_title('Profesion√°ln√≠ produkt')\n",
    "            axes[2].axis('off')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(\"Nepoda≈ôilo se extrahovat produkt\")\n",
    "except Exception as e:\n",
    "    print(f\"Chyba: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Anal√Ωza kompozice obr√°zku"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CompositionAnalyzer:\n",
    "    \"\"\"\n",
    "    Analyz√°tor kompozice obr√°zku pomoc√≠ segmentace.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.segmenter = segmenter\n",
    "    \n",
    "    def analyze(self, image):\n",
    "        \"\"\"\n",
    "        Analyzuje kompozici obr√°zku.\n",
    "        \"\"\"\n",
    "        if isinstance(image, str):\n",
    "            image = load_image(image)\n",
    "        \n",
    "        results = self.segmenter(image)\n",
    "        \n",
    "        width, height = image.size\n",
    "        total_pixels = width * height\n",
    "        \n",
    "        # Anal√Ωza segment≈Ø\n",
    "        segment_analysis = []\n",
    "        \n",
    "        for segment in results:\n",
    "            mask = np.array(segment['mask'])\n",
    "            area = mask.sum()\n",
    "            coverage = area / total_pixels * 100\n",
    "            \n",
    "            # Pozice centroidu\n",
    "            if area > 0:\n",
    "                y_coords, x_coords = np.where(mask > 0)\n",
    "                centroid_x = x_coords.mean() / width\n",
    "                centroid_y = y_coords.mean() / height\n",
    "            else:\n",
    "                centroid_x, centroid_y = 0.5, 0.5\n",
    "            \n",
    "            segment_analysis.append({\n",
    "                \"label\": segment['label'],\n",
    "                \"coverage_percent\": coverage,\n",
    "                \"centroid\": (centroid_x, centroid_y),\n",
    "                \"position\": self._get_position(centroid_x, centroid_y)\n",
    "            })\n",
    "        \n",
    "        # Se≈ôazen√≠ podle pokryt√≠\n",
    "        segment_analysis.sort(key=lambda x: x['coverage_percent'], reverse=True)\n",
    "        \n",
    "        # Celkov√° anal√Ωza\n",
    "        main_subjects = [s for s in segment_analysis if s['coverage_percent'] > 5]\n",
    "        \n",
    "        return {\n",
    "            \"total_segments\": len(results),\n",
    "            \"main_subjects\": main_subjects,\n",
    "            \"dominant_element\": segment_analysis[0] if segment_analysis else None,\n",
    "            \"composition_type\": self._determine_composition(segment_analysis),\n",
    "            \"all_segments\": segment_analysis\n",
    "        }\n",
    "    \n",
    "    def _get_position(self, x, y):\n",
    "        \"\"\"Urƒç√≠ pozici v obr√°zku.\"\"\"\n",
    "        h_pos = \"left\" if x < 0.33 else (\"right\" if x > 0.66 else \"center\")\n",
    "        v_pos = \"top\" if y < 0.33 else (\"bottom\" if y > 0.66 else \"middle\")\n",
    "        return f\"{v_pos}-{h_pos}\"\n",
    "    \n",
    "    def _determine_composition(self, segments):\n",
    "        \"\"\"Urƒç√≠ typ kompozice.\"\"\"\n",
    "        if not segments:\n",
    "            return \"empty\"\n",
    "        \n",
    "        main = segments[0]\n",
    "        \n",
    "        if main['coverage_percent'] > 50:\n",
    "            return \"single-subject-dominant\"\n",
    "        elif main['coverage_percent'] > 20:\n",
    "            return \"single-subject\"\n",
    "        elif len([s for s in segments if s['coverage_percent'] > 10]) > 2:\n",
    "            return \"multi-subject\"\n",
    "        else:\n",
    "            return \"scattered\"\n",
    "\n",
    "# Test\n",
    "comp_analyzer = CompositionAnalyzer()\n",
    "\n",
    "try:\n",
    "    analysis = comp_analyzer.analyze(image)\n",
    "    \n",
    "    print(\"=\" * 50)\n",
    "    print(\"ANAL√ùZA KOMPOZICE\")\n",
    "    print(\"=\" * 50)\n",
    "    print(f\"Typ kompozice: {analysis['composition_type']}\")\n",
    "    print(f\"Poƒçet segment≈Ø: {analysis['total_segments']}\")\n",
    "    \n",
    "    if analysis['dominant_element']:\n",
    "        dom = analysis['dominant_element']\n",
    "        print(f\"\\nDominantn√≠ element: {dom['label']}\")\n",
    "        print(f\"  Pokryt√≠: {dom['coverage_percent']:.1f}%\")\n",
    "        print(f\"  Pozice: {dom['position']}\")\n",
    "    \n",
    "    if analysis['main_subjects']:\n",
    "        print(\"\\nHlavn√≠ subjekty:\")\n",
    "        for subj in analysis['main_subjects'][:5]:\n",
    "            print(f\"  - {subj['label']}: {subj['coverage_percent']:.1f}% ({subj['position']})\")\n",
    "except Exception as e:\n",
    "    print(f\"Chyba: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Depth Estimation (bonus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Depth estimation pipeline\n",
    "try:\n",
    "    depth_estimator = pipeline(\n",
    "        \"depth-estimation\",\n",
    "        model=\"Intel/dpt-hybrid-midas\",\n",
    "        device=0 if device == \"cuda\" else -1\n",
    "    )\n",
    "    print(\"‚úÖ Depth estimation pipeline p≈ôipraven\")\n",
    "except Exception as e:\n",
    "    print(f\"Depth estimation nen√≠ k dispozici: {e}\")\n",
    "    depth_estimator = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if depth_estimator:\n",
    "    try:\n",
    "        depth_result = depth_estimator(image)\n",
    "        depth_map = np.array(depth_result['depth'])\n",
    "        \n",
    "        fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "        \n",
    "        axes[0].imshow(image)\n",
    "        axes[0].set_title('Origin√°l')\n",
    "        axes[0].axis('off')\n",
    "        \n",
    "        im = axes[1].imshow(depth_map, cmap='plasma')\n",
    "        axes[1].set_title('Hloubkov√° mapa')\n",
    "        axes[1].axis('off')\n",
    "        plt.colorbar(im, ax=axes[1], label='Vzd√°lenost')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    except Exception as e:\n",
    "        print(f\"Chyba p≈ôi odhadu hloubky: {e}\")\n",
    "else:\n",
    "    print(\"Depth estimation p≈ôeskoƒçen\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Utility funkce pro export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_segmentation_results(image, segments, output_dir, base_name=\"segmentation\"):\n",
    "    \"\"\"\n",
    "    Ulo≈æ√≠ v√Ωsledky segmentace.\n",
    "    \"\"\"\n",
    "    import os\n",
    "    import json\n",
    "    \n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Ulo≈æen√≠ origin√°ln√≠ho obr√°zku\n",
    "    if isinstance(image, str):\n",
    "        image = load_image(image)\n",
    "    image.save(f\"{output_dir}/{base_name}_original.jpg\")\n",
    "    \n",
    "    # Ulo≈æen√≠ jednotliv√Ωch masek\n",
    "    metadata = []\n",
    "    \n",
    "    for i, segment in enumerate(segments):\n",
    "        mask = segment['mask']\n",
    "        label = segment['label']\n",
    "        \n",
    "        # Ulo≈æen√≠ masky\n",
    "        mask_img = Image.fromarray((np.array(mask) * 255).astype(np.uint8))\n",
    "        mask_path = f\"{output_dir}/{base_name}_mask_{i:03d}_{label}.png\"\n",
    "        mask_img.save(mask_path)\n",
    "        \n",
    "        metadata.append({\n",
    "            \"index\": i,\n",
    "            \"label\": label,\n",
    "            \"score\": segment.get('score'),\n",
    "            \"mask_file\": os.path.basename(mask_path)\n",
    "        })\n",
    "    \n",
    "    # Ulo≈æen√≠ metadat\n",
    "    with open(f\"{output_dir}/{base_name}_metadata.json\", 'w') as f:\n",
    "        json.dump(metadata, f, indent=2)\n",
    "    \n",
    "    print(f\"Ulo≈æeno {len(segments)} segment≈Ø do {output_dir}\")\n",
    "    return metadata\n",
    "\n",
    "print(\"‚úÖ Export funkce p≈ôipraveny\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shrnut√≠\n",
    "\n",
    "V tomto notebooku jsme se nauƒçili:\n",
    "\n",
    "1. **S√©mantick√° segmentace** - klasifikace ka≈æd√©ho pixelu do t≈ô√≠dy\n",
    "2. **SegFormer model** - efektivn√≠ transformer pro segmentaci\n",
    "3. **Instance segmentation** - rozli≈°en√≠ jednotliv√Ωch objekt≈Ø\n",
    "4. **Odstranƒõn√≠ pozad√≠** - automatick√© odstranƒõn√≠ pozad√≠ z produktov√Ωch fotek\n",
    "5. **Anal√Ωza kompozice** - vyhodnocen√≠ rozlo≈æen√≠ prvk≈Ø v obr√°zku\n",
    "6. **Depth estimation** - odhad hloubky sc√©ny\n",
    "7. **Praktick√© automatizace** - zpracov√°n√≠ produktov√Ωch obr√°zk≈Ø pro e-shop\n",
    "\n",
    "### Dal≈°√≠ kroky\n",
    "- Notebook 11: Text Embeddings a S√©mantick√© Vyhled√°v√°n√≠"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
