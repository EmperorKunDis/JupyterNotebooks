{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0c723fc4",
   "metadata": {},
   "source": [
    "# ğŸ“š Kapitola 31: Ãšvod do LLM a Ollama\n",
    "\n",
    "<div style=\"background: linear-gradient(90deg, #667eea 0%, #764ba2 100%); padding: 20px; border-radius: 10px; margin: 20px 0;\">\n",
    "    <h2 style=\"color: white; margin: 0;\">Blok 4 | EXPERT</h2>\n",
    "    <p style=\"color: white; margin: 10px 0;\">ğŸ“– VÃ½ukovÃ¡ kapitola</p>\n",
    "</div>\n",
    "\n",
    "## ğŸ¯ Co se nauÄÃ­te\n",
    "\n",
    "V tÃ©to kapitole se zamÄ›Å™Ã­me na nÃ¡sledujÃ­cÃ­ tÃ©mata:\n",
    "\n",
    "- **LLM zÃ¡kladnÃ­ koncepty**\n",
    "- **Transformers architecture basics**\n",
    "- **Ollama installation vÅ¡echny OS**\n",
    "- **Model management commands**\n",
    "- **Ollama models overview**\n",
    "- **Hardware requirements**\n",
    "- **GPU acceleration setup**\n",
    "\n",
    "## âš ï¸ PÅ™edpoklady\n",
    "Tato kapitola navazuje na kapitoly: 4\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f76c6b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# âš™ï¸ Inicializace prostÅ™edÃ­\n",
    "# Tento kÃ³d nastavuje prostÅ™edÃ­ pro kapitolu 31\n",
    "\n",
    "import sys\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "# Informace o prostÅ™edÃ­\n",
    "print(\"=\" * 60)\n",
    "print(f\"ğŸ“š KAPITOLA 31: Ãšvod do LLM a Ollama\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"ğŸ Python verze: {sys.version}\")\n",
    "print(f\"ğŸ“… Datum spuÅ¡tÄ›nÃ­: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(f\"ğŸ’» OS: {os.name}\")\n",
    "print(f\"ğŸ“ PracovnÃ­ adresÃ¡Å™: {os.getcwd()}\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Instalace potÅ™ebnÃ½ch knihoven (odkomentujte podle potÅ™eby)\n",
    "# !pip install requests pandas numpy matplotlib\n",
    "# !pip install beautifulsoup4 sqlalchemy fastapi\n",
    "\n",
    "# Import zÃ¡kladnÃ­ch knihoven\n",
    "import json\n",
    "import csv\n",
    "import time\n",
    "import random\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Optional, Any\n",
    "\n",
    "print(\"âœ… ProstÅ™edÃ­ pÅ™ipraveno!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec1b61db",
   "metadata": {},
   "source": [
    "## ğŸ“– TeoretickÃ¡ ÄÃ¡st\n",
    "\n",
    "<div style=\"background: #f0f4ff; padding: 20px; border-left: 5px solid #4a69bd; margin: 20px 0; border-radius: 5px;\">\n",
    "    <h3 style=\"color: #2c3e50; margin-top: 0;\">ğŸ“ ZÃ¡kladnÃ­ teorie a koncepty</h3>\n",
    "</div>\n",
    "\n",
    "# Ãšvod do LLM a Ollama\n",
    "\n",
    "## 1. Ãšvod a motivace\n",
    "\n",
    "V obdobÃ­, kdy umÄ›lÃ¡ inteligence (AI) stÃ¡le vÃ­ce pronikÃ¡ do kaÅ¾dodennÃ­ho Å¾ivota a prÅ¯myslovÃ½ch procesÅ¯, vÃ½voj velkÃ½ch jazykovÃ½ch modelÅ¯ (LLM â€“ *Large Language Models*) pÅ™edstavuje klÃ­ÄovÃ½ vÃ½znamnÃ½ krok smÄ›rem ke zvÃ½Å¡enÃ­ automatizace, personalizaci a efektivitÄ›. LLM jsou schopny vykonÃ¡vat nespoÄet ÃºkolÅ¯ â€“ od pÅ™ekladu textu, pÅ™es tvorbu obsahu, aÅ¾ po rozumovÃ© analÃ½zy â€“ vÃ½raznÄ› zlepÅ¡ujÃ­ vÃ½konnost v oblastech jako je vzdÄ›lÃ¡vÃ¡nÃ­, lÃ©kaÅ™stvÃ­, prÃ¡vo nebo finanÄnÃ­ sluÅ¾by. \n",
    "\n",
    "V praxi se LLM pouÅ¾Ã­vajÃ­ napÅ™Ã­klad ve vÃ½voji chatbotÅ¯, automatizovanÃ½ch systÃ©mech pro zpracovÃ¡nÃ­ dokumentÅ¯, analÃ½ze dat, generovÃ¡nÃ­ kÃ³du nebo podpÅ¯rnÃ½ch systÃ©mÅ¯ pro programÃ¡tory. V tomto kurzu se zamÄ›Å™Ã­me na praktickÃ© vyuÅ¾itÃ­ nÃ¡strojÅ¯ jako je **Ollama**, kterÃ© umoÅ¾ÅˆujÃ­ bÄ›h LLM modelÅ¯ lokÃ¡lnÄ› â€“ tedy bez potÅ™eby pÅ™Ã­stupu k cloudu â€“ coÅ¾ zvyÅ¡uje soukromÃ­, rychlost a kontrolu nad daty. \n",
    "\n",
    "Student se nauÄÃ­, jak instalovat Ollama na rÅ¯znÃ½ch operaÄnÃ­ch systÃ©mech, spravovat modely, vyuÅ¾Ã­vat akceleraci GPU a zÃ¡roveÅˆ pochopÃ­ hlavnÃ­ principy fungovÃ¡nÃ­ LLM modelÅ¯ a jejich architektury. Tato kapitola je zÃ¡kladem pro pokraÄujÃ­cÃ­ studium v oblasti LLM, AI modelovÃ¡nÃ­ a lokÃ¡lnÃ­ho nasazenÃ­ umÄ›lÃ© inteligence.\n",
    "\n",
    "---\n",
    "\n",
    "## 2. HlavnÃ­ koncepty\n",
    "\n",
    "### **LLM â€“ zÃ¡kladnÃ­ koncepty**\n",
    "\n",
    "VelkÃ© jazykovÃ© modely (Large Language Models) jsou neuronovÃ© sÃ­tÄ› trÃ©novanÃ© na obrovskÃ©m mnoÅ¾stvÃ­ textu, kterÃ© se nauÄily pÅ™edpovÃ­dat dalÅ¡Ã­ slova v textu. Tyto modely jsou schopnÃ© nejen ÄÃ­st a interpretovat jazyk, ale i generovat text, odpovÃ­dat na otÃ¡zky, pÅ™eklÃ¡dat nebo Å™eÅ¡it logickÃ© Ãºlohy.\n",
    "\n",
    "JednÃ­m z nejznÃ¡mÄ›jÅ¡Ã­ch pÅ™Ã­kladÅ¯ je model **GPT-4**, kterÃ½ byl trÃ©novÃ¡n na tisÃ­cÃ­ch miliardÃ¡ch slov. Modely jako GPT, LLaMA, Mistral nebo Phi jsou vytvÃ¡Å™eny pomocÃ­ zpÄ›tnÃ©ho Å¡Ã­Å™enÃ­ chyb (backpropagation), sÃ­tÃ­ typu Transformer a obrovskÃ½ch datasetÅ¯.\n",
    "\n",
    "VÃ½hodou LLM je jejich schopnost pÅ™izpÅ¯sobit se rÅ¯znÃ½m ÃºkolÅ¯m, tedy vyuÅ¾Ã­t stejnÃ½ model pro mnoho rÅ¯znÃ½ch aplikacÃ­ â€“ napÅ™. jako chatbot, kreativnÃ­ nÃ¡stroj nebo nÃ¡stroj pro analÃ½zu dat.\n",
    "\n",
    "---\n",
    "\n",
    "### **Transformers architecture basics**\n",
    "\n",
    "Architektura Transformers je zÃ¡kladnÃ­m prvkem modernÃ­ch LLM modelÅ¯. VytvoÅ™enÃ¡ v roce 2017 v ÄlÃ¡nku *â€œAttention is All You Needâ€*, se jednÃ¡ o neuronovou sÃ­Å¥, kterÃ¡ pouÅ¾Ã­vÃ¡ mechanismus **attention**, kterÃ½ umoÅ¾Åˆuje modelu zamÄ›Å™it se na rÅ¯znÃ© ÄÃ¡sti vstupnÃ­ho textu pÅ™i generovÃ¡nÃ­ odpovÄ›di.\n",
    "\n",
    "HlavnÃ­ komponenty Transformeru:\n",
    "\n",
    "- **Embedding layer** â€“ pÅ™evÃ¡dÃ­ slova do ÄÃ­selnÃ½ch reprezentacÃ­\n",
    "- **Multi-head attention** â€“ umoÅ¾Åˆuje modelu vidÄ›t vztahy mezi rÅ¯znÃ½mi slovy ve vÄ›tÄ›\n",
    "- **Feed-forward neural network** â€“ zpracovÃ¡vÃ¡ jednotlivÃ© tokeny po pozornosti\n",
    "- **Residual connections a Layer Normalization** â€“ pomÃ¡hajÃ­ stabilizovat trÃ©nink\n",
    "\n",
    "Transformer je schopen zpracovÃ¡vat vstupnÃ­ text paralelnÄ› (ne postupnÄ› jako starÅ¡Ã­ modely), coÅ¾ zvyÅ¡uje rychlost trÃ©ninku a efektivitu.\n",
    "\n",
    "---\n",
    "\n",
    "### **Ollama â€“ instalace na vÅ¡echny OS**\n",
    "\n",
    "Ollama je jednoduchÃ½ nÃ¡stroj, kterÃ½ umoÅ¾Åˆuje spouÅ¡tÄ›t LLM modely lokÃ¡lnÄ›. Podporuje vÅ¡echny hlavnÃ­ operaÄnÃ­ systÃ©my.\n",
    "\n",
    "#### **Windows**\n",
    "1. StÃ¡hnÄ›te Ollama z oficiÃ¡lnÃ­ho webu: [https://ollama.com/download](https://ollama.com/download)\n",
    "2. SpusÅ¥te instalaÄnÃ­ program a nÃ¡sledujte pokyny.\n",
    "3. OvÄ›Å™te instalaci pÅ™Ã­kazem:\n",
    "   ```bash\n",
    "   ollama --version\n",
    "   ```\n",
    "\n",
    "#### **macOS**\n",
    "PouÅ¾ijte Homebrew:\n",
    "```bash\n",
    "brew install ollama\n",
    "```\n",
    "\n",
    "#### **Linux (Ubuntu/Debian)**\n",
    "```bash\n",
    "curl -fsSL https://ollama.com/install.sh | sh\n",
    "```\n",
    "\n",
    "Po instalaci spusÅ¥te:\n",
    "```bash\n",
    "ollama serve\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **Model management â€“ pÅ™Ã­kazy**\n",
    "\n",
    "Ollama umoÅ¾Åˆuje jednoduchou sprÃ¡vu modelÅ¯ pomocÃ­ pÅ™Ã­kazovÃ© Å™Ã¡dky:\n",
    "\n",
    "- **StaÅ¾enÃ­ modelu**:\n",
    "  ```bash\n",
    "  ollama pull llama3\n",
    "  ```\n",
    "- **ZobrazenÃ­ seznamu modelÅ¯**:\n",
    "  ```bash\n",
    "  ollama list\n",
    "  ```\n",
    "- **SpuÅ¡tÄ›nÃ­ modelu**:\n",
    "  ```bash\n",
    "  ollama run llama3\n",
    "  ```\n",
    "\n",
    "PÅ™Ã­kazy jako `ollama run`, `ollama ps` (zobrazenÃ­ bÄ›Å¾Ã­cÃ­ch modelÅ¯) a `ollama rm <model>` (smazÃ¡nÃ­ modelu) jsou zÃ¡kladnÃ­m nÃ¡strojem pro sprÃ¡vu.\n",
    "\n",
    "---\n",
    "\n",
    "### **Ollama â€“ pÅ™ehled modelÅ¯**\n",
    "\n",
    "Ollama podporuje mnoho open-source LLM modelÅ¯, kterÃ© mohou bÄ›Å¾et lokÃ¡lnÄ›. Mezi nejÄastÄ›ji pouÅ¾Ã­vanÃ© patÅ™Ã­:\n",
    "\n",
    "- **LLaMA 3** â€“ novÃ½ model od Meta\n",
    "- **Mistral** â€“ vysokÃ½ vÃ½kon a efektivita\n",
    "- **Phi-3** â€“ malÃ½, rychlÃ½ model pro edge zaÅ™Ã­zenÃ­\n",
    "- **Gemma** â€“ od Google\n",
    "\n",
    "KaÅ¾dÃ½ model mÃ¡ svÃ© specifickÃ© vlastnosti: rozsah trÃ©novacÃ­ch dat, velikost (napÅ™. 7B, 13B), zpÅ¯sob optimalizace a vÃ½konnost.\n",
    "\n",
    "---\n",
    "\n",
    "### **Hardware requirements**\n",
    "\n",
    "Pro bÄ›h LLM modelÅ¯ lokÃ¡lnÄ› je dÅ¯leÅ¾itÃ¡ dostupnÃ¡ pamÄ›Å¥ a vÃ½poÄetnÃ­ kapacita:\n",
    "\n",
    "- **RAM**: MinimÃ¡lnÄ› 8 GB, pro vÄ›tÅ¡Ã­ modely doporuÄeno 16 GB nebo vÃ­ce\n",
    "- **GPU** (pokud pouÅ¾Ã­vÃ¡te GPU): MinimÃ¡lnÄ› 8 GB VRAM, ideÃ¡lnÄ› 12â€“24 GB pro pokroÄilÃ© modely\n",
    "- **CPU**: Pro menÅ¡Ã­ modely postaÄÃ­ i 6-jÃ¡drovÃ½ procesor\n",
    "\n",
    "PouÅ¾itÃ­ GPU vÃ½raznÄ› zrychluje bÄ›h modelÅ¯ (napÅ™. LLaMA 3 na GPU bÄ›Å¾Ã­ nÄ›kolikanÃ¡sobnÄ› rychleji neÅ¾ na CPU).\n",
    "\n",
    "---\n",
    "\n",
    "### **GPU acceleration setup**\n",
    "\n",
    "Pro sprÃ¡vnÃ© vyuÅ¾itÃ­ GPU ve Windows, Linuxu a macOS:\n",
    "\n",
    "#### **Windows**\n",
    "- Instalace NVIDIA drivÃ©rÅ¯ (CUDA)\n",
    "- Nainstalujte Ollama s podporou CUDA:\n",
    "  ```bash\n",
    "  ollama run --gpu llama3\n",
    "  ```\n",
    "\n",
    "#### **Linux**\n",
    "```bash\n",
    "sudo apt install nvidia-driver-535\n",
    "ollama run llama3\n",
    "```\n",
    "\n",
    "#### **macOS**\n",
    "PouÅ¾ijte Metal framework â€“ Ollama automaticky vyuÅ¾Ã­vÃ¡ podporu pro Apple Silicon (M1/M2).\n",
    "\n",
    "---\n",
    "\n",
    "## 3. DÅ¯leÅ¾itÃ© detaily\n",
    "\n",
    "### **ÄŒastÃ© chyby a jak se jim vyhnout**\n",
    "\n",
    "- **ChybÄ›jÃ­cÃ­ GPU podpora**: PÅ™i spuÅ¡tÄ›nÃ­ modelu bez podpory GPU se mÅ¯Å¾e pÅ™Ã­kaz zaseknout nebo bÄ›Å¾et extrÃ©mnÄ› pomalu.\n",
    "- **Nedostatek pamÄ›ti RAM**: Modely vyÅ¾adujÃ­ velkÃ© mnoÅ¾stvÃ­ pamÄ›ti â€“ v pÅ™Ã­padÄ› chybÄ›jÃ­cÃ­ pamÄ›ti se aplikace mÅ¯Å¾e zhroutit.\n",
    "- **Å patnÃ© pouÅ¾itÃ­ pÅ™Ã­kazÅ¯**: NapÅ™. spuÅ¡tÄ›nÃ­ `ollama run` bez stahnutÃ©ho modelu nebo pouÅ¾itÃ­ `--gpu` na CPU.\n",
    "\n",
    "### **Best practices**\n",
    "\n",
    "- VÅ¾dy zkontrolujte dostupnou pamÄ›Å¥ a vÃ½kon pÅ™ed spuÅ¡tÄ›nÃ­m modelu.\n",
    "- PouÅ¾Ã­vejte menÅ¡Ã­ modely (napÅ™. Mistral 7B) pro zaÄÃ¡tek, pak postupnÄ› pÅ™echÃ¡zÃ­te na vÄ›tÅ¡Ã­.\n",
    "- UdrÅ¾ujte modely aktuÃ¡lnÃ­ pomocÃ­ `ollama pull <model>`.\n",
    "\n",
    "### **Performance tipy**\n",
    "\n",
    "- VyuÅ¾ijte GPU podporu (`--gpu`)\n",
    "- VyuÅ¾ijte modely optimalizovanÃ© pro rychlost (napÅ™. Phi, Gemma)\n",
    "- PouÅ¾Ã­vejte streamovÃ¡nÃ­ odpovÄ›dÃ­ (`--stream`) pro lepÅ¡Ã­ zkuÅ¡enost\n",
    "\n",
    "---\n",
    "\n",
    "## 4. PropojenÃ­ s pÅ™edchozÃ­mi kapitolami\n",
    "\n",
    "Tato kapitola navazuje na poznatky z ÃºvodnÃ­ho kurzu do AI a neuronovÃ½ch sÃ­tÃ­, kde jsme se nauÄili zÃ¡klady strojovÃ©ho uÄenÃ­. NynÃ­ se zamÄ›Å™ujeme na konkrÃ©tnÃ­ implementace a praktickÃ© nÃ¡stroje â€“ tedy jak LLM funguje v praxi a jak je moÅ¾nÃ© jej bÄ›Å¾et lokÃ¡lnÄ›.\n",
    "\n",
    "ZÃ¡roveÅˆ rozÅ¡iÅ™uje pochopenÃ­ z pÅ™edchozÃ­ch kapitol o modelovÃ¡nÃ­, trÃ©nink a zpÄ›tnÃ© Å¡Ã­Å™enÃ­ chyb â€“ nynÃ­ se zamÄ›Å™ujeme na **bÄ›h** a **deploy** modelÅ¯ v reÃ¡lnÃ©m prostÅ™edÃ­.\n",
    "\n",
    "---\n",
    "\n",
    "Pokud mÃ¡te zÃ¡jem o pokraÄovÃ¡nÃ­ v tomto kurzu, budete mÃ­t pÅ™ipravenÃ© zÃ¡klady pro pokroÄilÃ© prÃ¡ce s prompt engineeringem, fine-tuningem, pÅ™Ã­padnÄ› vytvÃ¡Å™enÃ­ vlastnÃ­ch LLM modelÅ¯.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d476ffed",
   "metadata": {},
   "source": [
    "## ğŸ’» PraktickÃ© pÅ™Ã­klady\n",
    "\n",
    "<div style=\"background: #e8f5e9; padding: 20px; border-left: 5px solid #4caf50; margin: 20px 0; border-radius: 5px;\">\n",
    "    <h3 style=\"color: #2c3e50; margin-top: 0;\">ğŸ‘¨â€ğŸ’» Hands-on pÅ™Ã­klady ke spuÅ¡tÄ›nÃ­</h3>\n",
    "    <p>NÃ¡sledujÃ­cÃ­ pÅ™Ã­klady si mÅ¯Å¾ete hned vyzkouÅ¡et. KaÅ¾dÃ½ pÅ™Ã­klad je samostatnÄ› spustitelnÃ½.</p>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49598520",
   "metadata": {},
   "source": [
    "### PÅ™Ã­klad 1\n",
    "\n",
    "### Co pÅ™Ã­klad demonstruje:\n",
    "Tento pÅ™Ã­klad ukazuje zÃ¡kladnÃ­ instalaci a spuÅ¡tÄ›nÃ­ serveru Ollama na rÅ¯znÃ½ch operaÄnÃ­ch systÃ©mech."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "580feff2",
   "metadata": {},
   "source": [
    "### PÅ™Ã­klad 2\n",
    "\n",
    "### KompletnÃ­ kÃ³d s ÄeskÃ½mi komentÃ¡Å™i:\n",
    "\n",
    "```bash\n",
    "# Pro Linux (Ubuntu/Debian)\n",
    "curl -fsSL https://ollama.com/install.sh | sh\n",
    "\n",
    "# Pro macOS (pouÅ¾ijte Homebrew)\n",
    "brew install ollama\n",
    "\n",
    "# Pro Windows (PouÅ¾ijte PowerShell jako administrÃ¡tor)\n",
    "irm https://ollama.com/install.ps1 | iex\n",
    "\n",
    "# SpusÅ¥te Ollama server (po instalaci)\n",
    "ollama serve\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a93d365",
   "metadata": {},
   "source": [
    "### PÅ™Ã­klad 3\n",
    "\n",
    "### OÄekÃ¡vanÃ½ vÃ½stup:\n",
    "```\n",
    "WARN[0000] failed to get system info: open /etc/os-release: no such file or directory\n",
    "Loading model...\n",
    "Ollama is running on http://localhost:11434\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c112fff1",
   "metadata": {},
   "source": [
    "### PÅ™Ã­klad 4\n",
    "\n",
    "### VysvÄ›tlenÃ­:\n",
    "Tento pÅ™Ã­klad ukazuje rÅ¯znÃ© zpÅ¯soby instalace Ollama na rÅ¯znÃ½ch operaÄnÃ­ch systÃ©mech. Po spuÅ¡tÄ›nÃ­ `ollama serve` se spustÃ­ lokÃ¡lnÃ­ server, kterÃ½ umoÅ¾Åˆuje komunikaci s LLM modely.\n",
    "\n",
    "---\n",
    "\n",
    "## 2. **StaÅ¾enÃ­ a spuÅ¡tÄ›nÃ­ prvnÃ­ho modelu (llama3)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da23efdf",
   "metadata": {},
   "source": [
    "### PÅ™Ã­klad 5\n",
    "\n",
    "### Co pÅ™Ã­klad demonstruje:\n",
    "ZÃ­skÃ¡nÃ­ a spuÅ¡tÄ›nÃ­ zÃ¡kladnÃ­ho modelu `llama3` pomocÃ­ Ollama."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6588a055",
   "metadata": {},
   "source": [
    "### PÅ™Ã­klad 6\n",
    "\n",
    "### KompletnÃ­ kÃ³d s ÄeskÃ½mi komentÃ¡Å™i:\n",
    "\n",
    "```bash\n",
    "# StÃ¡hne a spustÃ­ model llama3 (vÃ½chozÃ­ verze)\n",
    "ollama run llama3\n",
    "\n",
    "# Po spuÅ¡tÄ›nÃ­ mÅ¯Å¾eÅ¡ zadÃ¡vat dotazy:\n",
    "# Jak se jmenujeÅ¡?\n",
    "# Co je umÄ›lÃ¡ inteligence?\n",
    "\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac4ca4c3",
   "metadata": {},
   "source": [
    "### PÅ™Ã­klad 7\n",
    "\n",
    "PÅ™Ã­klad odpovÄ›di:\n",
    "# Jsem Llama 3, umÄ›lÃ¡ inteligence vytvoÅ™enÃ¡ spoleÄnostÃ­ Meta.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d1293f4",
   "metadata": {},
   "source": [
    "### PÅ™Ã­klad 8\n",
    "\n",
    "### OÄekÃ¡vanÃ½ vÃ½stup:\n",
    "```\n",
    "> Jak se jmenujeÅ¡?\n",
    "Jsem Llama 3, umÄ›lÃ¡ inteligence vytvoÅ™enÃ¡ spoleÄnostÃ­ Meta.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c69d7b5",
   "metadata": {},
   "source": [
    "### PÅ™Ã­klad 9\n",
    "\n",
    "### VysvÄ›tlenÃ­:\n",
    "PÅ™Ã­kaz `ollama run llama3` stÃ¡hne model (pokud jeÅ¡tÄ› nenÃ­ lokÃ¡lnÄ›) a spustÃ­ interaktivnÃ­ konzoli pro zadÃ¡vÃ¡nÃ­ dotazÅ¯. Model se automaticky naÄte do pamÄ›ti.\n",
    "\n",
    "---\n",
    "\n",
    "## 3. **ZobrazenÃ­ seznamu dostupnÃ½ch modelÅ¯**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f75ed1e",
   "metadata": {},
   "source": [
    "### PÅ™Ã­klad 10\n",
    "\n",
    "### Co pÅ™Ã­klad demonstruje:\n",
    "ZobrazenÃ­ vÅ¡ech lokÃ¡lnÄ› nainstalovanÃ½ch modelÅ¯ pomocÃ­ Ollama."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae002c3f",
   "metadata": {},
   "source": [
    "### PÅ™Ã­klad 11\n",
    "\n",
    "### KompletnÃ­ kÃ³d s ÄeskÃ½mi komentÃ¡Å™i:\n",
    "\n",
    "```bash\n",
    "# ZobrazÃ­ seznam vÅ¡ech modelÅ¯ nainstalovanÃ½ch na systÃ©mu\n",
    "ollama list\n",
    "\n",
    "# MÅ¯Å¾eÅ¡ takÃ© pouÅ¾Ã­t:\n",
    "ollama ls\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c4c41fc",
   "metadata": {},
   "source": [
    "### PÅ™Ã­klad 12\n",
    "\n",
    "### OÄekÃ¡vanÃ½ vÃ½stup:\n",
    "```\n",
    "NAME                   ID        SIZE      MODIFIED\n",
    "llama3                 7c84a9    4.1 GB    2 hours ago\n",
    "mistral                5f3d9a    3.8 GB    1 day ago\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b112b0f0",
   "metadata": {},
   "source": [
    "### PÅ™Ã­klad 13\n",
    "\n",
    "### VysvÄ›tlenÃ­:\n",
    "PÅ™Ã­kaz `ollama list` (nebo `ollama ls`) vypÃ­Å¡e vÅ¡echny modely, kterÃ© jsou momentÃ¡lnÄ› nainstalovanÃ© v Ollama. Obsahuje informace o ID, velikosti a Äase poslednÃ­ zmÄ›ny.\n",
    "\n",
    "---\n",
    "\n",
    "## 4. **NastavenÃ­ GPU akcelerace (pokud je k dispozici)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bd185b2",
   "metadata": {},
   "source": [
    "### PÅ™Ã­klad 14\n",
    "\n",
    "### Co pÅ™Ã­klad demonstruje:\n",
    "PouÅ¾itÃ­ GPU pro zrychlenÃ­ provozu modelÅ¯ v Ollama."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e579ce7",
   "metadata": {},
   "source": [
    "### PÅ™Ã­klad 15\n",
    "\n",
    "### KompletnÃ­ kÃ³d s ÄeskÃ½mi komentÃ¡Å™i:\n",
    "\n",
    "```bash\n",
    "# Zkontroluj, zda mÃ¡Å¡ podporu GPU (pokud pouÅ¾Ã­vÃ¡Å¡ NVIDIA)\n",
    "nvidia-smi\n",
    "\n",
    "# SpusÅ¥ model s vyuÅ¾itÃ­m GPU (pokud je dostupnÃ©)\n",
    "ollama run llama3\n",
    "\n",
    "# V pÅ™Ã­padÄ› potÅ™eby mÅ¯Å¾eÅ¡ explicitnÄ› zadat, Å¾e chceÅ¡ pouÅ¾Ã­t GPU:\n",
    "OLLAMA_NUM_PARALLEL=1 ollama run llama3\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcfc1b26",
   "metadata": {},
   "source": [
    "### PÅ™Ã­klad 16\n",
    "\n",
    "### OÄekÃ¡vanÃ½ vÃ½stup:\n",
    "```\n",
    "GPU support detected: CUDA available.\n",
    "Model loaded with GPU acceleration.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17ede0c8",
   "metadata": {},
   "source": [
    "### PÅ™Ã­klad 17\n",
    "\n",
    "### VysvÄ›tlenÃ­:\n",
    "Pokud je k dispozici podpora GPU (napÅ™. CUDA), Ollama automaticky pouÅ¾ije GPU pro zrychlenÃ­ operacÃ­. VÃ½stup `nvidia-smi` ukazuje, Å¾e mÃ¡me dostupnÃ© grafickÃ© karty.\n",
    "\n",
    "---\n",
    "\n",
    "## 5. **VytvoÅ™enÃ­ vlastnÃ­ho modelu s pomocÃ­ Ollama**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b81047cd",
   "metadata": {},
   "source": [
    "### PÅ™Ã­klad 18\n",
    "\n",
    "### Co pÅ™Ã­klad demonstruje:\n",
    "VytvoÅ™enÃ­ jednoduchÃ©ho vlastnÃ­ho modelu na zÃ¡kladÄ› Å¡ablony pomocÃ­ `Modelfile`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbca1893",
   "metadata": {},
   "source": [
    "### PÅ™Ã­klad 19\n",
    "\n",
    "### KompletnÃ­ kÃ³d s ÄeskÃ½mi komentÃ¡Å™i:\n",
    "\n",
    "```bash\n",
    "# VytvoÅ™ soubor Modelfile\n",
    "cat > my-model-llama3 << EOF\n",
    "FROM llama3\n",
    "PARAMETER temperature 0.7\n",
    "PARAMETER top_p 0.9\n",
    "SYSTEM \"\"\"\n",
    "Jsi uÅ¾iteÄnÃ½ asistent, kterÃ½ odpovÃ­dÃ¡ v ÄeÅ¡tinÄ›.\n",
    "\"\"\"\n",
    "EOF\n",
    "\n",
    "# VytvoÅ™ model z Modelfile\n",
    "ollama create my-model -f my-model-llama3\n",
    "\n",
    "# SpusÅ¥ novÄ› vytvoÅ™enÃ½ model\n",
    "ollama run my-model\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b222932c",
   "metadata": {},
   "source": [
    "### PÅ™Ã­klad 20\n",
    "\n",
    "### OÄekÃ¡vanÃ½ vÃ½stup:\n",
    "```\n",
    "> Jak se mÃ¡Å¡?\n",
    "Jsem dobrÃ½ asistent, dÄ›kuji za dotaz.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "376c5caf",
   "metadata": {},
   "source": [
    "### PÅ™Ã­klad 21\n",
    "\n",
    "### VysvÄ›tlenÃ­:\n",
    "`Modelfile` je textovÃ½ soubor definujÃ­cÃ­ model â€“ zÃ¡kladnÃ­ model (napÅ™. `llama3`), parametry a systÃ©movou instrukci. PÅ™Ã­kaz `ollama create` vytvoÅ™Ã­ novÃ½ model podle tÃ©to Å¡ablony. PotÃ© mÅ¯Å¾eÅ¡ pouÅ¾Ã­t tento model stejnÄ› jako jinÃ©.\n",
    "\n",
    "---\n",
    "\n",
    "## ShrnutÃ­\n",
    "\n",
    "Tyto pÅ™Ã­klady ukazujÃ­ zÃ¡kladnÃ­ prÃ¡ci s Ollama â€“ od instalace a spuÅ¡tÄ›nÃ­ modelu, pÅ™es sprÃ¡vu modelÅ¯, aÅ¾ po vytvÃ¡Å™enÃ­ vlastnÃ­ch modelÅ¯ s vlastnÃ­mi nastavenÃ­mi. VÅ¡echny pÅ™Ã­klady jsou samostatnÃ© a lze je spustit na jakÃ©mkoli systÃ©mu podporujÃ­cÃ­m Ollama.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fc182fa",
   "metadata": {},
   "source": [
    "## ğŸ¯ CviÄenÃ­ a Ãºkoly\n",
    "\n",
    "<div style=\"background: #fff3e0; padding: 20px; border-left: 5px solid #ff9800; margin: 20px 0; border-radius: 5px;\">\n",
    "    <h3 style=\"color: #2c3e50; margin-top: 0;\">âœï¸ PraktickÃ¡ cviÄenÃ­ k procviÄenÃ­</h3>\n",
    "    <p>VyÅ™eÅ¡te nÃ¡sledujÃ­cÃ­ Ãºkoly. ZaÄnÄ›te od jednoduÅ¡Å¡Å¡Ã­ch a postupujte k sloÅ¾itÄ›jÅ¡Ã­m.</p>\n",
    "</div>\n",
    "\n",
    "# CviÄenÃ­: Ãšvod do LLM a Ollama\n",
    "\n",
    "---\n",
    "\n",
    "## CviÄenÃ­ 1: Instalace a spuÅ¡tÄ›nÃ­ prvnÃ­ho modelu pomocÃ­ Ollama\n",
    "\n",
    "### 1. **NÃ¡zev Ãºkolu**\n",
    "Instalace Ollama a spuÅ¡tÄ›nÃ­ prvnÃ­ho LLM modelu\n",
    "\n",
    "### 2. **DetailnÃ­ zadÃ¡nÃ­**\n",
    "Student si nainstaluje Ollama na svÅ¯j poÄÃ­taÄ (podle operaÄnÃ­ho systÃ©mu), spustÃ­ server, stÃ¡hne a spustÃ­ zÃ¡kladnÃ­ LLM model (napÅ™. `llama3` nebo `mistral`) a provede jednoduchÃ½ testovacÃ­ dotaz pomocÃ­ pÅ™Ã­kazovÃ© Å™Ã¡dky.\n",
    "\n",
    "### 3. **VstupnÃ­ data/poÅ¾adavky**\n",
    "- Linux, Windows nebo macOS\n",
    "- PÅ™Ã­stup k pÅ™Ã­kazovÃ© Å™Ã¡dce\n",
    "- InternetovÃ© pÅ™ipojenÃ­ (pro stahovÃ¡nÃ­ modelÅ¯)\n",
    "- PÅ™Ã­padnÄ› nainstalovanÃ½ `curl` nebo `ollama` klient\n",
    "\n",
    "### 4. **OÄekÃ¡vanÃ½ vÃ½stup**\n",
    "- Ollama server bÄ›Å¾Ã­\n",
    "- Model je staÅ¾en a spuÅ¡tÄ›n\n",
    "- VÃ½stup z modelu na testovacÃ­ dotaz (napÅ™. â€Jak se mÃ¡Å¡?â€œ)\n",
    "\n",
    "### 5. **Hints/NÃ¡povÄ›da**\n",
    "1. StÃ¡hni Ollama podle svÃ©ho OS: https://ollama.com/download\n",
    "2. SpusÅ¥ `ollama run llama3` v terminÃ¡lu a zadej dotaz.\n",
    "3. Zkontroluj, Å¾e je model dostupnÃ½ pÅ™es `ollama list`.\n",
    "4. MÅ¯Å¾eÅ¡ pouÅ¾Ã­t `curl` pro testovÃ¡nÃ­ REST API (`http://localhost:11434`).\n",
    "\n",
    "### 6. **Kostra Å™eÅ¡enÃ­**\n",
    "```bash\n",
    "# Instalace Ollama (napÅ™. na Linux)\n",
    "curl -fsSL https://ollama.com/install.sh | sh\n",
    "\n",
    "# SpuÅ¡tÄ›nÃ­ modelu\n",
    "ollama run llama3\n",
    "\n",
    "# TestovacÃ­ dotaz v interaktivnÃ­m reÅ¾imu\n",
    "> Jak se mÃ¡Å¡?\n",
    "\n",
    "# VÃ½stup by mÄ›l bÃ½t text odpovÄ›di modelu\n",
    "```\n",
    "\n",
    "### 7. **BonusovÃ© rozÅ¡Ã­Å™enÃ­**\n",
    "PouÅ¾ij REST API Ollama k odeslÃ¡nÃ­ dotazu z Python skriptu:\n",
    "\n",
    "```python\n",
    "import requests\n",
    "\n",
    "response = requests.post(\"http://localhost:11434/api/generate\", \n",
    "                        json={\"model\": \"llama3\", \"prompt\": \"Jak se mÃ¡Å¡?\"})\n",
    "print(response.json()['response'])\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## CviÄenÃ­ 2: VytvoÅ™enÃ­ jednoduchÃ©ho chatbotu pÅ™es Ollama REST API\n",
    "\n",
    "### 1. **NÃ¡zev Ãºkolu**\n",
    "VytvoÅ™enÃ­ chatovacÃ­ho robota pomocÃ­ Ollama REST API\n",
    "\n",
    "### 2. **DetailnÃ­ zadÃ¡nÃ­**\n",
    "Student vytvoÅ™Ã­ jednoduchÃ½ Python skript, kterÃ½ komunikuje s Ollama serverem pÅ™es REST API. Skript bude umoÅ¾Åˆovat zadÃ¡vat dotazy a zÃ­skÃ¡vat odpovÄ›di od modelu (napÅ™. `llama3`) v interaktivnÃ­m reÅ¾imu.\n",
    "\n",
    "### 3. **VstupnÃ­ data/poÅ¾adavky**\n",
    "- SpuÅ¡tÄ›nÃ½ Ollama server\n",
    "- Python 3.x\n",
    "- Knihovna `requests`\n",
    "\n",
    "### 4. **OÄekÃ¡vanÃ½ vÃ½stup**\n",
    "- InteraktivnÃ­ chatovacÃ­ aplikace, kterÃ¡ se dotazuje na uÅ¾ivatele a odpovÃ­dÃ¡ z modelu.\n",
    "- PrÅ¯bÄ›Å¾nÃ© vÃ½stupy (pÅ™i kaÅ¾dÃ©m dotazu).\n",
    "\n",
    "### 5. **Hints/NÃ¡povÄ›da**\n",
    "1. SpusÅ¥ `ollama run llama3` pro zajiÅ¡tÄ›nÃ­ dostupnosti modelu.\n",
    "2. PouÅ¾ij `requests.post()` na endpoint `/api/generate`.\n",
    "3. VytvoÅ™ cyklus, kterÃ½ Äte vstup a posÃ­lÃ¡ dotaz.\n",
    "4. MÅ¯Å¾eÅ¡ pouÅ¾Ã­t `stream=True` pro reÃ¡lnÃ½ vÃ½stup.\n",
    "\n",
    "### 6. **Kostra Å™eÅ¡enÃ­**\n",
    "```python\n",
    "import requests\n",
    "\n",
    "def chat_with_model():\n",
    "    while True:\n",
    "        prompt = input(\"Ty: \")\n",
    "        if prompt.lower() in [\"quit\", \"exit\"]:\n",
    "            break\n",
    "        response = requests.post(\"http://localhost:11434/api/generate\",\n",
    "                                json={\"model\": \"llama3\", \"prompt\": prompt})\n",
    "        print(\"Model:\", response.json()['response'])\n",
    "\n",
    "chat_with_model()\n",
    "```\n",
    "\n",
    "### 7. **BonusovÃ© rozÅ¡Ã­Å™enÃ­**\n",
    "PÅ™idej historii konverzace pomocÃ­ `messages` v JSONu (pokud podporuje model).\n",
    "\n",
    "---\n",
    "\n",
    "## CviÄenÃ­ 3: VytvoÅ™enÃ­ vlastnÃ­ho promptu pro LLM\n",
    "\n",
    "### 1. **NÃ¡zev Ãºkolu**\n",
    "VytvoÅ™enÃ­ efektivnÃ­ho promptu pro konkrÃ©tnÃ­ Ãºkol\n",
    "\n",
    "### 2. **DetailnÃ­ zadÃ¡nÃ­**\n",
    "Student navrhne a otestuje prompt, kterÃ½ instruuje model k vykonÃ¡nÃ­ specifickÃ©ho Ãºkolu (napÅ™. â€PÅ™eloÅ¾ nÃ¡sledujÃ­cÃ­ text do angliÄtinyâ€œ nebo â€VytvoÅ™ struÄnÃ½ shrnutÃ­ tohoto ÄlÃ¡nkuâ€œ). VÃ½sledek porovnÃ¡ s rÅ¯znÃ½mi verzemi promptu.\n",
    "\n",
    "### 3. **VstupnÃ­ data/poÅ¾adavky**\n",
    "- SpuÅ¡tÄ›nÃ½ model (napÅ™. `llama3`)\n",
    "- VstupnÃ­ text k zpracovÃ¡nÃ­\n",
    "\n",
    "### 4. **OÄekÃ¡vanÃ½ vÃ½stup**\n",
    "- VytvoÅ™enÃ½ prompt a jeho testovacÃ­ vÃ½sledek\n",
    "- PorovnÃ¡nÃ­ efektivity rÅ¯znÃ½ch promptÅ¯ (napÅ™. s nebo bez instrukcÃ­)\n",
    "\n",
    "### 5. **Hints/NÃ¡povÄ›da**\n",
    "1. ZkouÅ¡ej rÅ¯znÃ© formy promptu: â€PÅ™eloÅ¾ do angliÄtinyâ€œ, â€PÅ™eloÅ¾ do angliÄtiny a udrÅ¾uj stylâ€œ, â€PÅ™eloÅ¾ do angliÄtiny, vytvoÅ™ shrnutÃ­â€œ.\n",
    "2. VyzkouÅ¡ej pouÅ¾itÃ­ â€Instructâ€œ stylu: â€Instrukce: pÅ™eklÃ¡dej nÃ¡sledujÃ­cÃ­ text.â€œ\n",
    "3. PÅ™idej kontext nebo role modelu (napÅ™. â€Jsi profesionÃ¡lnÃ­ pÅ™ekladatelâ€œ).\n",
    "4. MÅ¯Å¾eÅ¡ pouÅ¾Ã­t `ollama run` s rÅ¯znÃ½mi prompty a porovnat.\n",
    "\n",
    "### 6. **Kostra Å™eÅ¡enÃ­**\n",
    "```bash\n",
    "# PÅ™Ã­klad promptu\n",
    "ollama run llama3\n",
    "\n",
    "> Instrukce: PÅ™eloÅ¾ nÃ¡sledujÃ­cÃ­ text do angliÄtiny.\n",
    "> Vstup: VÃ­tejte v naÅ¡Ã­ aplikaci, kterÃ¡ pomÃ¡hÃ¡ uÅ¾ivatelÅ¯m zÃ­skat informace rychle a jednoduÅ¡e.\n",
    "\n",
    "# OdpovÄ›Ä modelu\n",
    "```\n",
    "\n",
    "### 7. **BonusovÃ© rozÅ¡Ã­Å™enÃ­**\n",
    "VytvoÅ™ Python skript, kterÃ½ automaticky testuje nÄ›kolik promptÅ¯ a porovnÃ¡vÃ¡ jejich vÃ½sledky (napÅ™. podle kvality pÅ™ekladu).\n",
    "\n",
    "---\n",
    "\n",
    "## CviÄenÃ­ 4: Integrace LLM do vlastnÃ­ho API\n",
    "\n",
    "### 1. **NÃ¡zev Ãºkolu**\n",
    "VytvoÅ™enÃ­ jednoduchÃ©ho REST API pro komunikaci s LLM\n",
    "\n",
    "### 2. **DetailnÃ­ zadÃ¡nÃ­**\n",
    "Student vytvoÅ™Ã­ jednoduchÃ© Flask API, kterÃ© pÅ™ijÃ­mÃ¡ poÅ¾adavky na zpracovÃ¡nÃ­ textu (napÅ™. pÅ™eklad nebo shrnutÃ­) a pouÅ¾Ã­vÃ¡ Ollama jako backend.\n",
    "\n",
    "### 3. **VstupnÃ­ data/poÅ¾adavky**\n",
    "- NainstalovanÃ½ Flask\n",
    "- SpuÅ¡tÄ›nÃ½ Ollama server\n",
    "\n",
    "### 4. **OÄekÃ¡vanÃ½ vÃ½stup**\n",
    "- REST API, kterÃ© pÅ™ijÃ­mÃ¡ JSON s textem a vracÃ­ odpovÄ›Ä modelu\n",
    "- FunkÄnÃ­ test pÅ™es `curl` nebo Postman\n",
    "\n",
    "### 5. **Hints/NÃ¡povÄ›da**\n",
    "1. Nainstaluj Flask (`pip install flask`)\n",
    "2. VytvoÅ™ endpoint `/process` pro\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3689ccaa",
   "metadata": {},
   "source": [
    "## ğŸ“š DalÅ¡Ã­ zdroje a materiÃ¡ly\n",
    "\n",
    "<div style=\"background: #e3f2fd; padding: 20px; border-left: 5px solid #2196f3; margin: 20px 0; border-radius: 5px;\">\n",
    "    <h3 style=\"color: #2c3e50; margin-top: 0;\">ğŸ”— DoporuÄenÃ© materiÃ¡ly k dalÅ¡Ã­mu studiu</h3>\n",
    "</div>\n",
    "\n",
    "# Zdroje pro kapitolu: Ãšvod do LLM a Ollama\n",
    "\n",
    "## 1. DoporuÄenÃ© ÄlÃ¡nky/tutoriÃ¡ly\n",
    "\n",
    "1. **[What are Large Language Models?](https://towardsdatascience.com/what-are-large-language-models-7e8b8a4d3f0c)** â€“ *Towards Data Science*  \n",
    "   PÅ™ehlednÃ© a jednoduchÃ© vysvÄ›tlenÃ­, co jsou LLM, jak fungujÃ­ a jak se liÅ¡Ã­ od tradiÄnÃ­ch modelÅ¯. SkvÄ›lÃ© pro zaÄÃ¡teÄnÃ­ky.\n",
    "\n",
    "2. **[Getting Started with Ollama](https://ollama.com/blog/getting-started)** â€“ *Ollama blog*  \n",
    "   OficiÃ¡lnÃ­ prÅ¯vodce pro instalaci a zÃ¡kladnÃ­ pouÅ¾itÃ­ Ollama. Obsahuje praktickÃ© pÅ™Ã­klady a vysvÄ›tlenÃ­ konceptu â€local AIâ€œ.\n",
    "\n",
    "3. **[A Visual Guide to LLMs](https://jalammar.github.io/visual-interactive-guide-bert-embeddings/)** â€“ *Jay Alammar*  \n",
    "   InteraktivnÃ­ a vizuÃ¡lnÃ­ pÅ™ehled architektury LLM, vÄetnÄ› BERT a GPT. VhodnÃ© pro lepÅ¡Ã­ porozumÄ›nÃ­ fungovÃ¡nÃ­ neuronovÃ½ch sÃ­tÃ­.\n",
    "\n",
    "4. **[Understanding Transformers](https://www.youtube.com/watch?v=UF8uR6Z6KLw)** â€“ *3Blue1Brown*  \n",
    "   AnimovanÃ½ vÃ½klad principu Transformer architektury (napÅ™. pouÅ¾Ã­vanÃ© v GPT). VhodnÃ© pro hlubÅ¡Ã­ porozumÄ›nÃ­ mechanismu LLM.\n",
    "\n",
    "5. **[LLM Use Cases and Applications](https://www.ibm.com/cloud/learn/what-are-large-language-models)** â€“ *IBM Cloud Learn*  \n",
    "   PÅ™ehled reÃ¡lnÃ½ch pouÅ¾itÃ­ LLM v prÅ¯myslu a technologiÃ­ch. Velmi vhodnÃ© pro pÅ™edstavu o praktickÃ©m vyuÅ¾itÃ­ modelÅ¯.\n",
    "\n",
    "---\n",
    "\n",
    "## 2. YouTube videa\n",
    "\n",
    "1. **[Ollama Explained - Install, Run, and Use Local AI Models](https://www.youtube.com/watch?v=QX3FVl0v6ZU)** â€“ *Derek Banas* (15 min)  \n",
    "   JednoduchÃ½ a praktickÃ½ Ãºvod do Ollama, vÄetnÄ› instalace a spuÅ¡tÄ›nÃ­ modelÅ¯ lokÃ¡lnÄ›.\n",
    "\n",
    "2. **[What are Large Language Models (LLMs)?](https://www.youtube.com/watch?v=9xS505V61d4)** â€“ *Lex Fridman* (23 min)  \n",
    "   Rozhovor s Lex Fridmanem o LLM, jejich vÃ½voji a budoucnosti. HlubÅ¡Ã­ pohled na technologii.\n",
    "\n",
    "3. **[How to Use Ollama with Python](https://www.youtube.com/watch?v=1V8F7Xx2YzE)** â€“ *AI Coding* (10 min)  \n",
    "   VÃ½ukovÃ© video pro zaÄÃ¡teÄnÃ­ky, jak integrovat Ollama do Python aplikacÃ­.\n",
    "\n",
    "---\n",
    "\n",
    "## 3. Knihy a oficiÃ¡lnÃ­ dokumentace\n",
    "\n",
    "1. **[The Illustrated Guide to Transformers](https://www.amazon.com/Illustrated-Guide-Transformers-Bert-GPT/dp/0578971610)** â€“ *Jay Alammar*  \n",
    "   VizuÃ¡lnÄ› pÅ™ehlednÃ¡ kniha o architektuÅ™e Transformer a jejÃ­ch aplikacÃ­ch, ideÃ¡lnÃ­ pro vÃ½klad LLM.\n",
    "\n",
    "2. **[Official Ollama Documentation](https://ollama.com/docs)**  \n",
    "   KompletnÃ­ prÅ¯vodce pouÅ¾itÃ­m Ollama â€“ instalace, konfigurace, modely a API.\n",
    "\n",
    "3. **[Deep Learning with Python by FranÃ§ois Chollet](https://www.manning.com/books/deep-learning-with-python)**  \n",
    "   HlubokÃ½ Ãºvod do neuronovÃ½ch sÃ­tÃ­ vÄetnÄ› kapitoly o transformeru â€“ dobrÃ½ zÃ¡klad pro rozumÄ›nÃ­ LLM.\n",
    "\n",
    "---\n",
    "\n",
    "## 4. PraktickÃ© projekty\n",
    "\n",
    "1. **VytvoÅ™enÃ­ jednoduchÃ©ho chatbotu pomocÃ­ Ollama a Pythonu**  \n",
    "   Implementace jednoduchÃ©ho\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf5f9d85",
   "metadata": {},
   "source": [
    "## ğŸ“ ShrnutÃ­ kapitoly\n",
    "\n",
    "<div style=\"background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); padding: 30px; border-radius: 10px; color: white; margin: 30px 0;\">\n",
    "    <h3 style=\"color: white; margin-top: 0;\">âœ… Co jste se nauÄili</h3>\n",
    "    <ul style=\"list-style: none; padding-left: 0;\">\n",
    "        <li>âœ“ LLM zÃ¡kladnÃ­ koncepty</li>\n",
    "<li>âœ“ Transformers architecture basics</li>\n",
    "<li>âœ“ Ollama installation vÅ¡echny OS</li>\n",
    "<li>âœ“ Model management commands</li>\n",
    "<li>âœ“ Ollama models overview</li>\n",
    "    </ul>\n",
    "    \n",
    "    <h3 style=\"color: white;\">ğŸ¯ KlÃ­ÄovÃ© dovednosti</h3>\n",
    "    <p>Po dokonÄenÃ­ tÃ©to kapitoly byste mÄ›li bÃ½t schopni prakticky pouÅ¾Ã­t vÅ¡echny probranÃ© koncepty.</p>\n",
    "    \n",
    "    <h3 style='color: white;'>â¡ï¸ DalÅ¡Ã­ kapitola</h3><p>Kapitola 32 - pokraÄujte ve studiu!</p>\n",
    "</div>\n",
    "\n",
    "---\n",
    "\n",
    "*ğŸ“… Notebook vygenerovÃ¡n: 2025-09-29 13:14:15*  \n",
    "*ğŸ¤– GenerÃ¡tor: Comprehensive Colab Generator v2.0*  \n",
    "*ğŸ“š UÄebnice programovÃ¡nÃ­ - Od zÃ¡kladÅ¯ k AI*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcfbfccb",
   "metadata": {},
   "source": [
    "## ğŸ§ª Sandbox - Prostor pro experimenty\n",
    "\n",
    "PouÅ¾ijte nÃ¡sledujÃ­cÃ­ buÅˆky pro vlastnÃ­ experimenty a testovÃ¡nÃ­:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b3991ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ§ª Zde mÅ¯Å¾ete experimentovat s kÃ³dem z kapitoly\n",
    "# NapiÅ¡te svÅ¯j kÃ³d zde:\n",
    "\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
