{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üé§ Whisper - P≈ôevod ≈ôeƒçi na text (Speech-to-Text)\n",
    "\n",
    "**Autor:** Praut s.r.o. - AI Integration & Business Automation\n",
    "\n",
    "## Co se nauƒç√≠te:\n",
    "- Transkripce audio soubor≈Ø\n",
    "- V√≠cejazyƒçn√° transkripce\n",
    "- Automatick√© titulky\n",
    "- Zpracov√°n√≠ sch≈Øzek a hovor≈Ø"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q transformers accelerate torch librosa soundfile datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline, WhisperProcessor, WhisperForConditionalGeneration\n",
    "import torch\n",
    "import librosa\n",
    "\n",
    "device = 0 if torch.cuda.is_available() else -1\n",
    "print(f\"üñ•Ô∏è Device: {'GPU' if device == 0 else 'CPU'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Z√°kladn√≠ transkripce s Whisper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Whisper pipeline\n",
    "whisper = pipeline(\n",
    "    \"automatic-speech-recognition\",\n",
    "    model=\"openai/whisper-base\",\n",
    "    device=device\n",
    ")\n",
    "\n",
    "# Pro demo pou≈æijeme sample z datasetu\n",
    "from datasets import load_dataset\n",
    "\n",
    "# Naƒçten√≠ sample audio\n",
    "dataset = load_dataset(\"hf-internal-testing/librispeech_asr_dummy\", \"clean\", split=\"validation[:1]\")\n",
    "sample = dataset[0]\n",
    "\n",
    "print(f\"üìä Audio info:\")\n",
    "print(f\"   Sampling rate: {sample['audio']['sampling_rate']} Hz\")\n",
    "print(f\"   D√©lka: {len(sample['audio']['array']) / sample['audio']['sampling_rate']:.1f} s\")\n",
    "\n",
    "# Transkripce\n",
    "result = whisper(sample['audio']['array'])\n",
    "\n",
    "print(f\"\\nüé§ Transkripce:\")\n",
    "print(f\"   {result['text']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. R≈Øzn√© velikosti Whisper model≈Ø"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dostupn√© modely:\n",
    "# - openai/whisper-tiny (39M parametr≈Ø)\n",
    "# - openai/whisper-base (74M)\n",
    "# - openai/whisper-small (244M)\n",
    "# - openai/whisper-medium (769M)\n",
    "# - openai/whisper-large-v3 (1.5B)\n",
    "\n",
    "print(\"üìä Porovn√°n√≠ Whisper model≈Ø:\\n\")\n",
    "print(\"| Model | Parametry | VRAM | Rychlost | P≈ôesnost |\")\n",
    "print(\"|-------|-----------|------|----------|----------|\")\n",
    "print(\"| tiny  | 39M       | ~1GB | Nejrychlej≈°√≠ | Z√°kladn√≠ |\")\n",
    "print(\"| base  | 74M       | ~1GB | Rychl√Ω   | Dobr√°    |\")\n",
    "print(\"| small | 244M      | ~2GB | St≈ôedn√≠  | Velmi dobr√° |\")\n",
    "print(\"| medium| 769M      | ~5GB | Pomal√Ω   | Vynikaj√≠c√≠ |\")\n",
    "print(\"| large | 1.5B      | ~10GB| Nejpomalej≈°√≠ | Nejlep≈°√≠ |\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naƒçten√≠ vƒõt≈°√≠ho modelu pro lep≈°√≠ p≈ôesnost\n",
    "whisper_small = pipeline(\n",
    "    \"automatic-speech-recognition\",\n",
    "    model=\"openai/whisper-small\",\n",
    "    device=device\n",
    ")\n",
    "\n",
    "result_small = whisper_small(sample['audio']['array'])\n",
    "\n",
    "print(\"üîç Porovn√°n√≠ v√Ωsledk≈Ø:\")\n",
    "print(f\"   Base:  {result['text']}\")\n",
    "print(f\"   Small: {result_small['text']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Transkripce s ƒçasov√Ωmi znaƒçkami"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transkripce s timestamps\n",
    "result_timestamps = whisper_small(\n",
    "    sample['audio']['array'],\n",
    "    return_timestamps=True\n",
    ")\n",
    "\n",
    "print(\"‚è±Ô∏è Transkripce s ƒçasov√Ωmi znaƒçkami:\\n\")\n",
    "\n",
    "if 'chunks' in result_timestamps:\n",
    "    for chunk in result_timestamps['chunks']:\n",
    "        start = chunk['timestamp'][0] if chunk['timestamp'][0] else 0\n",
    "        end = chunk['timestamp'][1] if chunk['timestamp'][1] else '?'\n",
    "        print(f\"   [{start:.1f}s - {end}s] {chunk['text']}\")\n",
    "else:\n",
    "    print(f\"   {result_timestamps['text']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. V√≠cejazyƒçn√° transkripce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Whisper automaticky detekuje jazyk\n",
    "# M≈Ø≈æeme ale specifikovat jazyk pro lep≈°√≠ v√Ωsledky\n",
    "\n",
    "def transkribuj(audio_array, jazyk=None):\n",
    "    \"\"\"Transkribuje audio s voliteln√Ωm urƒçen√≠m jazyka.\"\"\"\n",
    "    \n",
    "    generate_kwargs = {}\n",
    "    if jazyk:\n",
    "        generate_kwargs[\"language\"] = jazyk\n",
    "    \n",
    "    result = whisper_small(\n",
    "        audio_array,\n",
    "        generate_kwargs=generate_kwargs\n",
    "    )\n",
    "    \n",
    "    return result['text']\n",
    "\n",
    "# Podporovan√© jazyky (v√Ωbƒõr)\n",
    "print(\"üåç Podporovan√© jazyky Whisper:\")\n",
    "jazyky = [\n",
    "    \"english\", \"czech\", \"german\", \"french\", \"spanish\",\n",
    "    \"italian\", \"polish\", \"portuguese\", \"russian\", \"chinese\",\n",
    "    \"japanese\", \"korean\", \"arabic\", \"hindi\", \"turkish\"\n",
    "]\n",
    "print(f\"   {', '.join(jazyky)}\")\n",
    "print(\"   ... a dal≈°√≠ch 80+ jazyk≈Ø\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Generov√°n√≠ titulk≈Ø (SRT form√°t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generuj_srt(audio_array, sampling_rate=16000):\n",
    "    \"\"\"Generuje titulky ve form√°tu SRT.\"\"\"\n",
    "    \n",
    "    result = whisper_small(\n",
    "        audio_array,\n",
    "        return_timestamps=True,\n",
    "        chunk_length_s=30\n",
    "    )\n",
    "    \n",
    "    srt_lines = []\n",
    "    \n",
    "    if 'chunks' in result:\n",
    "        for i, chunk in enumerate(result['chunks'], 1):\n",
    "            start = chunk['timestamp'][0] if chunk['timestamp'][0] else 0\n",
    "            end = chunk['timestamp'][1] if chunk['timestamp'][1] else start + 5\n",
    "            \n",
    "            # Form√°tov√°n√≠ ƒçasu pro SRT\n",
    "            start_srt = f\"{int(start//3600):02d}:{int((start%3600)//60):02d}:{int(start%60):02d},{int((start%1)*1000):03d}\"\n",
    "            end_srt = f\"{int(end//3600):02d}:{int((end%3600)//60):02d}:{int(end%60):02d},{int((end%1)*1000):03d}\"\n",
    "            \n",
    "            srt_lines.append(f\"{i}\")\n",
    "            srt_lines.append(f\"{start_srt} --> {end_srt}\")\n",
    "            srt_lines.append(chunk['text'].strip())\n",
    "            srt_lines.append(\"\")\n",
    "    \n",
    "    return \"\\n\".join(srt_lines)\n",
    "\n",
    "# Generov√°n√≠ SRT\n",
    "srt = generuj_srt(sample['audio']['array'])\n",
    "print(\"üìù Vygenerovan√© SRT titulky:\\n\")\n",
    "print(srt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Zpracov√°n√≠ audio soubor≈Ø"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import soundfile as sf\n",
    "import numpy as np\n",
    "\n",
    "def transkribuj_soubor(cesta_k_souboru):\n",
    "    \"\"\"Transkribuje audio soubor (MP3, WAV, FLAC...).\"\"\"\n",
    "    \n",
    "    # Naƒçten√≠ audio\n",
    "    audio, sr = librosa.load(cesta_k_souboru, sr=16000)\n",
    "    \n",
    "    # Transkripce\n",
    "    result = whisper_small(\n",
    "        audio,\n",
    "        return_timestamps=True\n",
    "    )\n",
    "    \n",
    "    return {\n",
    "        'text': result['text'],\n",
    "        'chunks': result.get('chunks', []),\n",
    "        'duration': len(audio) / sr\n",
    "    }\n",
    "\n",
    "# Demo - vytvo≈ô√≠me testovac√≠ audio\n",
    "print(\"üìÅ Funkce transkribuj_soubor() p≈ôipravena.\")\n",
    "print(\"   Pou≈æit√≠: transkribuj_soubor('cesta/k/audio.mp3')\")\n",
    "print(\"   Podporovan√© form√°ty: MP3, WAV, FLAC, OGG, M4A\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. D√°vkov√© zpracov√°n√≠ v√≠ce soubor≈Ø"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "def zpracuj_slozku(cesta_slozky, pripony=['.mp3', '.wav', '.flac']):\n",
    "    \"\"\"Zpracuje v≈°echny audio soubory ve slo≈æce.\"\"\"\n",
    "    \n",
    "    vysledky = []\n",
    "    slozka = Path(cesta_slozky)\n",
    "    \n",
    "    soubory = [f for f in slozka.iterdir() if f.suffix.lower() in pripony]\n",
    "    \n",
    "    for soubor in soubory:\n",
    "        print(f\"   Zpracov√°v√°m: {soubor.name}\")\n",
    "        try:\n",
    "            result = transkribuj_soubor(str(soubor))\n",
    "            vysledky.append({\n",
    "                'soubor': soubor.name,\n",
    "                'delka_s': result['duration'],\n",
    "                'text': result['text'],\n",
    "                'status': 'OK'\n",
    "            })\n",
    "        except Exception as e:\n",
    "            vysledky.append({\n",
    "                'soubor': soubor.name,\n",
    "                'delka_s': 0,\n",
    "                'text': '',\n",
    "                'status': f'Error: {str(e)}'\n",
    "            })\n",
    "    \n",
    "    return pd.DataFrame(vysledky)\n",
    "\n",
    "print(\"üìÅ Funkce zpracuj_slozku() p≈ôipravena.\")\n",
    "print(\"   Pou≈æit√≠: zpracuj_slozku('/cesta/ke/slozce')\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. P≈ôeklad a transkripce z√°rove≈à"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Whisper um√≠ p≈ô√≠mo p≈ôekl√°dat do angliƒçtiny\n",
    "whisper_translate = pipeline(\n",
    "    \"automatic-speech-recognition\",\n",
    "    model=\"openai/whisper-small\",\n",
    "    device=device\n",
    ")\n",
    "\n",
    "def transkribuj_a_preloz(audio_array):\n",
    "    \"\"\"Transkribuje a p≈ôelo≈æ√≠ do angliƒçtiny.\"\"\"\n",
    "    \n",
    "    # P≈Øvodn√≠ transkripce\n",
    "    original = whisper_translate(audio_array)\n",
    "    \n",
    "    # P≈ôeklad do angliƒçtiny\n",
    "    translated = whisper_translate(\n",
    "        audio_array,\n",
    "        generate_kwargs={\"task\": \"translate\"}\n",
    "    )\n",
    "    \n",
    "    return {\n",
    "        'original': original['text'],\n",
    "        'english': translated['text']\n",
    "    }\n",
    "\n",
    "print(\"üåç Funkce transkribuj_a_preloz() p≈ôipravena.\")\n",
    "print(\"   P≈ôelo≈æ√≠ audio z libovoln√©ho jazyka do angliƒçtiny.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Zpracov√°n√≠ sch≈Øzek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zpracuj_schuzku(audio_array):\n",
    "    \"\"\"Zpracuje nahr√°vku sch≈Øzky a vytvo≈ô√≠ strukturovan√Ω v√Ωstup.\"\"\"\n",
    "    \n",
    "    # Transkripce s timestamps\n",
    "    result = whisper_small(\n",
    "        audio_array,\n",
    "        return_timestamps=True,\n",
    "        chunk_length_s=30\n",
    "    )\n",
    "    \n",
    "    # Struktura v√Ωstupu\n",
    "    output = {\n",
    "        'full_transcript': result['text'],\n",
    "        'duration_minutes': len(audio_array) / 16000 / 60,\n",
    "        'segments': []\n",
    "    }\n",
    "    \n",
    "    if 'chunks' in result:\n",
    "        for chunk in result['chunks']:\n",
    "            output['segments'].append({\n",
    "                'start': chunk['timestamp'][0],\n",
    "                'end': chunk['timestamp'][1],\n",
    "                'text': chunk['text'].strip()\n",
    "            })\n",
    "    \n",
    "    return output\n",
    "\n",
    "# Demo\n",
    "meeting = zpracuj_schuzku(sample['audio']['array'])\n",
    "\n",
    "print(\"üìã Z√°pis ze sch≈Øzky:\\n\")\n",
    "print(f\"D√©lka: {meeting['duration_minutes']:.1f} minut\")\n",
    "print(f\"\\nTranskript:\\n{meeting['full_transcript']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Praktick√° automatizace: Voice Notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "class VoiceNotesProcessor:\n",
    "    def __init__(self, model_name=\"openai/whisper-small\"):\n",
    "        self.whisper = pipeline(\n",
    "            \"automatic-speech-recognition\",\n",
    "            model=model_name,\n",
    "            device=device\n",
    "        )\n",
    "        self.notes = []\n",
    "    \n",
    "    def add_note(self, audio_array, title=None):\n",
    "        \"\"\"P≈ôid√° hlasovou pozn√°mku.\"\"\"\n",
    "        result = self.whisper(audio_array, return_timestamps=True)\n",
    "        \n",
    "        note = {\n",
    "            'id': len(self.notes) + 1,\n",
    "            'title': title or f\"Note {len(self.notes) + 1}\",\n",
    "            'timestamp': datetime.now().isoformat(),\n",
    "            'text': result['text'],\n",
    "            'duration': len(audio_array) / 16000\n",
    "        }\n",
    "        \n",
    "        self.notes.append(note)\n",
    "        return note\n",
    "    \n",
    "    def search_notes(self, keyword):\n",
    "        \"\"\"Vyhled√° v pozn√°mk√°ch.\"\"\"\n",
    "        return [n for n in self.notes if keyword.lower() in n['text'].lower()]\n",
    "    \n",
    "    def export_markdown(self):\n",
    "        \"\"\"Exportuje pozn√°mky do Markdown.\"\"\"\n",
    "        md = \"# Voice Notes\\n\\n\"\n",
    "        for note in self.notes:\n",
    "            md += f\"## {note['title']}\\n\"\n",
    "            md += f\"*{note['timestamp']}* ({note['duration']:.1f}s)\\n\\n\"\n",
    "            md += f\"{note['text']}\\n\\n---\\n\\n\"\n",
    "        return md\n",
    "\n",
    "# Demo\n",
    "processor = VoiceNotesProcessor()\n",
    "processor.add_note(sample['audio']['array'], \"Meeting notes\")\n",
    "\n",
    "print(\"üìù Voice Notes System:\")\n",
    "print(processor.export_markdown())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## üèÅ Shrnut√≠\n",
    "\n",
    "- ‚úÖ Whisper pro p≈ôesnou transkripci\n",
    "- ‚úÖ Podpora 90+ jazyk≈Ø\n",
    "- ‚úÖ Automatick√© titulky (SRT)\n",
    "- ‚úÖ D√°vkov√© zpracov√°n√≠ soubor≈Ø\n",
    "- ‚úÖ P≈ôeklad z ≈ôeƒçi do angliƒçtiny\n",
    "\n",
    "**Dal≈°√≠ notebook:** Computer Vision - klasifikace a detekce"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "accelerator": "GPU",
  "colab": {
   "provenance": [],
   "gpuType": "T4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
