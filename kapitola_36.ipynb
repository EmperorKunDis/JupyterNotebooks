{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kapitola 36: Rizika AI - Kdyz se dobry sluha stane zlym panem\n",
    "\n",
    "V teto kapitole se podivame na temnou stranu umele inteligence: algoritmickou nespravedlnost (bias), rizika zneuziti a jak provadet **audit fairness** nasich modelu.\n",
    "\n",
    "## Co se naucime:\n",
    "- Hlavni rizika AI (soukromi, autonomie, nespravedlnost)\n",
    "- Co je algoritmicky bias a jak vznika\n",
    "- Prakticky audit spravedlnosti na realnych datech\n",
    "- Metriky fairness a jak je interpretovat\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Instalace a import knihoven"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instalace potrebnych knihoven\n",
    "!pip install pandas scikit-learn seaborn matplotlib numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "# Nastaveni\n",
    "plt.rcParams['figure.figsize'] = [12, 6]\n",
    "sns.set_style('whitegrid')\n",
    "\n",
    "print(\"Knihovny nacteny!\")\n",
    "print()\n",
    "print(\"V teto kapitole se naucime:\")\n",
    "print(\"1. Jaká jsou hlavni rizika AI\")\n",
    "print(\"2. Co je algoritmicky bias\")\n",
    "print(\"3. Jak provadet audit spravedlnosti\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. Tri hlavni rizika umele inteligence\n",
    "\n",
    "AI prinasi obrovske moznosti, ale take vyznamna rizika:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vizualizace tri hlavnich rizik AI\n",
    "\n",
    "rizika = {\n",
    "    'Zneuziti dat\\na ztrata soukromi': [\n",
    "        'Digitalni profily bez souhlasu',\n",
    "        'Cilena manipulace',\n",
    "        'Odhaleni citlivych informaci'\n",
    "    ],\n",
    "    'Autonomni systemy\\na eticka dilemata': [\n",
    "        'Rozhodnuti samoridiciho auta',\n",
    "        'Kdo je zodpovedny za chybu?',\n",
    "        'Vojenske vyuziti AI'\n",
    "    ],\n",
    "    'Algoritmicka\\nnespravedlnost (Bias)': [\n",
    "        'Diskriminace pri prijimani',\n",
    "        'Nespravedlive uvery',\n",
    "        'Predpojatost ve zdravotnictvi'\n",
    "    ]\n",
    "}\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(16, 6))\n",
    "barvy = ['#ff6b6b', '#ffd93d', '#6bcb77']\n",
    "\n",
    "for ax, (nazev, priklady), barva in zip(axes, rizika.items(), barvy):\n",
    "    ax.add_patch(plt.Rectangle((0, 0), 1, 1, facecolor=barva, alpha=0.3))\n",
    "    ax.text(0.5, 0.85, nazev, ha='center', va='center', fontsize=13, fontweight='bold')\n",
    "    for i, priklad in enumerate(priklady):\n",
    "        ax.text(0.5, 0.55 - i*0.2, f'• {priklad}', ha='center', va='center', fontsize=10)\n",
    "    ax.set_xlim(0, 1)\n",
    "    ax.set_ylim(0, 1)\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.suptitle('Tri hlavni rizika umele inteligence', fontsize=16, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detailni vysvetleni\n",
    "print(\"=\" * 70)\n",
    "print(\"ALGORITMICKA NESPRAVEDLNOST (BIAS) - NEJZAKLADNEJSI PROBLEM\")\n",
    "print(\"=\" * 70)\n",
    "print()\n",
    "print(\"Jak bias vznika?\")\n",
    "print(\"-\" * 50)\n",
    "print(\"1. HISTORICKA DATA: Model se uci z minulosti\")\n",
    "print(\"   - V minulosti bylo mene zen na manaerskych pozicich\")\n",
    "print(\"   - Model se 'nauci', ze zeny jsou horsi kandidatky\")\n",
    "print()\n",
    "print(\"2. NEVYVAZENA DATA: Nerovnomerne zastoupeni skupin\")\n",
    "print(\"   - Malo dat o minoritach -> horsi predikce pro ne\")\n",
    "print()\n",
    "print(\"3. CHYBNE LABELY: Predpojati anotatori\")\n",
    "print(\"   - Lidske predsudky se prenesou do dat\")\n",
    "print()\n",
    "print(\"4. PROXY PROMENNE: Neprime diskriminacni znaky\")\n",
    "print(\"   - PSC muze korelovat s rasou\")\n",
    "print(\"   - Model diskriminuje, aniz by primo pouzival rasu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3. Dataset Adult - Predikce prijmu\n",
    "\n",
    "Pouzijeme slavny dataset **Adult** (Census Income) k demonstraci algoritmicke nespravedlnosti. Cilem je predpovedet, zda osoba vydela vice nez $50K rocne."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nacteni Adult datasetu\n",
    "url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data'\n",
    "columns = ['age', 'workclass', 'fnlwgt', 'education', 'education-num', 'marital-status',\n",
    "           'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss',\n",
    "           'hours-per-week', 'native-country', 'income']\n",
    "\n",
    "try:\n",
    "    df = pd.read_csv(url, header=None, names=columns, na_values=' ?', sep=', ', engine='python')\n",
    "    print(\"Data uspesne nactena z UCI repository!\")\n",
    "except:\n",
    "    # Fallback - vytvorime synteticka data\n",
    "    print(\"Vytvarim synteticka data pro demonstraci...\")\n",
    "    np.random.seed(42)\n",
    "    n = 5000\n",
    "    df = pd.DataFrame({\n",
    "        'age': np.random.randint(18, 70, n),\n",
    "        'education-num': np.random.randint(1, 16, n),\n",
    "        'hours-per-week': np.random.randint(10, 80, n),\n",
    "        'sex': np.random.choice(['Male', 'Female'], n, p=[0.65, 0.35]),\n",
    "        'race': np.random.choice(['White', 'Black', 'Asian', 'Other'], n, p=[0.7, 0.15, 0.1, 0.05]),\n",
    "        'income': np.random.choice(['<=50K', '>50K'], n, p=[0.75, 0.25])\n",
    "    })\n",
    "\n",
    "print(f\"\\nPocet zaznamu: {len(df)}\")\n",
    "print(f\"Pocet sloupcu: {len(df.columns)}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cisteni dat\n",
    "df_clean = df.dropna().copy()\n",
    "print(f\"Zaznamu po odstraneni chybejicich hodnot: {len(df_clean)}\")\n",
    "\n",
    "# Vizualizace rozdeleni prijmu podle pohlavi\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Rozdeleni prijmu\n",
    "income_counts = df_clean['income'].value_counts()\n",
    "axes[0].pie(income_counts.values, labels=income_counts.index, autopct='%1.1f%%', \n",
    "            colors=['#ff9999', '#99ff99'], startangle=90)\n",
    "axes[0].set_title('Rozdeleni prijmu v datasetu', fontsize=14)\n",
    "\n",
    "# Rozdeleni podle pohlavi\n",
    "sex_income = pd.crosstab(df_clean['sex'], df_clean['income'], normalize='index') * 100\n",
    "sex_income.plot(kind='bar', ax=axes[1], color=['#ff9999', '#99ff99'])\n",
    "axes[1].set_title('Prijem podle pohlavi (%)', fontsize=14)\n",
    "axes[1].set_xlabel('Pohlavi')\n",
    "axes[1].set_ylabel('Procento')\n",
    "axes[1].legend(['<=50K', '>50K'])\n",
    "axes[1].tick_params(axis='x', rotation=0)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nJiz v datech vidime nerovnost - muzi maji vyrazne vyssi sanci na vyssi prijem!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4. Trenink modelu\n",
    "\n",
    "Natrénujeme RandomForest klasifikator a zmerime jeho celkovou presnost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Priprava dat pro model\n",
    "df_model = df_clean.copy()\n",
    "\n",
    "# Ulozime si puvodni pohlavi pro pozdejsi audit\n",
    "sex_original = df_model['sex'].copy()\n",
    "race_original = df_model['race'].copy() if 'race' in df_model.columns else None\n",
    "\n",
    "# Encodovani kategorickych promennych\n",
    "label_encoders = {}\n",
    "for col in df_model.columns:\n",
    "    if df_model[col].dtype == 'object':\n",
    "        le = LabelEncoder()\n",
    "        df_model[col] = le.fit_transform(df_model[col].astype(str))\n",
    "        label_encoders[col] = le\n",
    "\n",
    "# Priprava X a y\n",
    "X = df_model.drop('income', axis=1)\n",
    "y = df_model['income']\n",
    "\n",
    "# Rozdeleni na trenovaci a testovaci data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Ulozime si odpovidajici pohlavi pro testovaci data\n",
    "test_indices = X_test.index\n",
    "sex_test = sex_original.loc[test_indices]\n",
    "\n",
    "print(f\"Trenovacich vzorku: {len(X_train)}\")\n",
    "print(f\"Testovacich vzorku: {len(X_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trenink modelu\n",
    "print(\"Trenuji RandomForest klasifikator...\")\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predikce\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Celkova presnost\n",
    "overall_accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(f\"CELKOVA PRESNOST MODELU: {overall_accuracy*100:.2f}%\")\n",
    "print(\"=\" * 60)\n",
    "print(\"\\nNa prvni pohled to vypada dobre! Ale je model spravedlivy?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 5. AUDIT SPRAVEDLNOSTI - Klicova cast!\n",
    "\n",
    "Ted provedeme **fairness audit** - zmerime, jak si model vede pro ruzne demograficke skupiny."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Priprava auditu\n",
    "audit_df = pd.DataFrame({\n",
    "    'sex': sex_test.values,\n",
    "    'true_income': y_test.values,\n",
    "    'predicted_income': y_pred\n",
    "})\n",
    "\n",
    "# Rozdelime podle pohlavi\n",
    "audit_male = audit_df[audit_df['sex'] == 'Male']\n",
    "audit_female = audit_df[audit_df['sex'] == 'Female']\n",
    "\n",
    "# Vypocet presnosti pro kazdou skupinu\n",
    "accuracy_male = accuracy_score(audit_male['true_income'], audit_male['predicted_income'])\n",
    "accuracy_female = accuracy_score(audit_female['true_income'], audit_female['predicted_income'])\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"AUDIT SPRAVEDLNOSTI PODLE POHLAVI\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\nCelkova presnost:     {overall_accuracy*100:.2f}%\")\n",
    "print(f\"Presnost pro MUZE:    {accuracy_male*100:.2f}%\")\n",
    "print(f\"Presnost pro ZENY:    {accuracy_female*100:.2f}%\")\n",
    "print(f\"\\nRozdil:               {abs(accuracy_male - accuracy_female)*100:.2f} procentnich bodu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vizualizace rozdilu\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Sloupcovy graf presnosti\n",
    "skupiny = ['Celkova', 'Muzi', 'Zeny']\n",
    "presnosti = [overall_accuracy, accuracy_male, accuracy_female]\n",
    "barvy = ['steelblue', '#4CAF50', '#FF5722']\n",
    "\n",
    "bars = axes[0].bar(skupiny, [p*100 for p in presnosti], color=barvy)\n",
    "axes[0].set_ylabel('Presnost (%)', fontsize=12)\n",
    "axes[0].set_title('Porovnani presnosti modelu', fontsize=14, fontweight='bold')\n",
    "axes[0].set_ylim(0, 100)\n",
    "\n",
    "# Pridani hodnot nad sloupce\n",
    "for bar, p in zip(bars, presnosti):\n",
    "    axes[0].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 1, \n",
    "                f'{p*100:.1f}%', ha='center', fontsize=11)\n",
    "\n",
    "# Horizontal bar pro porovnani\n",
    "disparity = abs(accuracy_male - accuracy_female) * 100\n",
    "axes[1].barh(['Rozdil v presnosti'], [disparity], color='red', alpha=0.7)\n",
    "axes[1].set_xlim(0, 20)\n",
    "axes[1].set_xlabel('Procentni body', fontsize=12)\n",
    "axes[1].set_title(f'Disparita mezi skupinami: {disparity:.2f}%', fontsize=14, fontweight='bold')\n",
    "\n",
    "# Hranice prijatelnosti\n",
    "axes[1].axvline(x=5, color='orange', linestyle='--', label='Hranice 5%')\n",
    "axes[1].axvline(x=10, color='red', linestyle='--', label='Hranice 10%')\n",
    "axes[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detailnejsi analyza - False Positive a False Negative Rate\n",
    "def calculate_rates(y_true, y_pred):\n",
    "    \"\"\"Vypocita ruzne metriky fairness.\"\"\"\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "    \n",
    "    # Metriky\n",
    "    accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
    "    tpr = tp / (tp + fn) if (tp + fn) > 0 else 0  # True Positive Rate (Recall)\n",
    "    fpr = fp / (fp + tn) if (fp + tn) > 0 else 0  # False Positive Rate\n",
    "    fnr = fn / (fn + tp) if (fn + tp) > 0 else 0  # False Negative Rate\n",
    "    \n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'tpr': tpr,\n",
    "        'fpr': fpr,\n",
    "        'fnr': fnr\n",
    "    }\n",
    "\n",
    "# Vypocet pro obe skupiny\n",
    "rates_male = calculate_rates(audit_male['true_income'], audit_male['predicted_income'])\n",
    "rates_female = calculate_rates(audit_female['true_income'], audit_female['predicted_income'])\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"DETAILNI METRIKY FAIRNESS\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"{'Metrika':<25} {'Muzi':>15} {'Zeny':>15} {'Rozdil':>15}\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "for metrika in ['accuracy', 'tpr', 'fpr', 'fnr']:\n",
    "    m = rates_male[metrika]\n",
    "    f = rates_female[metrika]\n",
    "    rozdil = abs(m - f)\n",
    "    print(f\"{metrika.upper():<25} {m*100:>14.2f}% {f*100:>14.2f}% {rozdil*100:>14.2f}%\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"VYSVETLENI METRIK:\")\n",
    "print(\"-\" * 70)\n",
    "print(\"TPR (True Positive Rate): Jak casto spravne predikujeme vyssi prijem\")\n",
    "print(\"FPR (False Positive Rate): Jak casto CHYBNE predikujeme vyssi prijem\")\n",
    "print(\"FNR (False Negative Rate): Jak casto CHYBNE predikujeme nizsi prijem\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 6. Interpretace vysledku - \"Aha!\" moment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interpretace\n",
    "print(\"=\" * 70)\n",
    "print(\"INTERPRETACE VYSLEDKU\")\n",
    "print(\"=\" * 70)\n",
    "print()\n",
    "print(\"CO JSME ZJISTILI?\")\n",
    "print(\"-\" * 50)\n",
    "print()\n",
    "print(\"1. CELKOVA PRESNOST vypada dobre (~85%)\")\n",
    "print(\"   -> Na prvni pohled model funguje!\")\n",
    "print()\n",
    "print(\"2. ALE kdyz se podivame na jednotlive skupiny...\")\n",
    "print(f\"   -> Pro muze: {accuracy_male*100:.1f}%\")\n",
    "print(f\"   -> Pro zeny: {accuracy_female*100:.1f}%\")\n",
    "print(f\"   -> Rozdil: {abs(accuracy_male-accuracy_female)*100:.1f} procentnich bodu\")\n",
    "print()\n",
    "print(\"3. PROC JE TO PROBLEM?\")\n",
    "print(\"   - Model SYSTEMATICKY znevyhodnuje jednu skupinu\")\n",
    "print(\"   - Pri 1000 rozhodnutich = stovky nespravedlivych pripadu\")\n",
    "print(\"   - Pokud model rozhoduje o uverech/praci = diskriminace\")\n",
    "print()\n",
    "print(\"4. KDE SE BIAS VZAL?\")\n",
    "print(\"   - Z historickych dat - odrazejí spo;ecenske nerovnosti\")\n",
    "print(\"   - Model se naucil existujici predsudky\")\n",
    "print(\"   - Neni to chyba AI, ale NASICH DAT\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 7. Reseni - Jak zmernit bias?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mozna reseni\n",
    "print(\"=\" * 70)\n",
    "print(\"JAK ZMERNIT ALGORITMICKOU NESPRAVEDLNOST?\")\n",
    "print(\"=\" * 70)\n",
    "print()\n",
    "\n",
    "reseni = [\n",
    "    (\"1. ODSTRANENI CITLIVYCH ATRIBUTU\", \n",
    "     \"Nepoužívat pohlavi, rasu, vek primo v modelu.\\n\"\n",
    "     \"   PROBLEM: Proxy promenne (PSC, jmeno) mohou stale korelovat.\"),\n",
    "    \n",
    "    (\"2. VYVAZENI DATASETU\",\n",
    "     \"Oversampling mensinovych skupin, undersampling vetsiny.\\n\"\n",
    "     \"   Zajisti rovnomerne zastoupeni vsech skupin.\"),\n",
    "    \n",
    "    (\"3. FAIRNESS-AWARE ALGORITMY\",\n",
    "     \"Specialni algoritmy jako: Fairlearn, AI Fairness 360.\\n\"\n",
    "     \"   Optimalizuji presnost i spravedlnost zaroven.\"),\n",
    "    \n",
    "    (\"4. POST-PROCESSING\",\n",
    "     \"Upravit prahy rozhodovani pro ruzne skupiny.\\n\"\n",
    "     \"   Vyrovnat False Positive/Negative rates.\"),\n",
    "    \n",
    "    (\"5. PRAVIDELNY AUDIT\",\n",
    "     \"Kontinualne monitorovat metriky fairness.\\n\"\n",
    "     \"   Odhalit drift a degradaci v case.\")\n",
    "]\n",
    "\n",
    "for nazev, popis in reseni:\n",
    "    print(f\"\\n{nazev}\")\n",
    "    print(\"-\" * 50)\n",
    "    print(f\"   {popis}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment: Model BEZ citlivych atributu\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"EXPERIMENT: Model bez pohlavi\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Odstranime pohlavi z features\n",
    "if 'sex' in X_train.columns:\n",
    "    X_train_fair = X_train.drop('sex', axis=1)\n",
    "    X_test_fair = X_test.drop('sex', axis=1)\n",
    "    \n",
    "    # Trenink noveho modelu\n",
    "    model_fair = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "    model_fair.fit(X_train_fair, y_train)\n",
    "    y_pred_fair = model_fair.predict(X_test_fair)\n",
    "    \n",
    "    # Audit\n",
    "    audit_fair = pd.DataFrame({\n",
    "        'sex': sex_test.values,\n",
    "        'true_income': y_test.values,\n",
    "        'predicted_income': y_pred_fair\n",
    "    })\n",
    "    \n",
    "    acc_fair_male = accuracy_score(\n",
    "        audit_fair[audit_fair['sex']=='Male']['true_income'],\n",
    "        audit_fair[audit_fair['sex']=='Male']['predicted_income']\n",
    "    )\n",
    "    acc_fair_female = accuracy_score(\n",
    "        audit_fair[audit_fair['sex']=='Female']['true_income'],\n",
    "        audit_fair[audit_fair['sex']=='Female']['predicted_income']\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nPuvodni model:\")\n",
    "    print(f\"  Muzi: {accuracy_male*100:.2f}%, Zeny: {accuracy_female*100:.2f}%\")\n",
    "    print(f\"  Rozdil: {abs(accuracy_male-accuracy_female)*100:.2f}%\")\n",
    "    print(f\"\\nModel BEZ pohlavi:\")\n",
    "    print(f\"  Muzi: {acc_fair_male*100:.2f}%, Zeny: {acc_fair_female*100:.2f}%\")\n",
    "    print(f\"  Rozdil: {abs(acc_fair_male-acc_fair_female)*100:.2f}%\")\n",
    "else:\n",
    "    print(\"Sloupec 'sex' neni v datech.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 8. Mini-kviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mini-kviz\n",
    "print(\"=\" * 60)\n",
    "print(\"KVIZ: RIZIKA AI A FAIRNESS\")\n",
    "print(\"=\" * 60)\n",
    "print()\n",
    "\n",
    "otazky = [\n",
    "    {\n",
    "        \"otazka\": \"1. Co je algoritmicky bias?\",\n",
    "        \"moznosti\": [\n",
    "            \"a) Chyba v kodu\",\n",
    "            \"b) Systematicke znevyhodnovani urcitych skupin\",\n",
    "            \"c) Pomalost algoritmu\",\n",
    "            \"d) Typ neuronove site\"\n",
    "        ],\n",
    "        \"spravna\": \"b\",\n",
    "        \"vysvetleni\": \"Bias je systematicka nespravedlnost, kdy model znevyhodnuje urcite demograficke skupiny.\"\n",
    "    },\n",
    "    {\n",
    "        \"otazka\": \"2. Odkud se bias nejcasteji bere?\",\n",
    "        \"moznosti\": [\n",
    "            \"a) Z hardwaru pocitace\",\n",
    "            \"b) Z historickych dat obsahujicich spolecenske nerovnosti\",\n",
    "            \"c) Z internetu\",\n",
    "            \"d) Z programovaciho jazyka\"\n",
    "        ],\n",
    "        \"spravna\": \"b\",\n",
    "        \"vysvetleni\": \"Model se uci z dat, ktera casto odrazeji existujici spolecenske predsudky a nerovnosti.\"\n",
    "    },\n",
    "    {\n",
    "        \"otazka\": \"3. Proc nestaci merit jen celkovou presnost modelu?\",\n",
    "        \"moznosti\": [\n",
    "            \"a) Celkova presnost je vzdy spatna\",\n",
    "            \"b) Muze skryvat velke rozdily mezi skupinami\",\n",
    "            \"c) Je prilis slozita na vypocet\",\n",
    "            \"d) Nema zadny vyznam\"\n",
    "        ],\n",
    "        \"spravna\": \"b\",\n",
    "        \"vysvetleni\": \"Vysoka celkova presnost muze maskovat fakt, ze model funguje spatne pro minoritni skupiny.\"\n",
    "    },\n",
    "    {\n",
    "        \"otazka\": \"4. Co je proxy promenna?\",\n",
    "        \"moznosti\": [\n",
    "            \"a) Promenna zastupujici jinou, citlivou promennou\",\n",
    "            \"b) Skryta vrstva neuronove site\",\n",
    "            \"c) Typ databaze\",\n",
    "            \"d) Metoda trenovani\"\n",
    "        ],\n",
    "        \"spravna\": \"a\",\n",
    "        \"vysvetleni\": \"Proxy promenna (napr. PSC) muze korelovat s citlivymi atributy (rasa) a umoznit neprimou diskriminaci.\"\n",
    "    },\n",
    "    {\n",
    "        \"otazka\": \"5. Co je prvni krok k naprave algoritmicke nespravedlnosti?\",\n",
    "        \"moznosti\": [\n",
    "            \"a) Vyhodit model\",\n",
    "            \"b) Merit a auditovat fairness metriky\",\n",
    "            \"c) Pouzit jiny programovaci jazyk\",\n",
    "            \"d) Ignorovat problem\"\n",
    "        ],\n",
    "        \"spravna\": \"b\",\n",
    "        \"vysvetleni\": \"Prvnim krokem je vzdy mereni - bez auditu nevime, ze problem existuje.\"\n",
    "    }\n",
    "]\n",
    "\n",
    "for q in otazky:\n",
    "    print(q[\"otazka\"])\n",
    "    for m in q[\"moznosti\"]:\n",
    "        print(f\"   {m}\")\n",
    "    print(f\"   Spravna odpoved: {q['spravna']}\")\n",
    "    print(f\"   > {q['vysvetleni']}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 9. Shrnuti kapitoly\n",
    "\n",
    "| Koncept | Popis |\n",
    "|---------|-------|\n",
    "| **Algoritmicky bias** | Systematicke znevyhodnovani urcitych skupin modelem |\n",
    "| **Fairness audit** | Mereni presnosti pro ruzne demograficke skupiny |\n",
    "| **TPR/FPR/FNR** | Metriky pro hodnoceni spravedlnosti |\n",
    "| **Proxy promenne** | Promenne neprime korelujici s citlivymi atributy |\n",
    "| **Fairness-aware ML** | Algoritmy optimalizujici presnost i spravedlnost |\n",
    "\n",
    "### Klicove poznatky:\n",
    "- Vysoka celkova presnost nezarucuje spravedlnost\n",
    "- Bias pochazi z dat, ne z AI samotne\n",
    "- Mereni je prvni krok k naprave\n",
    "- Odpovednost za fer AI lezi na nas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 10. Vyzva pro vas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VYZVA 1: Audit podle rasy\n",
    "print(\"VYZVA 1: Provedte audit podle rasy\")\n",
    "print(\"=\"*50)\n",
    "print()\n",
    "print(\"Modifikujte kod auditu tak, aby analyzoval\")\n",
    "print(\"rozdily v presnosti mezi rasovymi skupinami.\")\n",
    "print()\n",
    "print(\"Otazky k zamysleni:\")\n",
    "print(\"- Jsou rozdily mezi rasami vetsi nez mezi pohlavimi?\")\n",
    "print(\"- Ktera skupina je nejvice znevyhodnena?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VYZVA 2: Vyzkousejte fairness knihovnu\n",
    "print(\"VYZVA 2: Pouzijte knihovnu Fairlearn\")\n",
    "print(\"=\"*50)\n",
    "print()\n",
    "print(\"Instalace: pip install fairlearn\")\n",
    "print()\n",
    "print(\"Fairlearn nabizi:\")\n",
    "print(\"- MetricFrame pro audit\")\n",
    "print(\"- Mitigacni algoritmy\")\n",
    "print(\"- Vizualizacni nastroje\")\n",
    "print()\n",
    "print(\"Dokumentace: https://fairlearn.org/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VYZVA 3: Eticky rozmer\n",
    "print(\"VYZVA 3: Zamyslete se nad etickymi otazkami\")\n",
    "print(\"=\"*50)\n",
    "print()\n",
    "print(\"1. Mel by se model pouzit pro rozhodovani o uverech?\")\n",
    "print(\"2. Kdo je zodpovedny za diskriminacni rozhodnuti - vyvojar nebo uzivatel?\")\n",
    "print(\"3. Je 'fer' mit stejnou presnost pro vsechny skupiny?\")\n",
    "print(\"4. Jak vyvazit presnost a spravedlnost?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Dalsi kroky\n",
    "\n",
    "V pristich kapitolach se naucime:\n",
    "- Pokrocile techniky mitigace biasu\n",
    "- Interpretovatelnost modelu (proc model rozhoduje tak, jak rozhoduje)\n",
    "- Nasazeni AI do produkce zodpovednym zpusobem\n",
    "\n",
    "**Pamatujte: S velkou moci prichazi velka zodpovednost. Jako tvurci AI mame povinnost budovat systemy, ktere jsou fer pro vsechny!**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
