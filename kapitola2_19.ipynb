{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üìÑ Document AI: OCR, Anal√Ωza Layoutu a Extrakce Dat\n",
    "\n",
    "**Autor:** Martin Studna, Praut s.r.o.  \n",
    "**Notebook:** 19/20 - Pokroƒçil√© zpracov√°n√≠ dokument≈Ø\n",
    "\n",
    "---\n",
    "\n",
    "## Co se nauƒç√≠te\n",
    "\n",
    "1. **OCR s Transformery** - TrOCR pro rozpozn√°v√°n√≠ textu z obr√°zk≈Ø\n",
    "2. **Anal√Ωza layoutu** - LayoutLM pro pochopen√≠ struktury dokument≈Ø\n",
    "3. **Extrakce z formul√°≈ô≈Ø** - Donut pro strukturovanou extrakci dat\n",
    "4. **Table extraction** - Extrakce tabulek z dokument≈Ø\n",
    "5. **Produkƒçn√≠ Document Pipeline** - End-to-end ≈ôe≈°en√≠\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîß Instalace a Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instalace pot≈ôebn√Ωch knihoven\n",
    "!pip install -q transformers torch torchvision pillow pdf2image pytesseract\n",
    "!pip install -q datasets evaluate accelerate sentencepiece\n",
    "!pip install -q opencv-python-headless img2table\n",
    "\n",
    "# Pro Colab - instalace syst√©mov√Ωch z√°vislost√≠\n",
    "!apt-get install -y poppler-utils tesseract-ocr tesseract-ocr-ces 2>/dev/null || true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import io\n",
    "import json\n",
    "import re\n",
    "from typing import Dict, List, Optional, Tuple, Any, Union\n",
    "from dataclasses import dataclass, field\n",
    "from collections import defaultdict\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Detekce za≈ô√≠zen√≠\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"üñ•Ô∏è Pou≈æ√≠v√°m za≈ô√≠zen√≠: {device}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"   GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"   Pamƒõ≈•: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üìù ƒå√°st 1: OCR s TrOCR\n",
    "\n",
    "TrOCR (Transformer-based Optical Character Recognition) kombinuje vision encoder s textov√Ωm decoderem pro p≈ôesn√© rozpozn√°v√°n√≠ textu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrOCRProcessor, VisionEncoderDecoderModel\n",
    "\n",
    "class TrOCREngine:\n",
    "    \"\"\"OCR engine zalo≈æen√Ω na TrOCR modelu.\"\"\"\n",
    "    \n",
    "    def __init__(self, model_name: str = \"microsoft/trocr-base-printed\"):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            model_name: N√°zev modelu (printed/handwritten)\n",
    "                - microsoft/trocr-base-printed - pro ti≈°tƒõn√Ω text\n",
    "                - microsoft/trocr-base-handwritten - pro rukou psan√Ω text\n",
    "        \"\"\"\n",
    "        print(f\"üì• Naƒç√≠t√°m TrOCR model: {model_name}\")\n",
    "        self.processor = TrOCRProcessor.from_pretrained(model_name)\n",
    "        self.model = VisionEncoderDecoderModel.from_pretrained(model_name)\n",
    "        self.model.to(device)\n",
    "        self.model.eval()\n",
    "        print(\"‚úÖ Model naƒçten\")\n",
    "    \n",
    "    def recognize_text(self, image: Image.Image, max_length: int = 128) -> str:\n",
    "        \"\"\"Rozpozn√° text z obr√°zku.\"\"\"\n",
    "        # Konverze na RGB pokud pot≈ôeba\n",
    "        if image.mode != 'RGB':\n",
    "            image = image.convert('RGB')\n",
    "        \n",
    "        # P≈ô√≠prava vstup≈Ø\n",
    "        pixel_values = self.processor(image, return_tensors='pt').pixel_values\n",
    "        pixel_values = pixel_values.to(device)\n",
    "        \n",
    "        # Generov√°n√≠ textu\n",
    "        with torch.no_grad():\n",
    "            generated_ids = self.model.generate(\n",
    "                pixel_values,\n",
    "                max_length=max_length,\n",
    "                num_beams=4,\n",
    "                early_stopping=True\n",
    "            )\n",
    "        \n",
    "        # Dek√≥dov√°n√≠\n",
    "        text = self.processor.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
    "        return text.strip()\n",
    "    \n",
    "    def recognize_lines(self, image: Image.Image, line_boxes: List[Tuple[int, int, int, int]]) -> List[str]:\n",
    "        \"\"\"Rozpozn√° text z v√≠ce ≈ô√°dk≈Ø.\"\"\"\n",
    "        results = []\n",
    "        for box in line_boxes:\n",
    "            # V√Ω≈ôez ≈ô√°dku\n",
    "            line_image = image.crop(box)\n",
    "            text = self.recognize_text(line_image)\n",
    "            results.append(text)\n",
    "        return results\n",
    "\n",
    "# Test TrOCR\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TEST TrOCR Engine\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_test_document_image(text_lines: List[str], \n",
    "                               width: int = 800, \n",
    "                               height: int = 600,\n",
    "                               font_size: int = 24) -> Image.Image:\n",
    "    \"\"\"Vytvo≈ô√≠ testovac√≠ obr√°zek dokumentu s textem.\"\"\"\n",
    "    # B√≠l√© pozad√≠\n",
    "    image = Image.new('RGB', (width, height), color='white')\n",
    "    draw = ImageDraw.Draw(image)\n",
    "    \n",
    "    # Pou≈æit√≠ z√°kladn√≠ho fontu\n",
    "    try:\n",
    "        font = ImageFont.truetype(\"/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf\", font_size)\n",
    "    except:\n",
    "        font = ImageFont.load_default()\n",
    "    \n",
    "    # Kreslen√≠ textu\n",
    "    y_position = 50\n",
    "    line_height = font_size + 15\n",
    "    \n",
    "    for line in text_lines:\n",
    "        draw.text((50, y_position), line, fill='black', font=font)\n",
    "        y_position += line_height\n",
    "    \n",
    "    return image\n",
    "\n",
    "# Vytvo≈ôen√≠ testovac√≠ho dokumentu\n",
    "test_lines = [\n",
    "    \"FAKTURA c. 2024-001234\",\n",
    "    \"Dodavatel: Praut s.r.o.\",\n",
    "    \"ICO: 12345678\",\n",
    "    \"Datum vystaveni: 15.01.2024\",\n",
    "    \"Celkova castka: 12 500 Kc\"\n",
    "]\n",
    "\n",
    "test_image = create_test_document_image(test_lines)\n",
    "display(test_image)\n",
    "print(\"üìÑ Testovac√≠ dokument vytvo≈ôen\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicializace a test TrOCR\n",
    "ocr_engine = TrOCREngine(\"microsoft/trocr-base-printed\")\n",
    "\n",
    "# Vytvo≈ôen√≠ jednotliv√Ωch ≈ô√°dk≈Ø pro OCR\n",
    "def create_single_line_image(text: str, width: int = 600, height: int = 50) -> Image.Image:\n",
    "    \"\"\"Vytvo≈ô√≠ obr√°zek s jedn√≠m ≈ô√°dkem textu.\"\"\"\n",
    "    image = Image.new('RGB', (width, height), color='white')\n",
    "    draw = ImageDraw.Draw(image)\n",
    "    \n",
    "    try:\n",
    "        font = ImageFont.truetype(\"/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf\", 28)\n",
    "    except:\n",
    "        font = ImageFont.load_default()\n",
    "    \n",
    "    draw.text((10, 10), text, fill='black', font=font)\n",
    "    return image\n",
    "\n",
    "# Test na jednotliv√Ωch ≈ô√°dc√≠ch\n",
    "print(\"\\nüìñ V√Ωsledky OCR:\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "for original_text in test_lines[:3]:  # Test prvn√≠ch 3 ≈ô√°dk≈Ø\n",
    "    line_image = create_single_line_image(original_text)\n",
    "    recognized_text = ocr_engine.recognize_text(line_image)\n",
    "    \n",
    "    print(f\"Original:   '{original_text}'\")\n",
    "    print(f\"Recognized: '{recognized_text}'\")\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üìê ƒå√°st 2: Anal√Ωza Layoutu s LayoutLM\n",
    "\n",
    "LayoutLM kombinuje textov√© embeddingy s prostorov√Ωmi informacemi pro pochopen√≠ struktury dokument≈Ø."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import LayoutLMv3Processor, LayoutLMv3ForTokenClassification\n",
    "from transformers import LayoutLMv3ForSequenceClassification\n",
    "\n",
    "class DocumentLayoutAnalyzer:\n",
    "    \"\"\"Analyz√°tor struktury dokument≈Ø pomoc√≠ LayoutLMv3.\"\"\"\n",
    "    \n",
    "    # ≈†t√≠tky pro klasifikaci entit v dokumentech\n",
    "    ENTITY_LABELS = [\n",
    "        'O',           # Outside - nen√≠ entita\n",
    "        'B-HEADER',    # Zaƒç√°tek z√°hlav√≠\n",
    "        'I-HEADER',    # Uvnit≈ô z√°hlav√≠\n",
    "        'B-QUESTION',  # Zaƒç√°tek ot√°zky\n",
    "        'I-QUESTION',  # Uvnit≈ô ot√°zky\n",
    "        'B-ANSWER',    # Zaƒç√°tek odpovƒõdi\n",
    "        'I-ANSWER',    # Uvnit≈ô odpovƒõdi\n",
    "        'B-KEY',       # Zaƒç√°tek kl√≠ƒçe (label)\n",
    "        'I-KEY',       # Uvnit≈ô kl√≠ƒçe\n",
    "        'B-VALUE',     # Zaƒç√°tek hodnoty\n",
    "        'I-VALUE',     # Uvnit≈ô hodnoty\n",
    "    ]\n",
    "    \n",
    "    def __init__(self, model_name: str = \"microsoft/layoutlmv3-base\"):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            model_name: N√°zev LayoutLM modelu\n",
    "        \"\"\"\n",
    "        print(f\"üì• Naƒç√≠t√°m LayoutLMv3: {model_name}\")\n",
    "        self.processor = LayoutLMv3Processor.from_pretrained(\n",
    "            model_name,\n",
    "            apply_ocr=True  # Automatick√© OCR\n",
    "        )\n",
    "        self.model = LayoutLMv3ForTokenClassification.from_pretrained(\n",
    "            model_name,\n",
    "            num_labels=len(self.ENTITY_LABELS)\n",
    "        )\n",
    "        self.model.to(device)\n",
    "        self.model.eval()\n",
    "        print(\"‚úÖ LayoutLMv3 naƒçten\")\n",
    "    \n",
    "    def analyze_document(self, image: Image.Image) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Analyzuje strukturu dokumentu.\n",
    "        \n",
    "        Returns:\n",
    "            Dict obsahuj√≠c√≠:\n",
    "            - words: Seznam slov\n",
    "            - boxes: Bounding boxy slov\n",
    "            - entities: Detekovan√© entity\n",
    "        \"\"\"\n",
    "        # Konverze na RGB\n",
    "        if image.mode != 'RGB':\n",
    "            image = image.convert('RGB')\n",
    "        \n",
    "        # P≈ô√≠prava vstup≈Ø (processor provede OCR automaticky)\n",
    "        encoding = self.processor(\n",
    "            image,\n",
    "            return_tensors='pt',\n",
    "            truncation=True,\n",
    "            max_length=512\n",
    "        )\n",
    "        \n",
    "        # P≈ôesun na device\n",
    "        encoding = {k: v.to(device) for k, v in encoding.items()}\n",
    "        \n",
    "        # Inference\n",
    "        with torch.no_grad():\n",
    "            outputs = self.model(**encoding)\n",
    "        \n",
    "        # Zpracov√°n√≠ v√Ωsledk≈Ø\n",
    "        predictions = outputs.logits.argmax(-1).squeeze().cpu().numpy()\n",
    "        \n",
    "        # Extrakce slov a box≈Ø\n",
    "        words = encoding.get('input_ids', [])\n",
    "        boxes = encoding.get('bbox', [])\n",
    "        \n",
    "        # Dek√≥dov√°n√≠ token≈Ø\n",
    "        tokens = self.processor.tokenizer.convert_ids_to_tokens(\n",
    "            encoding['input_ids'].squeeze().cpu().numpy()\n",
    "        )\n",
    "        \n",
    "        # Sestaven√≠ v√Ωsledk≈Ø\n",
    "        results = {\n",
    "            'tokens': tokens,\n",
    "            'predictions': [self.ENTITY_LABELS[p] for p in predictions],\n",
    "            'boxes': boxes.squeeze().cpu().numpy().tolist() if torch.is_tensor(boxes) else [],\n",
    "            'entities': self._extract_entities(tokens, predictions)\n",
    "        }\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def _extract_entities(self, tokens: List[str], predictions: np.ndarray) -> List[Dict]:\n",
    "        \"\"\"Extrahuje entity z predikc√≠.\"\"\"\n",
    "        entities = []\n",
    "        current_entity = None\n",
    "        current_tokens = []\n",
    "        \n",
    "        for i, (token, pred_idx) in enumerate(zip(tokens, predictions)):\n",
    "            label = self.ENTITY_LABELS[pred_idx]\n",
    "            \n",
    "            if label.startswith('B-'):\n",
    "                # Ulo≈æen√≠ p≈ôedchoz√≠ entity\n",
    "                if current_entity:\n",
    "                    entities.append({\n",
    "                        'type': current_entity,\n",
    "                        'text': self._merge_tokens(current_tokens)\n",
    "                    })\n",
    "                \n",
    "                # Nov√° entita\n",
    "                current_entity = label[2:]\n",
    "                current_tokens = [token]\n",
    "            \n",
    "            elif label.startswith('I-') and current_entity:\n",
    "                current_tokens.append(token)\n",
    "            \n",
    "            else:\n",
    "                # Konec entity\n",
    "                if current_entity:\n",
    "                    entities.append({\n",
    "                        'type': current_entity,\n",
    "                        'text': self._merge_tokens(current_tokens)\n",
    "                    })\n",
    "                current_entity = None\n",
    "                current_tokens = []\n",
    "        \n",
    "        # Posledn√≠ entita\n",
    "        if current_entity:\n",
    "            entities.append({\n",
    "                'type': current_entity,\n",
    "                'text': self._merge_tokens(current_tokens)\n",
    "            })\n",
    "        \n",
    "        return entities\n",
    "    \n",
    "    def _merge_tokens(self, tokens: List[str]) -> str:\n",
    "        \"\"\"Spoj√≠ tokeny do textu.\"\"\"\n",
    "        text = ' '.join(tokens)\n",
    "        # Odstranƒõn√≠ speci√°ln√≠ch token≈Ø a mezer u ## token≈Ø\n",
    "        text = text.replace(' ##', '')\n",
    "        text = re.sub(r'\\s+', ' ', text)\n",
    "        return text.strip()\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"DocumentLayoutAnalyzer p≈ôipraven\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vytvo≈ôen√≠ strukturovan√©ho testovac√≠ho dokumentu\n",
    "def create_form_image() -> Image.Image:\n",
    "    \"\"\"Vytvo≈ô√≠ obr√°zek formul√°≈ôe.\"\"\"\n",
    "    width, height = 600, 400\n",
    "    image = Image.new('RGB', (width, height), color='white')\n",
    "    draw = ImageDraw.Draw(image)\n",
    "    \n",
    "    try:\n",
    "        font = ImageFont.truetype(\"/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf\", 18)\n",
    "        font_bold = ImageFont.truetype(\"/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf\", 22)\n",
    "    except:\n",
    "        font = ImageFont.load_default()\n",
    "        font_bold = font\n",
    "    \n",
    "    # Z√°hlav√≠\n",
    "    draw.text((200, 20), \"OBJEDNAVKA\", fill='black', font=font_bold)\n",
    "    \n",
    "    # Pole formul√°≈ôe\n",
    "    fields = [\n",
    "        (\"Cislo objednavky:\", \"OBJ-2024-001\"),\n",
    "        (\"Datum:\", \"15.01.2024\"),\n",
    "        (\"Zakaznik:\", \"Jan Novak\"),\n",
    "        (\"Email:\", \"jan.novak@email.cz\"),\n",
    "        (\"Produkt:\", \"AI Automatizace\"),\n",
    "        (\"Castka:\", \"25 000 Kc\"),\n",
    "    ]\n",
    "    \n",
    "    y = 70\n",
    "    for label, value in fields:\n",
    "        draw.text((50, y), label, fill='gray', font=font)\n",
    "        draw.text((250, y), value, fill='black', font=font)\n",
    "        y += 45\n",
    "    \n",
    "    # R√°meƒçky\n",
    "    draw.rectangle([40, 60, 560, 340], outline='lightgray', width=2)\n",
    "    draw.line([40, 55, 560, 55], fill='lightgray', width=2)\n",
    "    \n",
    "    return image\n",
    "\n",
    "form_image = create_form_image()\n",
    "display(form_image)\n",
    "print(\"üìã Testovac√≠ formul√°≈ô vytvo≈ôen\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test LayoutLM analyz√°toru\n",
    "layout_analyzer = DocumentLayoutAnalyzer()\n",
    "\n",
    "# Anal√Ωza dokumentu\n",
    "results = layout_analyzer.analyze_document(form_image)\n",
    "\n",
    "print(\"\\nüìä V√Ωsledky anal√Ωzy layoutu:\")\n",
    "print(\"-\" * 50)\n",
    "print(f\"Poƒçet token≈Ø: {len(results['tokens'])}\")\n",
    "print(f\"\\nPrvn√≠ch 20 token≈Ø:\")\n",
    "for i, (token, pred) in enumerate(zip(results['tokens'][:20], results['predictions'][:20])):\n",
    "    if token not in ['<s>', '</s>', '<pad>']:\n",
    "        print(f\"  {token:20} -> {pred}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üç© ƒå√°st 3: Donut - Document Understanding Transformer\n",
    "\n",
    "Donut je end-to-end model pro extrakci strukturovan√Ωch dat z dokument≈Ø bez pot≈ôeby OCR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DonutProcessor, VisionEncoderDecoderModel as DonutModel\n",
    "\n",
    "class DonutDocumentExtractor:\n",
    "    \"\"\"Extraktor dat z dokument≈Ø pomoc√≠ Donut modelu.\"\"\"\n",
    "    \n",
    "    def __init__(self, model_name: str = \"naver-clova-ix/donut-base-finetuned-cord-v2\"):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            model_name: N√°zev Donut modelu\n",
    "                - naver-clova-ix/donut-base-finetuned-cord-v2 - pro √∫ƒçtenky\n",
    "                - naver-clova-ix/donut-base-finetuned-docvqa - pro DocVQA\n",
    "        \"\"\"\n",
    "        print(f\"üì• Naƒç√≠t√°m Donut model: {model_name}\")\n",
    "        self.processor = DonutProcessor.from_pretrained(model_name)\n",
    "        self.model = DonutModel.from_pretrained(model_name)\n",
    "        self.model.to(device)\n",
    "        self.model.eval()\n",
    "        print(\"‚úÖ Donut model naƒçten\")\n",
    "    \n",
    "    def extract_data(self, image: Image.Image, task_prompt: str = \"<s_cord-v2>\") -> Dict:\n",
    "        \"\"\"\n",
    "        Extrahuje strukturovan√° data z dokumentu.\n",
    "        \n",
    "        Args:\n",
    "            image: Obr√°zek dokumentu\n",
    "            task_prompt: Prompt pro typ extrakce\n",
    "        \n",
    "        Returns:\n",
    "            Strukturovan√° data z dokumentu\n",
    "        \"\"\"\n",
    "        # Konverze na RGB\n",
    "        if image.mode != 'RGB':\n",
    "            image = image.convert('RGB')\n",
    "        \n",
    "        # P≈ô√≠prava vstup≈Ø\n",
    "        pixel_values = self.processor(image, return_tensors='pt').pixel_values\n",
    "        pixel_values = pixel_values.to(device)\n",
    "        \n",
    "        # P≈ô√≠prava decoder input\n",
    "        decoder_input_ids = self.processor.tokenizer(\n",
    "            task_prompt, \n",
    "            add_special_tokens=False, \n",
    "            return_tensors='pt'\n",
    "        ).input_ids\n",
    "        decoder_input_ids = decoder_input_ids.to(device)\n",
    "        \n",
    "        # Generov√°n√≠\n",
    "        with torch.no_grad():\n",
    "            outputs = self.model.generate(\n",
    "                pixel_values,\n",
    "                decoder_input_ids=decoder_input_ids,\n",
    "                max_length=self.model.decoder.config.max_position_embeddings,\n",
    "                early_stopping=True,\n",
    "                pad_token_id=self.processor.tokenizer.pad_token_id,\n",
    "                eos_token_id=self.processor.tokenizer.eos_token_id,\n",
    "                use_cache=True,\n",
    "                num_beams=4,\n",
    "                bad_words_ids=[[self.processor.tokenizer.unk_token_id]],\n",
    "                return_dict_in_generate=True,\n",
    "            )\n",
    "        \n",
    "        # Dek√≥dov√°n√≠ v√Ωstupu\n",
    "        sequence = self.processor.batch_decode(outputs.sequences)[0]\n",
    "        sequence = sequence.replace(self.processor.tokenizer.eos_token, '')\n",
    "        sequence = sequence.replace(self.processor.tokenizer.pad_token, '')\n",
    "        \n",
    "        # Parsov√°n√≠ do JSON\n",
    "        parsed = self.processor.token2json(sequence)\n",
    "        \n",
    "        return {\n",
    "            'raw_output': sequence,\n",
    "            'parsed': parsed\n",
    "        }\n",
    "    \n",
    "    def answer_question(self, image: Image.Image, question: str) -> str:\n",
    "        \"\"\"\n",
    "        Odpov√≠d√° na ot√°zky o dokumentu (pro DocVQA model).\n",
    "        \n",
    "        Args:\n",
    "            image: Obr√°zek dokumentu\n",
    "            question: Ot√°zka v p≈ôirozen√©m jazyce\n",
    "        \n",
    "        Returns:\n",
    "            Odpovƒõƒè na ot√°zku\n",
    "        \"\"\"\n",
    "        task_prompt = f\"<s_docvqa><s_question>{question}</s_question><s_answer>\"\n",
    "        result = self.extract_data(image, task_prompt)\n",
    "        \n",
    "        # Extrakce odpovƒõdi\n",
    "        answer = result['parsed'].get('answer', result['raw_output'])\n",
    "        return answer\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"DonutDocumentExtractor p≈ôipraven\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vytvo≈ôen√≠ testovac√≠ √∫ƒçtenky\n",
    "def create_receipt_image() -> Image.Image:\n",
    "    \"\"\"Vytvo≈ô√≠ obr√°zek √∫ƒçtenky.\"\"\"\n",
    "    width, height = 400, 500\n",
    "    image = Image.new('RGB', (width, height), color='white')\n",
    "    draw = ImageDraw.Draw(image)\n",
    "    \n",
    "    try:\n",
    "        font = ImageFont.truetype(\"/usr/share/fonts/truetype/dejavu/DejaVuSansMono.ttf\", 14)\n",
    "        font_bold = ImageFont.truetype(\"/usr/share/fonts/truetype/dejavu/DejaVuSansMono-Bold.ttf\", 16)\n",
    "    except:\n",
    "        font = ImageFont.load_default()\n",
    "        font_bold = font\n",
    "    \n",
    "    y = 20\n",
    "    center_x = width // 2\n",
    "    \n",
    "    # Z√°hlav√≠\n",
    "    lines = [\n",
    "        \"================================\",\n",
    "        \"      PRAUT COFFEE SHOP        \",\n",
    "        \"    Karlovy Vary, Cheb 123     \",\n",
    "        \"       ICO: 12345678           \",\n",
    "        \"================================\",\n",
    "        \"\",\n",
    "        \"Datum: 15.01.2024  14:32\",\n",
    "        \"Pokladna: 1  Obsluha: Jana\",\n",
    "        \"--------------------------------\",\n",
    "        \"Cappuccino      2x    89.00\",\n",
    "        \"Espresso        1x    59.00\",\n",
    "        \"Cheesecake      1x   125.00\",\n",
    "        \"Croissant       2x    65.00\",\n",
    "        \"--------------------------------\",\n",
    "        \"Celkem:              427.00 Kc\",\n",
    "        \"DPH 15%:              55.70 Kc\",\n",
    "        \"================================\",\n",
    "        \"Hotove:              500.00 Kc\",\n",
    "        \"Vratit:               73.00 Kc\",\n",
    "        \"================================\",\n",
    "        \"\",\n",
    "        \"     Dekujeme za navstevu!     \",\n",
    "    ]\n",
    "    \n",
    "    for line in lines:\n",
    "        # Centrov√°n√≠\n",
    "        bbox = draw.textbbox((0, 0), line, font=font)\n",
    "        text_width = bbox[2] - bbox[0]\n",
    "        x = (width - text_width) // 2\n",
    "        draw.text((x, y), line, fill='black', font=font)\n",
    "        y += 20\n",
    "    \n",
    "    return image\n",
    "\n",
    "receipt_image = create_receipt_image()\n",
    "display(receipt_image)\n",
    "print(\"üßæ Testovac√≠ √∫ƒçtenka vytvo≈ôena\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Donut extraktoru\n",
    "donut_extractor = DonutDocumentExtractor()\n",
    "\n",
    "# Extrakce dat z √∫ƒçtenky\n",
    "extraction_result = donut_extractor.extract_data(receipt_image)\n",
    "\n",
    "print(\"\\nüç© V√Ωsledky Donut extrakce:\")\n",
    "print(\"-\" * 50)\n",
    "print(\"\\nParsovan√° data:\")\n",
    "print(json.dumps(extraction_result['parsed'], indent=2, ensure_ascii=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üìä ƒå√°st 4: Extrakce Tabulek\n",
    "\n",
    "Specializovan√© ≈ôe≈°en√≠ pro detekci a extrakci tabulek z dokument≈Ø."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TableTransformerForObjectDetection, DetrImageProcessor\n",
    "\n",
    "class TableExtractor:\n",
    "    \"\"\"Extraktor tabulek z dokument≈Ø pomoc√≠ Table Transformer.\"\"\"\n",
    "    \n",
    "    LABELS = ['table', 'table column', 'table row', 'table column header', \n",
    "              'table projected row header', 'table spanning cell']\n",
    "    \n",
    "    def __init__(self, detection_threshold: float = 0.7):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            detection_threshold: Pr√°h pro detekci tabulek\n",
    "        \"\"\"\n",
    "        print(\"üì• Naƒç√≠t√°m Table Transformer...\")\n",
    "        \n",
    "        # Model pro detekci tabulek\n",
    "        self.detector_processor = DetrImageProcessor.from_pretrained(\n",
    "            \"microsoft/table-transformer-detection\"\n",
    "        )\n",
    "        self.detector = TableTransformerForObjectDetection.from_pretrained(\n",
    "            \"microsoft/table-transformer-detection\"\n",
    "        )\n",
    "        self.detector.to(device)\n",
    "        self.detector.eval()\n",
    "        \n",
    "        # Model pro rozpozn√°n√≠ struktury tabulky\n",
    "        self.structure_processor = DetrImageProcessor.from_pretrained(\n",
    "            \"microsoft/table-transformer-structure-recognition\"\n",
    "        )\n",
    "        self.structure_model = TableTransformerForObjectDetection.from_pretrained(\n",
    "            \"microsoft/table-transformer-structure-recognition\"\n",
    "        )\n",
    "        self.structure_model.to(device)\n",
    "        self.structure_model.eval()\n",
    "        \n",
    "        self.threshold = detection_threshold\n",
    "        print(\"‚úÖ Table Transformer naƒçten\")\n",
    "    \n",
    "    def detect_tables(self, image: Image.Image) -> List[Dict]:\n",
    "        \"\"\"\n",
    "        Detekuje tabulky v obr√°zku.\n",
    "        \n",
    "        Returns:\n",
    "            Seznam detekovan√Ωch tabulek s bounding boxy\n",
    "        \"\"\"\n",
    "        if image.mode != 'RGB':\n",
    "            image = image.convert('RGB')\n",
    "        \n",
    "        # P≈ô√≠prava vstup≈Ø\n",
    "        inputs = self.detector_processor(images=image, return_tensors='pt')\n",
    "        inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "        \n",
    "        # Detekce\n",
    "        with torch.no_grad():\n",
    "            outputs = self.detector(**inputs)\n",
    "        \n",
    "        # Post-processing\n",
    "        target_sizes = torch.tensor([image.size[::-1]]).to(device)\n",
    "        results = self.detector_processor.post_process_object_detection(\n",
    "            outputs, threshold=self.threshold, target_sizes=target_sizes\n",
    "        )[0]\n",
    "        \n",
    "        tables = []\n",
    "        for score, label, box in zip(results['scores'], results['labels'], results['boxes']):\n",
    "            tables.append({\n",
    "                'confidence': score.item(),\n",
    "                'box': box.cpu().numpy().tolist(),\n",
    "                'label': 'table'\n",
    "            })\n",
    "        \n",
    "        return tables\n",
    "    \n",
    "    def analyze_structure(self, image: Image.Image, table_box: List[float]) -> Dict:\n",
    "        \"\"\"\n",
    "        Analyzuje strukturu tabulky (≈ô√°dky, sloupce, bu≈àky).\n",
    "        \n",
    "        Args:\n",
    "            image: Obr√°zek dokumentu\n",
    "            table_box: Bounding box tabulky [x1, y1, x2, y2]\n",
    "        \n",
    "        Returns:\n",
    "            Struktura tabulky\n",
    "        \"\"\"\n",
    "        # V√Ω≈ôez tabulky\n",
    "        x1, y1, x2, y2 = [int(c) for c in table_box]\n",
    "        table_image = image.crop((x1, y1, x2, y2))\n",
    "        \n",
    "        if table_image.mode != 'RGB':\n",
    "            table_image = table_image.convert('RGB')\n",
    "        \n",
    "        # P≈ô√≠prava vstup≈Ø\n",
    "        inputs = self.structure_processor(images=table_image, return_tensors='pt')\n",
    "        inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "        \n",
    "        # Anal√Ωza struktury\n",
    "        with torch.no_grad():\n",
    "            outputs = self.structure_model(**inputs)\n",
    "        \n",
    "        # Post-processing\n",
    "        target_sizes = torch.tensor([table_image.size[::-1]]).to(device)\n",
    "        results = self.structure_processor.post_process_object_detection(\n",
    "            outputs, threshold=0.5, target_sizes=target_sizes\n",
    "        )[0]\n",
    "        \n",
    "        # Organizace v√Ωsledk≈Ø podle typu\n",
    "        structure = {\n",
    "            'rows': [],\n",
    "            'columns': [],\n",
    "            'headers': [],\n",
    "            'cells': []\n",
    "        }\n",
    "        \n",
    "        label_map = {\n",
    "            0: 'table',\n",
    "            1: 'columns',\n",
    "            2: 'rows',\n",
    "            3: 'headers',\n",
    "            4: 'spanning_cells',\n",
    "            5: 'spanning_cells'\n",
    "        }\n",
    "        \n",
    "        for score, label, box in zip(results['scores'], results['labels'], results['boxes']):\n",
    "            label_idx = label.item()\n",
    "            element_type = label_map.get(label_idx, 'unknown')\n",
    "            \n",
    "            element = {\n",
    "                'confidence': score.item(),\n",
    "                'box': box.cpu().numpy().tolist()\n",
    "            }\n",
    "            \n",
    "            if element_type == 'rows':\n",
    "                structure['rows'].append(element)\n",
    "            elif element_type == 'columns':\n",
    "                structure['columns'].append(element)\n",
    "            elif element_type == 'headers':\n",
    "                structure['headers'].append(element)\n",
    "        \n",
    "        # Odvozen√≠ bunƒõk z pr≈Øniku ≈ô√°dk≈Ø a sloupc≈Ø\n",
    "        structure['cells'] = self._compute_cells(structure['rows'], structure['columns'])\n",
    "        \n",
    "        return structure\n",
    "    \n",
    "    def _compute_cells(self, rows: List[Dict], columns: List[Dict]) -> List[Dict]:\n",
    "        \"\"\"Vypoƒç√≠t√° bu≈àky z pr≈Ønik≈Ø ≈ô√°dk≈Ø a sloupc≈Ø.\"\"\"\n",
    "        cells = []\n",
    "        \n",
    "        for i, row in enumerate(rows):\n",
    "            r_x1, r_y1, r_x2, r_y2 = row['box']\n",
    "            \n",
    "            for j, col in enumerate(columns):\n",
    "                c_x1, c_y1, c_x2, c_y2 = col['box']\n",
    "                \n",
    "                # Pr≈Ønik\n",
    "                cell_x1 = max(r_x1, c_x1)\n",
    "                cell_y1 = max(r_y1, c_y1)\n",
    "                cell_x2 = min(r_x2, c_x2)\n",
    "                cell_y2 = min(r_y2, c_y2)\n",
    "                \n",
    "                if cell_x1 < cell_x2 and cell_y1 < cell_y2:\n",
    "                    cells.append({\n",
    "                        'row': i,\n",
    "                        'column': j,\n",
    "                        'box': [cell_x1, cell_y1, cell_x2, cell_y2]\n",
    "                    })\n",
    "        \n",
    "        return cells\n",
    "    \n",
    "    def visualize_detection(self, image: Image.Image, tables: List[Dict]) -> Image.Image:\n",
    "        \"\"\"Vizualizuje detekovan√© tabulky.\"\"\"\n",
    "        vis_image = image.copy()\n",
    "        draw = ImageDraw.Draw(vis_image)\n",
    "        \n",
    "        colors = ['red', 'blue', 'green', 'orange', 'purple']\n",
    "        \n",
    "        for i, table in enumerate(tables):\n",
    "            color = colors[i % len(colors)]\n",
    "            box = table['box']\n",
    "            \n",
    "            draw.rectangle(box, outline=color, width=3)\n",
    "            \n",
    "            label = f\"Table {i+1}: {table['confidence']:.2f}\"\n",
    "            draw.text((box[0], box[1] - 20), label, fill=color)\n",
    "        \n",
    "        return vis_image\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TableExtractor p≈ôipraven\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vytvo≈ôen√≠ testovac√≠ho dokumentu s tabulkou\n",
    "def create_table_document() -> Image.Image:\n",
    "    \"\"\"Vytvo≈ô√≠ dokument obsahuj√≠c√≠ tabulku.\"\"\"\n",
    "    width, height = 700, 500\n",
    "    image = Image.new('RGB', (width, height), color='white')\n",
    "    draw = ImageDraw.Draw(image)\n",
    "    \n",
    "    try:\n",
    "        font = ImageFont.truetype(\"/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf\", 14)\n",
    "        font_bold = ImageFont.truetype(\"/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf\", 16)\n",
    "    except:\n",
    "        font = ImageFont.load_default()\n",
    "        font_bold = font\n",
    "    \n",
    "    # Z√°hlav√≠ dokumentu\n",
    "    draw.text((50, 30), \"P≈òEHLED PRODEJ≈Æ - Q1 2024\", fill='black', font=font_bold)\n",
    "    \n",
    "    # Tabulka\n",
    "    table_x, table_y = 50, 80\n",
    "    col_widths = [150, 100, 100, 100, 100]\n",
    "    row_height = 35\n",
    "    \n",
    "    # Data tabulky\n",
    "    headers = [\"Produkt\", \"Leden\", \"√önor\", \"B≈ôezen\", \"Celkem\"]\n",
    "    data = [\n",
    "        [\"AI Automatizace\", \"45 000\", \"52 000\", \"61 000\", \"158 000\"],\n",
    "        [\"ML Konzultace\", \"32 000\", \"38 000\", \"41 000\", \"111 000\"],\n",
    "        [\"Cloud Setup\", \"28 000\", \"31 000\", \"35 000\", \"94 000\"],\n",
    "        [\"≈†kolen√≠\", \"15 000\", \"18 000\", \"22 000\", \"55 000\"],\n",
    "        [\"Celkem\", \"120 000\", \"139 000\", \"159 000\", \"418 000\"],\n",
    "    ]\n",
    "    \n",
    "    # Kreslen√≠ tabulky\n",
    "    current_y = table_y\n",
    "    \n",
    "    # Z√°hlav√≠\n",
    "    current_x = table_x\n",
    "    for i, (header, width) in enumerate(zip(headers, col_widths)):\n",
    "        # Bu≈àka\n",
    "        draw.rectangle([current_x, current_y, current_x + width, current_y + row_height],\n",
    "                      outline='black', fill='lightgray')\n",
    "        # Text\n",
    "        draw.text((current_x + 10, current_y + 10), header, fill='black', font=font_bold)\n",
    "        current_x += width\n",
    "    \n",
    "    current_y += row_height\n",
    "    \n",
    "    # Data\n",
    "    for row in data:\n",
    "        current_x = table_x\n",
    "        is_total = row[0] == \"Celkem\"\n",
    "        \n",
    "        for value, width in zip(row, col_widths):\n",
    "            fill_color = 'lightyellow' if is_total else 'white'\n",
    "            draw.rectangle([current_x, current_y, current_x + width, current_y + row_height],\n",
    "                          outline='black', fill=fill_color)\n",
    "            draw.text((current_x + 10, current_y + 10), value, fill='black', font=font)\n",
    "            current_x += width\n",
    "        \n",
    "        current_y += row_height\n",
    "    \n",
    "    # Pozn√°mka pod tabulkou\n",
    "    draw.text((50, current_y + 20), \"* V≈°echny ƒç√°stky jsou v Kƒç\", fill='gray', font=font)\n",
    "    \n",
    "    return image\n",
    "\n",
    "table_document = create_table_document()\n",
    "display(table_document)\n",
    "print(\"üìä Testovac√≠ dokument s tabulkou vytvo≈ôen\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Table Extractor\n",
    "table_extractor = TableExtractor(detection_threshold=0.5)\n",
    "\n",
    "# Detekce tabulek\n",
    "detected_tables = table_extractor.detect_tables(table_document)\n",
    "\n",
    "print(f\"\\nüìä Detekov√°no {len(detected_tables)} tabulek:\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "for i, table in enumerate(detected_tables):\n",
    "    print(f\"\\nTabulka {i+1}:\")\n",
    "    print(f\"  Confidence: {table['confidence']:.3f}\")\n",
    "    print(f\"  Box: {[int(c) for c in table['box']]}\")\n",
    "    \n",
    "    # Anal√Ωza struktury\n",
    "    if table['confidence'] > 0.5:\n",
    "        structure = table_extractor.analyze_structure(table_document, table['box'])\n",
    "        print(f\"  ≈ò√°dk≈Ø: {len(structure['rows'])}\")\n",
    "        print(f\"  Sloupc≈Ø: {len(structure['columns'])}\")\n",
    "        print(f\"  Bunƒõk: {len(structure['cells'])}\")\n",
    "\n",
    "# Vizualizace\n",
    "if detected_tables:\n",
    "    vis_image = table_extractor.visualize_detection(table_document, detected_tables)\n",
    "    display(vis_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üè≠ ƒå√°st 5: Produkƒçn√≠ Document Pipeline\n",
    "\n",
    "Kompletn√≠ pipeline pro zpracov√°n√≠ dokument≈Ø v produkƒçn√≠m prost≈ôed√≠."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "from datetime import datetime\n",
    "import hashlib\n",
    "import time\n",
    "\n",
    "class DocumentType(Enum):\n",
    "    INVOICE = \"invoice\"\n",
    "    RECEIPT = \"receipt\"\n",
    "    FORM = \"form\"\n",
    "    REPORT = \"report\"\n",
    "    CONTRACT = \"contract\"\n",
    "    ID_DOCUMENT = \"id_document\"\n",
    "    UNKNOWN = \"unknown\"\n",
    "\n",
    "@dataclass\n",
    "class ProcessedDocument:\n",
    "    \"\"\"V√Ωsledek zpracov√°n√≠ dokumentu.\"\"\"\n",
    "    document_id: str\n",
    "    document_type: DocumentType\n",
    "    extracted_text: str\n",
    "    structured_data: Dict[str, Any]\n",
    "    tables: List[Dict]\n",
    "    entities: List[Dict]\n",
    "    confidence: float\n",
    "    processing_time: float\n",
    "    metadata: Dict[str, Any] = field(default_factory=dict)\n",
    "    \n",
    "    def to_dict(self) -> Dict:\n",
    "        return {\n",
    "            'document_id': self.document_id,\n",
    "            'document_type': self.document_type.value,\n",
    "            'extracted_text': self.extracted_text,\n",
    "            'structured_data': self.structured_data,\n",
    "            'tables': self.tables,\n",
    "            'entities': self.entities,\n",
    "            'confidence': self.confidence,\n",
    "            'processing_time': self.processing_time,\n",
    "            'metadata': self.metadata\n",
    "        }\n",
    "\n",
    "class ProductionDocumentPipeline:\n",
    "    \"\"\"\n",
    "    Produkƒçn√≠ pipeline pro zpracov√°n√≠ dokument≈Ø.\n",
    "    \n",
    "    Kombinuje OCR, layout anal√Ωzu, extrakci dat a tabulek\n",
    "    do jednoho unifikovan√©ho rozhran√≠.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, \n",
    "                 enable_ocr: bool = True,\n",
    "                 enable_layout: bool = True,\n",
    "                 enable_table_extraction: bool = True,\n",
    "                 cache_size: int = 100):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            enable_ocr: Povolit TrOCR engine\n",
    "            enable_layout: Povolit LayoutLM anal√Ωzu\n",
    "            enable_table_extraction: Povolit extrakci tabulek\n",
    "            cache_size: Velikost cache pro v√Ωsledky\n",
    "        \"\"\"\n",
    "        print(\"üè≠ Inicializace Document Pipeline...\")\n",
    "        \n",
    "        self.components = {}\n",
    "        \n",
    "        if enable_ocr:\n",
    "            self.components['ocr'] = TrOCREngine()\n",
    "        \n",
    "        if enable_layout:\n",
    "            self.components['layout'] = DocumentLayoutAnalyzer()\n",
    "        \n",
    "        if enable_table_extraction:\n",
    "            self.components['tables'] = TableExtractor()\n",
    "        \n",
    "        # Cache a statistiky\n",
    "        self.cache = {}\n",
    "        self.cache_size = cache_size\n",
    "        self.stats = {\n",
    "            'documents_processed': 0,\n",
    "            'total_processing_time': 0,\n",
    "            'cache_hits': 0,\n",
    "            'errors': 0,\n",
    "            'by_type': defaultdict(int)\n",
    "        }\n",
    "        \n",
    "        # Regex patterns pro entity\n",
    "        self.patterns = {\n",
    "            'invoice_number': r'(?:fa[ck]tura|invoice)\\s*(?:ƒç\\.?|c\\.?|no\\.?|#)?\\s*[:.]?\\s*([\\w\\-/]+)',\n",
    "            'date': r'(\\d{1,2}[./]\\d{1,2}[./]\\d{2,4})',\n",
    "            'amount': r'(\\d{1,3}(?:\\s?\\d{3})*(?:[,.]\\d{2})?)\\s*(?:Kƒç|CZK|EUR|USD|Kc)',\n",
    "            'ico': r'Iƒå[O]?\\s*[:.]?\\s*(\\d{8})',\n",
    "            'dic': r'DIƒå\\s*[:.]?\\s*([A-Z]{2}\\d{8,10})',\n",
    "            'email': r'[\\w.+-]+@[\\w-]+\\.[\\w.-]+',\n",
    "            'phone': r'(?:\\+420\\s?)?\\d{3}\\s?\\d{3}\\s?\\d{3}',\n",
    "        }\n",
    "        \n",
    "        print(\"‚úÖ Pipeline inicializov√°n\")\n",
    "        print(f\"   Komponenty: {list(self.components.keys())}\")\n",
    "    \n",
    "    def process(self, image: Image.Image, \n",
    "                document_hint: Optional[DocumentType] = None,\n",
    "                use_cache: bool = True) -> ProcessedDocument:\n",
    "        \"\"\"\n",
    "        Zpracuje dokument kompletn√≠m pipeline.\n",
    "        \n",
    "        Args:\n",
    "            image: Obr√°zek dokumentu\n",
    "            document_hint: N√°povƒõda typu dokumentu\n",
    "            use_cache: Pou≈æ√≠t cache\n",
    "        \n",
    "        Returns:\n",
    "            ProcessedDocument se v≈°emi extrahovan√Ωmi daty\n",
    "        \"\"\"\n",
    "        start_time = time.time()\n",
    "        \n",
    "        # Generov√°n√≠ ID dokumentu\n",
    "        image_bytes = io.BytesIO()\n",
    "        image.save(image_bytes, format='PNG')\n",
    "        doc_id = hashlib.md5(image_bytes.getvalue()).hexdigest()[:12]\n",
    "        \n",
    "        # Kontrola cache\n",
    "        if use_cache and doc_id in self.cache:\n",
    "            self.stats['cache_hits'] += 1\n",
    "            return self.cache[doc_id]\n",
    "        \n",
    "        try:\n",
    "            # Konverze na RGB\n",
    "            if image.mode != 'RGB':\n",
    "                image = image.convert('RGB')\n",
    "            \n",
    "            # 1. OCR - extrakce textu\n",
    "            extracted_text = \"\"\n",
    "            if 'ocr' in self.components:\n",
    "                extracted_text = self._extract_text_from_regions(image)\n",
    "            \n",
    "            # 2. Layout anal√Ωza\n",
    "            layout_entities = []\n",
    "            if 'layout' in self.components:\n",
    "                layout_result = self.components['layout'].analyze_document(image)\n",
    "                layout_entities = layout_result.get('entities', [])\n",
    "            \n",
    "            # 3. Extrakce tabulek\n",
    "            tables = []\n",
    "            if 'tables' in self.components:\n",
    "                detected = self.components['tables'].detect_tables(image)\n",
    "                for table in detected:\n",
    "                    if table['confidence'] > 0.5:\n",
    "                        structure = self.components['tables'].analyze_structure(\n",
    "                            image, table['box']\n",
    "                        )\n",
    "                        tables.append({\n",
    "                            'box': table['box'],\n",
    "                            'confidence': table['confidence'],\n",
    "                            'structure': structure\n",
    "                        })\n",
    "            \n",
    "            # 4. Extrakce strukturovan√Ωch dat pomoc√≠ regex\n",
    "            structured_data = self._extract_structured_data(extracted_text)\n",
    "            \n",
    "            # 5. Urƒçen√≠ typu dokumentu\n",
    "            doc_type = document_hint or self._classify_document(extracted_text, structured_data)\n",
    "            \n",
    "            # 6. V√Ωpoƒçet confidence\n",
    "            confidence = self._compute_confidence(extracted_text, structured_data, tables)\n",
    "            \n",
    "            processing_time = time.time() - start_time\n",
    "            \n",
    "            # Sestaven√≠ v√Ωsledku\n",
    "            result = ProcessedDocument(\n",
    "                document_id=doc_id,\n",
    "                document_type=doc_type,\n",
    "                extracted_text=extracted_text,\n",
    "                structured_data=structured_data,\n",
    "                tables=tables,\n",
    "                entities=layout_entities,\n",
    "                confidence=confidence,\n",
    "                processing_time=processing_time,\n",
    "                metadata={\n",
    "                    'image_size': image.size,\n",
    "                    'processed_at': datetime.now().isoformat(),\n",
    "                    'components_used': list(self.components.keys())\n",
    "                }\n",
    "            )\n",
    "            \n",
    "            # Aktualizace statistik\n",
    "            self.stats['documents_processed'] += 1\n",
    "            self.stats['total_processing_time'] += processing_time\n",
    "            self.stats['by_type'][doc_type.value] += 1\n",
    "            \n",
    "            # Cache\n",
    "            if use_cache:\n",
    "                self._add_to_cache(doc_id, result)\n",
    "            \n",
    "            return result\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.stats['errors'] += 1\n",
    "            raise RuntimeError(f\"Chyba p≈ôi zpracov√°n√≠ dokumentu: {e}\")\n",
    "    \n",
    "    def _extract_text_from_regions(self, image: Image.Image) -> str:\n",
    "        \"\"\"Extrahuje text z cel√©ho obr√°zku pomoc√≠ rozdƒõlen√≠ na regiony.\"\"\"\n",
    "        # Pro jednoduchost - cel√Ω obr√°zek\n",
    "        # V produkci by se rozdƒõlil na ≈ô√°dky pomoc√≠ detekce\n",
    "        width, height = image.size\n",
    "        \n",
    "        # Rozdƒõlen√≠ na horizont√°ln√≠ pruhy\n",
    "        texts = []\n",
    "        strip_height = 50\n",
    "        \n",
    "        for y in range(0, height - strip_height, strip_height):\n",
    "            strip = image.crop((0, y, width, y + strip_height))\n",
    "            text = self.components['ocr'].recognize_text(strip)\n",
    "            if text.strip():\n",
    "                texts.append(text)\n",
    "        \n",
    "        return '\\n'.join(texts)\n",
    "    \n",
    "    def _extract_structured_data(self, text: str) -> Dict[str, Any]:\n",
    "        \"\"\"Extrahuje strukturovan√° data pomoc√≠ regex patterns.\"\"\"\n",
    "        data = {}\n",
    "        text_lower = text.lower()\n",
    "        \n",
    "        for field, pattern in self.patterns.items():\n",
    "            matches = re.findall(pattern, text, re.IGNORECASE)\n",
    "            if matches:\n",
    "                if len(matches) == 1:\n",
    "                    data[field] = matches[0]\n",
    "                else:\n",
    "                    data[field] = matches\n",
    "        \n",
    "        return data\n",
    "    \n",
    "    def _classify_document(self, text: str, structured_data: Dict) -> DocumentType:\n",
    "        \"\"\"Klasifikuje typ dokumentu na z√°kladƒõ obsahu.\"\"\"\n",
    "        text_lower = text.lower()\n",
    "        \n",
    "        # Heuristick√° klasifikace\n",
    "        if any(kw in text_lower for kw in ['faktura', 'invoice', 'da≈àov√Ω doklad']):\n",
    "            return DocumentType.INVOICE\n",
    "        elif any(kw in text_lower for kw in ['√∫ƒçtenka', 'receipt', 'pokladn√≠']):\n",
    "            return DocumentType.RECEIPT\n",
    "        elif any(kw in text_lower for kw in ['smlouva', 'contract', 'agreement']):\n",
    "            return DocumentType.CONTRACT\n",
    "        elif any(kw in text_lower for kw in ['formul√°≈ô', 'form', '≈æ√°dost', 'p≈ôihl√°≈°ka']):\n",
    "            return DocumentType.FORM\n",
    "        elif any(kw in text_lower for kw in ['zpr√°va', 'report', 'p≈ôehled']):\n",
    "            return DocumentType.REPORT\n",
    "        elif any(kw in text_lower for kw in ['obƒçansk√Ω pr≈Økaz', 'passport', '≈ôidiƒçsk√Ω']):\n",
    "            return DocumentType.ID_DOCUMENT\n",
    "        \n",
    "        return DocumentType.UNKNOWN\n",
    "    \n",
    "    def _compute_confidence(self, text: str, \n",
    "                           structured_data: Dict, \n",
    "                           tables: List) -> float:\n",
    "        \"\"\"Vypoƒç√≠t√° celkovou confidence sk√≥re.\"\"\"\n",
    "        scores = []\n",
    "        \n",
    "        # Text quality\n",
    "        if text:\n",
    "            # Penalizace za p≈ô√≠li≈° kr√°tk√Ω text\n",
    "            text_score = min(1.0, len(text) / 100)\n",
    "            scores.append(text_score)\n",
    "        \n",
    "        # Structured data extraction\n",
    "        if structured_data:\n",
    "            data_score = min(1.0, len(structured_data) / 5)\n",
    "            scores.append(data_score)\n",
    "        \n",
    "        # Table detection confidence\n",
    "        if tables:\n",
    "            table_scores = [t['confidence'] for t in tables]\n",
    "            scores.extend(table_scores)\n",
    "        \n",
    "        return np.mean(scores) if scores else 0.0\n",
    "    \n",
    "    def _add_to_cache(self, doc_id: str, result: ProcessedDocument):\n",
    "        \"\"\"P≈ôid√° v√Ωsledek do cache s LRU eviction.\"\"\"\n",
    "        if len(self.cache) >= self.cache_size:\n",
    "            # Odstranƒõn√≠ nejstar≈°√≠ho\n",
    "            oldest_key = next(iter(self.cache))\n",
    "            del self.cache[oldest_key]\n",
    "        \n",
    "        self.cache[doc_id] = result\n",
    "    \n",
    "    def get_stats(self) -> Dict:\n",
    "        \"\"\"Vr√°t√≠ statistiky pipeline.\"\"\"\n",
    "        stats = dict(self.stats)\n",
    "        stats['by_type'] = dict(stats['by_type'])\n",
    "        \n",
    "        if stats['documents_processed'] > 0:\n",
    "            stats['avg_processing_time'] = (\n",
    "                stats['total_processing_time'] / stats['documents_processed']\n",
    "            )\n",
    "            stats['cache_hit_rate'] = (\n",
    "                stats['cache_hits'] / \n",
    "                (stats['documents_processed'] + stats['cache_hits'])\n",
    "            )\n",
    "        \n",
    "        return stats\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ProductionDocumentPipeline p≈ôipraven\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicializace produkƒçn√≠ho pipeline\n",
    "# Pro demo pou≈æ√≠v√°me jen nƒõkter√© komponenty\n",
    "pipeline = ProductionDocumentPipeline(\n",
    "    enable_ocr=True,\n",
    "    enable_layout=True,\n",
    "    enable_table_extraction=True,\n",
    "    cache_size=50\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vytvo≈ôen√≠ komplexn√≠ho testovac√≠ho dokumentu - faktury\n",
    "def create_invoice_image() -> Image.Image:\n",
    "    \"\"\"Vytvo≈ô√≠ realistick√Ω obr√°zek faktury.\"\"\"\n",
    "    width, height = 600, 800\n",
    "    image = Image.new('RGB', (width, height), color='white')\n",
    "    draw = ImageDraw.Draw(image)\n",
    "    \n",
    "    try:\n",
    "        font = ImageFont.truetype(\"/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf\", 12)\n",
    "        font_bold = ImageFont.truetype(\"/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf\", 14)\n",
    "        font_title = ImageFont.truetype(\"/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf\", 20)\n",
    "    except:\n",
    "        font = ImageFont.load_default()\n",
    "        font_bold = font\n",
    "        font_title = font\n",
    "    \n",
    "    # Logo/hlaviƒçka\n",
    "    draw.text((50, 30), \"PRAUT s.r.o.\", fill='darkblue', font=font_title)\n",
    "    draw.text((50, 55), \"AI Automatizace a Integrace\", fill='gray', font=font)\n",
    "    \n",
    "    # Typ dokumentu\n",
    "    draw.text((400, 30), \"FAKTURA\", fill='black', font=font_title)\n",
    "    draw.text((400, 55), \"Danovy doklad\", fill='gray', font=font)\n",
    "    \n",
    "    # ƒå√≠slo faktury\n",
    "    draw.text((400, 85), \"Cislo: FA-2024-00123\", fill='black', font=font_bold)\n",
    "    \n",
    "    # Horizont√°ln√≠ ƒç√°ra\n",
    "    draw.line([(50, 110), (550, 110)], fill='lightgray', width=2)\n",
    "    \n",
    "    # Dodavatel\n",
    "    y = 130\n",
    "    draw.text((50, y), \"Dodavatel:\", fill='gray', font=font)\n",
    "    draw.text((50, y+18), \"Praut s.r.o.\", fill='black', font=font_bold)\n",
    "    draw.text((50, y+36), \"Chebska 123\", fill='black', font=font)\n",
    "    draw.text((50, y+54), \"350 02 Cheb\", fill='black', font=font)\n",
    "    draw.text((50, y+72), \"ICO: 12345678\", fill='black', font=font)\n",
    "    draw.text((50, y+90), \"DIC: CZ12345678\", fill='black', font=font)\n",
    "    \n",
    "    # Odbƒõratel\n",
    "    draw.text((320, y), \"Odberatel:\", fill='gray', font=font)\n",
    "    draw.text((320, y+18), \"ABC Company s.r.o.\", fill='black', font=font_bold)\n",
    "    draw.text((320, y+36), \"Prazska 456\", fill='black', font=font)\n",
    "    draw.text((320, y+54), \"110 00 Praha 1\", fill='black', font=font)\n",
    "    draw.text((320, y+72), \"ICO: 87654321\", fill='black', font=font)\n",
    "    draw.text((320, y+90), \"DIC: CZ87654321\", fill='black', font=font)\n",
    "    \n",
    "    # Datumy\n",
    "    y = 260\n",
    "    draw.text((50, y), \"Datum vystaveni: 15.01.2024\", fill='black', font=font)\n",
    "    draw.text((250, y), \"Datum splatnosti: 29.01.2024\", fill='black', font=font)\n",
    "    draw.text((450, y), \"DUZP: 15.01.2024\", fill='black', font=font)\n",
    "    \n",
    "    # Tabulka polo≈æek\n",
    "    y = 300\n",
    "    draw.line([(50, y), (550, y)], fill='black', width=1)\n",
    "    \n",
    "    # Z√°hlav√≠ tabulky\n",
    "    headers = [\"Popis\", \"Pocet\", \"Cena/ks\", \"Celkem\"]\n",
    "    x_positions = [50, 280, 360, 460]\n",
    "    \n",
    "    for header, x in zip(headers, x_positions):\n",
    "        draw.text((x, y+5), header, fill='black', font=font_bold)\n",
    "    \n",
    "    y += 25\n",
    "    draw.line([(50, y), (550, y)], fill='black', width=1)\n",
    "    \n",
    "    # Polo≈æky\n",
    "    items = [\n",
    "        (\"AI Konzultace - analyza\", \"8\", \"2 500 Kc\", \"20 000 Kc\"),\n",
    "        (\"Vyvoj automatizace\", \"24\", \"1 800 Kc\", \"43 200 Kc\"),\n",
    "        (\"Integrace API\", \"12\", \"2 000 Kc\", \"24 000 Kc\"),\n",
    "        (\"Skoleni zamestnancu\", \"4\", \"3 500 Kc\", \"14 000 Kc\"),\n",
    "    ]\n",
    "    \n",
    "    for item in items:\n",
    "        y += 5\n",
    "        for text, x in zip(item, x_positions):\n",
    "            draw.text((x, y), text, fill='black', font=font)\n",
    "        y += 20\n",
    "    \n",
    "    # ƒå√°ra pod polo≈ækami\n",
    "    y += 10\n",
    "    draw.line([(50, y), (550, y)], fill='black', width=1)\n",
    "    \n",
    "    # Souƒçty\n",
    "    y += 15\n",
    "    draw.text((350, y), \"Zaklad dane:\", fill='black', font=font)\n",
    "    draw.text((460, y), \"101 200 Kc\", fill='black', font=font_bold)\n",
    "    \n",
    "    y += 20\n",
    "    draw.text((350, y), \"DPH 21%:\", fill='black', font=font)\n",
    "    draw.text((460, y), \"21 252 Kc\", fill='black', font=font_bold)\n",
    "    \n",
    "    y += 25\n",
    "    draw.line([(350, y), (550, y)], fill='black', width=2)\n",
    "    y += 5\n",
    "    draw.text((350, y), \"CELKEM K UHRADE:\", fill='black', font=font_bold)\n",
    "    draw.text((460, y), \"122 452 Kc\", fill='darkblue', font=font_title)\n",
    "    \n",
    "    # Platebn√≠ √∫daje\n",
    "    y = 580\n",
    "    draw.line([(50, y), (550, y)], fill='lightgray', width=1)\n",
    "    y += 15\n",
    "    draw.text((50, y), \"Platebni udaje:\", fill='gray', font=font)\n",
    "    y += 20\n",
    "    draw.text((50, y), \"Banka: Ceska sporitelna\", fill='black', font=font)\n",
    "    y += 18\n",
    "    draw.text((50, y), \"Cislo uctu: 123456789/0800\", fill='black', font=font)\n",
    "    y += 18\n",
    "    draw.text((50, y), \"Variabilni symbol: 202400123\", fill='black', font=font)\n",
    "    y += 18\n",
    "    draw.text((50, y), \"Konstantni symbol: 0308\", fill='black', font=font)\n",
    "    \n",
    "    # QR k√≥d placeholder\n",
    "    draw.rectangle([450, 600, 530, 680], outline='black', fill='lightgray')\n",
    "    draw.text((465, 635), \"QR PAY\", fill='black', font=font)\n",
    "    \n",
    "    # Patiƒçka\n",
    "    draw.text((50, 750), \"Kontakt: info@praut.cz | +420 123 456 789 | www.praut.cz\", \n",
    "              fill='gray', font=font)\n",
    "    \n",
    "    return image\n",
    "\n",
    "invoice_image = create_invoice_image()\n",
    "display(invoice_image)\n",
    "print(\"üìÑ Testovac√≠ faktura vytvo≈ôena\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zpracov√°n√≠ faktury pipeline\n",
    "result = pipeline.process(invoice_image)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"V√ùSLEDKY ZPRACOV√ÅN√ç DOKUMENTU\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(f\"\\nüìã Z√°kladn√≠ informace:\")\n",
    "print(f\"   ID dokumentu: {result.document_id}\")\n",
    "print(f\"   Typ dokumentu: {result.document_type.value}\")\n",
    "print(f\"   Confidence: {result.confidence:.2%}\")\n",
    "print(f\"   ƒåas zpracov√°n√≠: {result.processing_time:.2f}s\")\n",
    "\n",
    "print(f\"\\nüìù Extrahovan√Ω text (uk√°zka):\")\n",
    "print(f\"   {result.extracted_text[:200]}...\" if len(result.extracted_text) > 200 else result.extracted_text)\n",
    "\n",
    "print(f\"\\nüîç Strukturovan√° data:\")\n",
    "for key, value in result.structured_data.items():\n",
    "    print(f\"   {key}: {value}\")\n",
    "\n",
    "print(f\"\\nüìä Detekovan√© tabulky: {len(result.tables)}\")\n",
    "for i, table in enumerate(result.tables):\n",
    "    print(f\"   Tabulka {i+1}: confidence={table['confidence']:.2f}\")\n",
    "\n",
    "print(f\"\\nüìà Statistiky pipeline:\")\n",
    "stats = pipeline.get_stats()\n",
    "print(f\"   Zpracov√°no dokument≈Ø: {stats['documents_processed']}\")\n",
    "print(f\"   Pr≈Ømƒõrn√Ω ƒças: {stats.get('avg_processing_time', 0):.2f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch processing v√≠ce dokument≈Ø\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"BATCH PROCESSING\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Vytvo≈ôen√≠ r≈Øzn√Ωch dokument≈Ø\n",
    "documents = [\n",
    "    (\"Faktura\", invoice_image),\n",
    "    (\"√öƒçtenka\", receipt_image),\n",
    "    (\"Formul√°≈ô\", form_image),\n",
    "    (\"Tabulka\", table_document),\n",
    "]\n",
    "\n",
    "results = []\n",
    "for name, image in documents:\n",
    "    print(f\"\\nüìÑ Zpracov√°v√°m: {name}\")\n",
    "    result = pipeline.process(image)\n",
    "    results.append((name, result))\n",
    "    print(f\"   Typ: {result.document_type.value}\")\n",
    "    print(f\"   Confidence: {result.confidence:.2%}\")\n",
    "    print(f\"   ƒåas: {result.processing_time:.2f}s\")\n",
    "\n",
    "# Fin√°ln√≠ statistiky\n",
    "print(\"\\n\" + \"-\"*60)\n",
    "print(\"FIN√ÅLN√ç STATISTIKY\")\n",
    "print(\"-\"*60)\n",
    "stats = pipeline.get_stats()\n",
    "print(f\"Celkem zpracov√°no: {stats['documents_processed']} dokument≈Ø\")\n",
    "print(f\"Pr≈Ømƒõrn√Ω ƒças zpracov√°n√≠: {stats.get('avg_processing_time', 0):.2f}s\")\n",
    "print(f\"Cache hit rate: {stats.get('cache_hit_rate', 0):.1%}\")\n",
    "print(f\"Chyby: {stats['errors']}\")\n",
    "print(f\"\\nRozdƒõlen√≠ podle typu:\")\n",
    "for doc_type, count in stats['by_type'].items():\n",
    "    print(f\"   {doc_type}: {count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üéØ Shrnut√≠\n",
    "\n",
    "V tomto notebooku jsme implementovali:\n",
    "\n",
    "### Komponenty Document AI\n",
    "\n",
    "| Komponenta | Model | Pou≈æit√≠ |\n",
    "|------------|-------|--------|\n",
    "| **TrOCR** | microsoft/trocr-base-printed | Rozpozn√°v√°n√≠ ti≈°tƒõn√©ho textu |\n",
    "| **LayoutLM** | microsoft/layoutlmv3-base | Anal√Ωza struktury dokumentu |\n",
    "| **Donut** | naver-clova-ix/donut-base | End-to-end extrakce dat |\n",
    "| **Table Transformer** | microsoft/table-transformer | Detekce a extrakce tabulek |\n",
    "\n",
    "### Produkƒçn√≠ Pipeline\n",
    "\n",
    "- **Modul√°rn√≠ architektura** - zap√≠n√°n√≠/vyp√≠n√°n√≠ komponent\n",
    "- **Caching** - LRU cache pro opakovan√© dokumenty\n",
    "- **Strukturovan√° extrakce** - regex patterns pro ƒçesk√© dokumenty\n",
    "- **Automatick√° klasifikace** - rozpozn√°n√≠ typu dokumentu\n",
    "- **Batch processing** - efektivn√≠ zpracov√°n√≠ v√≠ce dokument≈Ø\n",
    "\n",
    "### Dal≈°√≠ kroky\n",
    "\n",
    "1. **Fine-tuning** na ƒçesk√Ωch dokumentech\n",
    "2. **Integrace s PDF** pomoc√≠ pdf2image\n",
    "3. **REST API** pro produkƒçn√≠ nasazen√≠\n",
    "4. **Validace dat** pomoc√≠ sch√©mat (Pydantic)\n",
    "5. **Archivace** do datab√°ze s full-text search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üéâ Notebook 19: Document AI dokonƒçen!\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\nüìö Nauƒçili jste se:\")\n",
    "print(\"   ‚úÖ TrOCR pro rozpozn√°v√°n√≠ textu\")\n",
    "print(\"   ‚úÖ LayoutLM pro anal√Ωzu struktury\")\n",
    "print(\"   ‚úÖ Donut pro end-to-end extrakci\")\n",
    "print(\"   ‚úÖ Table Transformer pro tabulky\")\n",
    "print(\"   ‚úÖ Produkƒçn√≠ Document Pipeline\")\n",
    "print(\"\\nüöÄ Dal≈°√≠ notebook: Audio AI - TTS, Voice Processing\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
