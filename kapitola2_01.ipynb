{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ü§ó √övod do Hugging Face Transformers\n",
    "\n",
    "**Autor:** Praut s.r.o. - AI Integration & Business Automation\n",
    "\n",
    "Tento notebook v√°s provede z√°klady pr√°ce s knihovnou Hugging Face Transformers - nejpopul√°rnƒõj≈°√≠ knihovnou pro pr√°ci s AI modely.\n",
    "\n",
    "## Co se nauƒç√≠te:\n",
    "- Instalace a konfigurace Hugging Face\n",
    "- Z√°kladn√≠ pipeline pro r≈Øzn√© √∫lohy\n",
    "- Pr√°ce s modely a tokenizery\n",
    "- Praktick√© p≈ô√≠klady automatizace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instalace pot≈ôebn√Ωch knihoven\n",
    "!pip install -q transformers accelerate torch sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import z√°kladn√≠ch knihoven\n",
    "from transformers import pipeline, AutoModel, AutoTokenizer\n",
    "import torch\n",
    "\n",
    "# Kontrola dostupnosti GPU\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"üñ•Ô∏è Pou≈æ√≠v√°m za≈ô√≠zen√≠: {device}\")\n",
    "if device == \"cuda\":\n",
    "    print(f\"   GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"   Pamƒõ≈•: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Pipeline - Nejjednodu≈°≈°√≠ zp≈Øsob pou≈æit√≠ model≈Ø\n",
    "\n",
    "Pipeline je vysoko√∫rov≈àov√© API, kter√© automaticky:\n",
    "- St√°hne model a tokenizer\n",
    "- P≈ôedzpracuje vstup\n",
    "- Provede inferenci\n",
    "- Zpracuje v√Ωstup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# P≈ô√≠klad 1: Sentiment anal√Ωza\n",
    "sentiment_analyzer = pipeline(\"sentiment-analysis\", device=0 if device==\"cuda\" else -1)\n",
    "\n",
    "texty = [\n",
    "    \"Tento produkt je naprosto skvƒõl√Ω, jsem velmi spokojen√Ω!\",\n",
    "    \"Hrozn√° kvalita, nikdy v√≠ce nekoup√≠m.\",\n",
    "    \"Je to pr≈Ømƒõrn√©, nic extra.\"\n",
    "]\n",
    "\n",
    "vysledky = sentiment_analyzer(texty)\n",
    "for text, vysledek in zip(texty, vysledky):\n",
    "    print(f\"üìù {text}\")\n",
    "    print(f\"   ‚Üí {vysledek['label']} (sk√≥re: {vysledek['score']:.2%})\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# P≈ô√≠klad 2: Generov√°n√≠ textu\n",
    "generator = pipeline(\"text-generation\", model=\"gpt2\", device=0 if device==\"cuda\" else -1)\n",
    "\n",
    "prompt = \"Umƒõl√° inteligence v podnik√°n√≠ p≈ôin√°≈°√≠\"\n",
    "vysledek = generator(prompt, max_length=50, num_return_sequences=1, do_sample=True)\n",
    "\n",
    "print(f\"üìù Prompt: {prompt}\")\n",
    "print(f\"ü§ñ Vygenerov√°no: {vysledek[0]['generated_text']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# P≈ô√≠klad 3: Sumarizace textu\n",
    "summarizer = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\", device=0 if device==\"cuda\" else -1)\n",
    "\n",
    "dlouhy_text = \"\"\"\n",
    "Artificial intelligence (AI) is transforming businesses across all industries. \n",
    "Companies are using AI to automate repetitive tasks, analyze large datasets, \n",
    "and make better decisions. Machine learning models can predict customer behavior, \n",
    "optimize supply chains, and detect fraud. Natural language processing enables \n",
    "chatbots and virtual assistants to handle customer inquiries 24/7. Computer vision \n",
    "is used in quality control, security systems, and autonomous vehicles. The adoption \n",
    "of AI is accelerating, with more organizations investing in AI capabilities to \n",
    "stay competitive in the digital economy.\n",
    "\"\"\"\n",
    "\n",
    "souhrn = summarizer(dlouhy_text, max_length=60, min_length=20, do_sample=False)\n",
    "print(f\"üìÑ P≈Øvodn√≠ text ({len(dlouhy_text)} znak≈Ø)\")\n",
    "print(f\"üìã Souhrn: {souhrn[0]['summary_text']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Pr√°ce s tokenizery\n",
    "\n",
    "Tokenizer p≈ôev√°d√≠ text na ƒç√≠sla (tokeny), kter√© model zpracuje."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naƒçten√≠ tokenizeru\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "text = \"Hello, how are you doing today?\"\n",
    "\n",
    "# Tokenizace\n",
    "tokens = tokenizer.tokenize(text)\n",
    "print(f\"üìù Text: {text}\")\n",
    "print(f\"üî§ Tokeny: {tokens}\")\n",
    "\n",
    "# P≈ôevod na ID\n",
    "ids = tokenizer.encode(text)\n",
    "print(f\"üî¢ Token IDs: {ids}\")\n",
    "\n",
    "# Zpƒõt na text\n",
    "decoded = tokenizer.decode(ids)\n",
    "print(f\"üìñ Dek√≥dov√°no: {decoded}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pokroƒçil√° tokenizace pro model\n",
    "encoded = tokenizer(\n",
    "    text,\n",
    "    padding=True,\n",
    "    truncation=True,\n",
    "    max_length=512,\n",
    "    return_tensors=\"pt\"  # PyTorch tensory\n",
    ")\n",
    "\n",
    "print(\"üì¶ V√Ωstup tokenizeru:\")\n",
    "for key, value in encoded.items():\n",
    "    print(f\"   {key}: {value.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. P≈ô√≠m√° pr√°ce s modelem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "# Naƒçten√≠ modelu pro klasifikaci\n",
    "model_name = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# P≈ôesun na GPU pokud je dostupn√°\n",
    "model = model.to(device)\n",
    "\n",
    "# Manu√°ln√≠ inference\n",
    "text = \"I absolutely love this product!\"\n",
    "inputs = tokenizer(text, return_tensors=\"pt\").to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "    predictions = torch.softmax(outputs.logits, dim=-1)\n",
    "\n",
    "labels = [\"NEGATIVE\", \"POSITIVE\"]\n",
    "for i, prob in enumerate(predictions[0]):\n",
    "    print(f\"{labels[i]}: {prob:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Praktick√° automatizace: Hromadn√© zpracov√°n√≠"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Simulace dat z e-shopu\n",
    "recenze = pd.DataFrame({\n",
    "    \"id\": [1, 2, 3, 4, 5],\n",
    "    \"produkt\": [\"Notebook\", \"My≈°\", \"Kl√°vesnice\", \"Monitor\", \"Sluch√°tka\"],\n",
    "    \"text\": [\n",
    "        \"Great laptop, very fast and reliable!\",\n",
    "        \"The mouse stopped working after a week.\",\n",
    "        \"Perfect keyboard for programming.\",\n",
    "        \"Average quality, nothing special.\",\n",
    "        \"Best headphones I've ever owned!\"\n",
    "    ]\n",
    "})\n",
    "\n",
    "# Hromadn√° anal√Ωza sentimentu\n",
    "classifier = pipeline(\"sentiment-analysis\", device=0 if device==\"cuda\" else -1)\n",
    "results = classifier(recenze[\"text\"].tolist())\n",
    "\n",
    "recenze[\"sentiment\"] = [r[\"label\"] for r in results]\n",
    "recenze[\"confidence\"] = [r[\"score\"] for r in results]\n",
    "\n",
    "print(\"üìä Automatick√° anal√Ωza recenz√≠:\")\n",
    "print(recenze.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistiky\n",
    "print(\"\\nüìà Statistiky:\")\n",
    "print(f\"   Pozitivn√≠ recenze: {(recenze['sentiment'] == 'POSITIVE').sum()}\")\n",
    "print(f\"   Negativn√≠ recenze: {(recenze['sentiment'] == 'NEGATIVE').sum()}\")\n",
    "print(f\"   Pr≈Ømƒõrn√° jistota: {recenze['confidence'].mean():.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Dostupn√© √∫lohy v pipeline\n",
    "\n",
    "| √öloha | Popis |\n",
    "|-------|-------|\n",
    "| `text-classification` | Klasifikace textu |\n",
    "| `token-classification` | NER, POS tagging |\n",
    "| `question-answering` | Odpov√≠d√°n√≠ na ot√°zky |\n",
    "| `summarization` | Sumarizace |\n",
    "| `translation` | P≈ôeklad |\n",
    "| `text-generation` | Generov√°n√≠ textu |\n",
    "| `fill-mask` | Dopl≈àov√°n√≠ slov |\n",
    "| `zero-shot-classification` | Klasifikace bez tr√©ninku |\n",
    "| `image-classification` | Klasifikace obr√°zk≈Ø |\n",
    "| `object-detection` | Detekce objekt≈Ø |\n",
    "| `automatic-speech-recognition` | P≈ôevod ≈ôeƒçi na text |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## üèÅ Shrnut√≠\n",
    "\n",
    "V tomto notebooku jsme se nauƒçili:\n",
    "- ‚úÖ Pou≈æ√≠vat `pipeline` pro rychl√© experimenty\n",
    "- ‚úÖ Pracovat s tokenizery\n",
    "- ‚úÖ Naƒç√≠tat a pou≈æ√≠vat modely p≈ô√≠mo\n",
    "- ‚úÖ Automatizovat zpracov√°n√≠ dat\n",
    "\n",
    "**Dal≈°√≠ notebook:** Textov√° klasifikace a NER"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  },
  "accelerator": "GPU",
  "colab": {
   "provenance": [],
   "gpuType": "T4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
