{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kapitola 19: Naivni Bayesuv klasifikator - Spam filtr pomoci pytle slov\n",
    "\n",
    "## Jak AI rozpozna spam pomoci jednoduchych pravdepodobnosti\n",
    "\n",
    "---\n",
    "\n",
    "### Co se naucite:\n",
    "- Pochopit model \"pytle slov\" (Bag of Words)\n",
    "- Implementovat spam filtr pomoci scikit-learn\n",
    "- Pouzit CountVectorizer pro vektorizaci textu\n",
    "- Trenovat MultinomialNB klasifikator\n",
    "- Analyzovat dulezitost slov pro klasifikaci\n",
    "\n",
    "### Proc \"naivni\"?\n",
    "Algoritmus se \"naivne\" domniva, ze kazde slovo v emailu je zcela nezavisly dukaz.\n",
    "Nevnima gramatiku, kontext ani poradi slov. Presto je prekvapive presny!\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Instalace a import knihoven"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instalace knihoven pro Google Colab\n",
    "!pip install scikit-learn pandas numpy matplotlib seaborn -q\n",
    "\n",
    "print(\"Knihovny uspesne nainstalovany!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import knihoven\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Nastaveni vizualizaci\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (10, 6)\n",
    "plt.rcParams['font.size'] = 12\n",
    "\n",
    "print(\"Vsechny knihovny importovany!\")\n",
    "print(\"Tema: Naivni Bayesuv klasifikator pro spam detekci\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Model \"pytle slov\" (Bag of Words)\n",
    "\n",
    "Pro Naivni Bayesuv klasifikator je text jen **\"pytel slov\"** (Bag of Words).\n",
    "\n",
    "Veta: _\"Vyzvedni si svou vyhru zdarma!\"_\n",
    "\n",
    "Se prevede na: `{\"vyzvedni\": 1, \"si\": 1, \"svou\": 1, \"vyhru\": 1, \"zdarma\": 1}`\n",
    "\n",
    "Algoritmus nezajima poradi - kazde slovo je samostatna jednotka!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrace Bag of Words\n",
    "print(\"=\" * 60)\n",
    "print(\"DEMONSTRACE: Bag of Words (Pytel slov)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Prikladove vety\n",
    "vety = [\n",
    "    \"Vyzvedni si svou vyhru zdarma\",\n",
    "    \"Ahoj jak se mas sejdeme zitra\",\n",
    "    \"Klikni zde pro slevu zdarma\"\n",
    "]\n",
    "\n",
    "# Vytvoreni CountVectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(vety)\n",
    "\n",
    "# Zobrazeni slovniku\n",
    "print(\"\\nSlovnik (slova, ktera model zna):\")\n",
    "print(vectorizer.get_feature_names_out())\n",
    "\n",
    "# Zobrazeni matice vyskytu\n",
    "print(\"\\nMatice vyskytu slov (kazdy radek = jedna veta):\")\n",
    "df_bow = pd.DataFrame(\n",
    "    X.toarray(),\n",
    "    columns=vectorizer.get_feature_names_out(),\n",
    "    index=[f'Veta {i+1}' for i in range(len(vety))]\n",
    ")\n",
    "print(df_bow)\n",
    "\n",
    "print(\"\\nKazdy sloupeC = jedno slovo, hodnota = kolikrat se vyskytuje\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vizualizace Bag of Words\n",
    "plt.figure(figsize=(14, 5))\n",
    "\n",
    "sns.heatmap(df_bow, annot=True, cmap='YlOrRd', fmt='d', cbar_kws={'label': 'Pocet vyskytu'})\n",
    "plt.title('Bag of Words - Matice vyskytu slov', fontsize=14)\n",
    "plt.xlabel('Slova')\n",
    "plt.ylabel('Vety')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nVsimni si: slovo 'zdarma' se vyskytuje ve vetach 1 a 3 - to jsou typicke spam slova!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Priprava trenovacich dat\n",
    "\n",
    "Vytvorime dataset emailu pro trenovani spam filtru:\n",
    "- **SPAM**: Nevyzadane emaily (reklamy, podvody)\n",
    "- **HAM**: Legitimni emaily"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trenovaci data pro spam filtr\n",
    "data = [\n",
    "    # SPAM emaily\n",
    "    ('Vyzvedni si svou vyhru zdarma klikni zde', 'spam'),\n",
    "    ('Exkluzivni nabidka jen pro vas nevahe jte', 'spam'),\n",
    "    ('Kliknete zde pro neuveritelnou slevu', 'spam'),\n",
    "    ('Ziskejte pujcku bez dolozeni prijmu rychle', 'spam'),\n",
    "    ('Vyhrali jste milion dolaru gratulujeme', 'spam'),\n",
    "    ('Nakupujte zdarma slevy az 90 procent', 'spam'),\n",
    "    ('Pilulky na hubnuti zadarmo objednejte', 'spam'),\n",
    "    ('Rychla pujcka bez ruceni kliknete', 'spam'),\n",
    "    ('Zdarma iPhone kliknete a vyhrajte', 'spam'),\n",
    "    ('Nabidka prace z domu vydelejte miliony', 'spam'),\n",
    "    ('Kliknete pro slevu kupte ted', 'spam'),\n",
    "    ('Vase konto bude zruseno kliknete overit', 'spam'),\n",
    "    # HAM (legitimni) emaily\n",
    "    ('Ahoj jak se mas sejdeme se zitra', 'ham'),\n",
    "    ('Zprava o stavu projektu prikladam report', 'ham'),\n",
    "    ('Dekuji za vas email odpovim co nejdrive', 'ham'),\n",
    "    ('Potvrzeni vasi objednavky cislo 12345', 'ham'),\n",
    "    ('Schuzka zitra v 10 hodin v kancelari', 'ham'),\n",
    "    ('Posilam ti dokumenty k projektu', 'ham'),\n",
    "    ('Kdy budes mit cas na kavu', 'ham'),\n",
    "    ('Pripominam deadline projektu v patek', 'ham'),\n",
    "    ('Diky za pomoc moc si toho vazim', 'ham'),\n",
    "    ('Posli mi prosim cislo uctu', 'ham'),\n",
    "    ('Jak dopadla ta schuzka vcera', 'ham'),\n",
    "    ('Pozvanka na narozeninovou oslavu', 'ham'),\n",
    "]\n",
    "\n",
    "# Prevedeni na DataFrame\n",
    "df = pd.DataFrame(data, columns=['text', 'kategorie'])\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"DATASET PRO SPAM FILTR\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\nCelkem emailu: {len(df)}\")\n",
    "print(f\"\\nRozdeleni:\")\n",
    "print(df['kategorie'].value_counts())\n",
    "\n",
    "print(\"\\nUkazka dat:\")\n",
    "print(df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vizualizace rozdeleni dat\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# Graf 1: Pocty\n",
    "ax1 = axes[0]\n",
    "kategorie_counts = df['kategorie'].value_counts()\n",
    "colors = ['#e74c3c', '#2ecc71']\n",
    "bars = ax1.bar(kategorie_counts.index, kategorie_counts.values, color=colors, edgecolor='black')\n",
    "ax1.set_xlabel('Kategorie')\n",
    "ax1.set_ylabel('Pocet emailu')\n",
    "ax1.set_title('Rozdeleni emailu podle kategorie')\n",
    "for bar, count in zip(bars, kategorie_counts.values):\n",
    "    ax1.text(bar.get_x() + bar.get_width()/2., bar.get_height() + 0.2,\n",
    "             str(count), ha='center', fontsize=12, fontweight='bold')\n",
    "\n",
    "# Graf 2: Delka emailu\n",
    "ax2 = axes[1]\n",
    "df['delka'] = df['text'].apply(len)\n",
    "df[df['kategorie']=='spam']['delka'].hist(ax=ax2, bins=10, alpha=0.7, label='Spam', color='#e74c3c')\n",
    "df[df['kategorie']=='ham']['delka'].hist(ax=ax2, bins=10, alpha=0.7, label='Ham', color='#2ecc71')\n",
    "ax2.set_xlabel('Delka textu (znaky)')\n",
    "ax2.set_ylabel('Pocet')\n",
    "ax2.set_title('Distribuce delky emailu')\n",
    "ax2.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Trenovani Naivniho Bayesova klasifikatoru\n",
    "\n",
    "Kroky:\n",
    "1. Rozdeleni dat na trenovaci a testovaci\n",
    "2. Vektorizace textu (Bag of Words)\n",
    "3. Trenovani MultinomialNB modelu\n",
    "4. Evaluace vysledku"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Priprava dat\n",
    "X = df['text']\n",
    "y = df['kategorie']\n",
    "\n",
    "# Rozdeleni na trenovaci a testovaci data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.25, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"ROZDELENI DAT\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Trenovacich vzorku: {len(X_train)}\")\n",
    "print(f\"Testovacich vzorku: {len(X_test)}\")\n",
    "\n",
    "# Vektorizace textu\n",
    "vectorizer = CountVectorizer()\n",
    "X_train_vec = vectorizer.fit_transform(X_train)\n",
    "X_test_vec = vectorizer.transform(X_test)\n",
    "\n",
    "print(f\"\\nPocet unikatnich slov (features): {len(vectorizer.get_feature_names_out())}\")\n",
    "print(f\"Tvar trenovaci matice: {X_train_vec.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trenovani modelu\n",
    "print(\"=\" * 60)\n",
    "print(\"TRENOVANI NAIVE BAYES MODELU\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Vytvoreni a trenovani klasifikatoru\n",
    "model = MultinomialNB()\n",
    "model.fit(X_train_vec, y_train)\n",
    "\n",
    "print(\"\\nModel uspesne natrenovan!\")\n",
    "\n",
    "# Predikce na testovacich datech\n",
    "y_pred = model.predict(X_test_vec)\n",
    "\n",
    "# Evaluace\n",
    "presnost = accuracy_score(y_test, y_pred)\n",
    "print(f\"\\nPresnost modelu: {presnost*100:.1f}%\")\n",
    "\n",
    "print(\"\\nDetailni report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vizualizace Confusion Matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred, labels=['ham', 'spam'])\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=['Ham (predikce)', 'Spam (predikce)'],\n",
    "            yticklabels=['Ham (skutecnost)', 'Spam (skutecnost)'])\n",
    "plt.title('Confusion Matrix - Vysledky klasifikace', fontsize=14)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Interpretace:\")\n",
    "print(f\"  - True Negatives (spravne HAM): {cm[0,0]}\")\n",
    "print(f\"  - False Positives (HAM oznacen jako SPAM): {cm[0,1]}\")\n",
    "print(f\"  - False Negatives (SPAM oznacen jako HAM): {cm[1,0]}\")\n",
    "print(f\"  - True Positives (spravne SPAM): {cm[1,1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Predikce na novych emailech\n",
    "\n",
    "Otestujme model na emailech, ktere nikdy predtim nevidel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testovani na novych emailech\n",
    "print(\"=\" * 60)\n",
    "print(\"PREDIKCE NA NOVYCH EMAILECH\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "nove_emaily = [\n",
    "    \"Ahoj posles mi prosim ten report\",\n",
    "    \"Vyhra zdarma kliknete ihned na odkaz\",\n",
    "    \"Schuzka zitra v 9 hodin\",\n",
    "    \"Nova nabidka pujcky bez uroku kliknete\",\n",
    "    \"Dekuji za pozvani na vecirek\",\n",
    "    \"Slevy az 90 procent nakupujte zdarma\"\n",
    "]\n",
    "\n",
    "# Vektorizace novych emailu\n",
    "nove_emaily_vec = vectorizer.transform(nove_emaily)\n",
    "\n",
    "# Predikce kategorii\n",
    "predikce = model.predict(nove_emaily_vec)\n",
    "\n",
    "# Predikce pravdepodobnosti\n",
    "pravdepodobnosti = model.predict_proba(nove_emaily_vec)\n",
    "\n",
    "print(\"\\nVysledky predikce:\")\n",
    "print(\"-\" * 70)\n",
    "for email, kat, prob in zip(nove_emaily, predikce, pravdepodobnosti):\n",
    "    ham_prob = prob[0] * 100\n",
    "    spam_prob = prob[1] * 100\n",
    "    print(f\"Email: '{email[:40]}...'\")\n",
    "    print(f\"  -> Predikce: {kat.upper()}\")\n",
    "    print(f\"  -> P(ham)={ham_prob:.1f}%, P(spam)={spam_prob:.1f}%\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vizualizace predikci\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "# Data pro graf\n",
    "x_labels = [f'Email {i+1}' for i in range(len(nove_emaily))]\n",
    "ham_probs = [p[0]*100 for p in pravdepodobnosti]\n",
    "spam_probs = [p[1]*100 for p in pravdepodobnosti]\n",
    "\n",
    "x = np.arange(len(nove_emaily))\n",
    "width = 0.35\n",
    "\n",
    "bars1 = ax.bar(x - width/2, ham_probs, width, label='P(HAM)', color='#2ecc71')\n",
    "bars2 = ax.bar(x + width/2, spam_probs, width, label='P(SPAM)', color='#e74c3c')\n",
    "\n",
    "ax.set_ylabel('Pravdepodobnost (%)')\n",
    "ax.set_title('Pravdepodobnosti klasifikace novych emailu', fontsize=14)\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(x_labels)\n",
    "ax.legend()\n",
    "ax.axhline(y=50, color='gray', linestyle='--', alpha=0.5)\n",
    "ax.set_ylim(0, 105)\n",
    "\n",
    "# Pridani finalni predikce\n",
    "for i, (ham, spam, pred) in enumerate(zip(ham_probs, spam_probs, predikce)):\n",
    "    ax.text(i, max(ham, spam) + 2, pred.upper(), ha='center', fontweight='bold',\n",
    "            color='#e74c3c' if pred == 'spam' else '#2ecc71')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Analyza dulezitosti slov\n",
    "\n",
    "Podivejme se, ktera slova model povazuje za nejdulezitejsi\n",
    "pro rozpoznani spamu a legitimnich emailu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyza dulezitosti slov\n",
    "print(\"=\" * 60)\n",
    "print(\"ANALYZA DULEZITOSTI SLOV\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Ziskani log-pravdepodobnosti slov pro kazdu tridu\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "log_probs = model.feature_log_prob_\n",
    "\n",
    "# Index trid\n",
    "ham_idx = list(model.classes_).index('ham')\n",
    "spam_idx = list(model.classes_).index('spam')\n",
    "\n",
    "# Vytvoreni DataFrame s log-pravdepodobnostmi\n",
    "df_words = pd.DataFrame({\n",
    "    'slovo': feature_names,\n",
    "    'log_prob_ham': log_probs[ham_idx],\n",
    "    'log_prob_spam': log_probs[spam_idx]\n",
    "})\n",
    "\n",
    "# Vypocet pomeru (log odds ratio)\n",
    "df_words['spam_vs_ham'] = df_words['log_prob_spam'] - df_words['log_prob_ham']\n",
    "\n",
    "# Top spam slova\n",
    "top_spam = df_words.nlargest(10, 'spam_vs_ham')\n",
    "print(\"\\nTop 10 slov indikujicich SPAM:\")\n",
    "for _, row in top_spam.iterrows():\n",
    "    print(f\"  {row['slovo']}: {row['spam_vs_ham']:.2f}\")\n",
    "\n",
    "# Top ham slova\n",
    "top_ham = df_words.nsmallest(10, 'spam_vs_ham')\n",
    "print(\"\\nTop 10 slov indikujicich HAM:\")\n",
    "for _, row in top_ham.iterrows():\n",
    "    print(f\"  {row['slovo']}: {row['spam_vs_ham']:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vizualizace nejdulezitejsich slov\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "# Spam slova\n",
    "top_spam_plot = df_words.nlargest(15, 'spam_vs_ham')\n",
    "ax1.barh(top_spam_plot['slovo'], top_spam_plot['spam_vs_ham'], color='#e74c3c')\n",
    "ax1.set_xlabel('Log Odds Ratio (spam vs ham)')\n",
    "ax1.set_title('Top 15 SPAM indikatory', fontsize=14, fontweight='bold')\n",
    "ax1.invert_yaxis()\n",
    "\n",
    "# Ham slova\n",
    "top_ham_plot = df_words.nsmallest(15, 'spam_vs_ham')\n",
    "ax2.barh(top_ham_plot['slovo'], -top_ham_plot['spam_vs_ham'], color='#2ecc71')\n",
    "ax2.set_xlabel('Log Odds Ratio (ham vs spam)')\n",
    "ax2.set_title('Top 15 HAM indikatory', fontsize=14, fontweight='bold')\n",
    "ax2.invert_yaxis()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nInterpretace:\")\n",
    "print(\"- Slova jako 'zdarma', 'kliknete', 'pujcku' silne indikuji spam\")\n",
    "print(\"- Slova jako 'ahoj', 'prosim', 'dekuji' silne indikuji legitimni email\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. TF-IDF vektorizace\n",
    "\n",
    "Alternativa k Bag of Words je **TF-IDF** (Term Frequency - Inverse Document Frequency),\n",
    "ktera davá nižší váhu častým slovům a vyšší váhu vzácným slovům."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Srovnani CountVectorizer vs TfidfVectorizer\n",
    "print(\"=\" * 60)\n",
    "print(\"SROVNANI: CountVectorizer vs TF-IDF\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# TF-IDF vektorizace\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test)\n",
    "\n",
    "# Trenovani modelu s TF-IDF\n",
    "model_tfidf = MultinomialNB()\n",
    "model_tfidf.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Predikce\n",
    "y_pred_tfidf = model_tfidf.predict(X_test_tfidf)\n",
    "presnost_tfidf = accuracy_score(y_test, y_pred_tfidf)\n",
    "\n",
    "print(f\"\\nPresnost s CountVectorizer: {presnost*100:.1f}%\")\n",
    "print(f\"Presnost s TF-IDF: {presnost_tfidf*100:.1f}%\")\n",
    "\n",
    "# Cross-validace pro robustnejsi vysledky\n",
    "print(\"\\nCross-validace (5-fold):\")\n",
    "\n",
    "# CountVectorizer\n",
    "X_all_count = vectorizer.fit_transform(X)\n",
    "cv_scores_count = cross_val_score(MultinomialNB(), X_all_count, y, cv=5)\n",
    "print(f\"  CountVectorizer: {cv_scores_count.mean()*100:.1f}% (+/- {cv_scores_count.std()*100:.1f}%)\")\n",
    "\n",
    "# TF-IDF\n",
    "X_all_tfidf = tfidf_vectorizer.fit_transform(X)\n",
    "cv_scores_tfidf = cross_val_score(MultinomialNB(), X_all_tfidf, y, cv=5)\n",
    "print(f\"  TF-IDF: {cv_scores_tfidf.mean()*100:.1f}% (+/- {cv_scores_tfidf.std()*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vizualizace srovnani\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "metody = ['CountVectorizer', 'TF-IDF']\n",
    "presnosti = [cv_scores_count.mean()*100, cv_scores_tfidf.mean()*100]\n",
    "std_devs = [cv_scores_count.std()*100, cv_scores_tfidf.std()*100]\n",
    "\n",
    "colors = ['#3498db', '#9b59b6']\n",
    "bars = ax.bar(metody, presnosti, color=colors, edgecolor='black', yerr=std_devs, capsize=5)\n",
    "\n",
    "ax.set_ylabel('Presnost (%)')\n",
    "ax.set_title('Srovnani metod vektorizace textu', fontsize=14)\n",
    "ax.set_ylim(0, 110)\n",
    "\n",
    "for bar, p, s in zip(bars, presnosti, std_devs):\n",
    "    ax.text(bar.get_x() + bar.get_width()/2., bar.get_height() + s + 2,\n",
    "            f'{p:.1f}%', ha='center', fontsize=12, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Mini-projekt: Kompletni spam filtr\n",
    "\n",
    "Vytvorime kompletni spam filtr jako tridu, kterou lze snadno pouzit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpamFiltr:\n",
    "    \"\"\"\n",
    "    Kompletni spam filtr zalozeny na Naive Bayes.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, metoda='count'):\n",
    "        \"\"\"\n",
    "        Inicializace spam filtru.\n",
    "        \n",
    "        Parametry:\n",
    "        - metoda: 'count' pro CountVectorizer, 'tfidf' pro TfidfVectorizer\n",
    "        \"\"\"\n",
    "        if metoda == 'tfidf':\n",
    "            self.vectorizer = TfidfVectorizer()\n",
    "        else:\n",
    "            self.vectorizer = CountVectorizer()\n",
    "        \n",
    "        self.model = MultinomialNB()\n",
    "        self.je_natrenovany = False\n",
    "    \n",
    "    def trenuj(self, texty, labely):\n",
    "        \"\"\"\n",
    "        Natrenuje spam filtr na datech.\n",
    "        \n",
    "        Parametry:\n",
    "        - texty: seznam textu emailu\n",
    "        - labely: seznam labelu ('spam' nebo 'ham')\n",
    "        \"\"\"\n",
    "        X = self.vectorizer.fit_transform(texty)\n",
    "        self.model.fit(X, labely)\n",
    "        self.je_natrenovany = True\n",
    "        print(f\"Spam filtr natrenovan na {len(texty)} emailech.\")\n",
    "        print(f\"Slovnik obsahuje {len(self.vectorizer.get_feature_names_out())} slov.\")\n",
    "    \n",
    "    def klasifikuj(self, email, podrobne=False):\n",
    "        \"\"\"\n",
    "        Klasifikuje email jako spam nebo ham.\n",
    "        \n",
    "        Parametry:\n",
    "        - email: text emailu\n",
    "        - podrobne: pokud True, vypise podrobnosti\n",
    "        \n",
    "        Vraci:\n",
    "        - slovnik s vysledkem klasifikace\n",
    "        \"\"\"\n",
    "        if not self.je_natrenovany:\n",
    "            raise Exception(\"Filtr neni natrenovany! Zavolej nejprve trenuj()\")\n",
    "        \n",
    "        X = self.vectorizer.transform([email])\n",
    "        predikce = self.model.predict(X)[0]\n",
    "        pravdepodobnosti = self.model.predict_proba(X)[0]\n",
    "        \n",
    "        vysledek = {\n",
    "            'email': email,\n",
    "            'kategorie': predikce,\n",
    "            'je_spam': predikce == 'spam',\n",
    "            'p_ham': pravdepodobnosti[0],\n",
    "            'p_spam': pravdepodobnosti[1],\n",
    "            'jistota': max(pravdepodobnosti)\n",
    "        }\n",
    "        \n",
    "        if podrobne:\n",
    "            print(f\"Email: '{email[:50]}...'\" if len(email) > 50 else f\"Email: '{email}'\")\n",
    "            print(f\"Kategorie: {predikce.upper()}\")\n",
    "            print(f\"P(ham): {pravdepodobnosti[0]*100:.1f}%\")\n",
    "            print(f\"P(spam): {pravdepodobnosti[1]*100:.1f}%\")\n",
    "            print(f\"Jistota: {max(pravdepodobnosti)*100:.1f}%\")\n",
    "        \n",
    "        return vysledek\n",
    "    \n",
    "    def klasifikuj_hromadne(self, emaily):\n",
    "        \"\"\"\n",
    "        Klasifikuje vice emailu najednou.\n",
    "        \"\"\"\n",
    "        return [self.klasifikuj(email) for email in emaily]\n",
    "\n",
    "\n",
    "print(\"Trida SpamFiltr pripravena!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pouziti spam filtru\n",
    "print(\"=\" * 60)\n",
    "print(\"DEMONSTRACE: SpamFiltr v akci\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Vytvoreni a trenovani filtru\n",
    "filtr = SpamFiltr(metoda='count')\n",
    "filtr.trenuj(df['text'].tolist(), df['kategorie'].tolist())\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"TESTOVANI FILTRU\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Testovaci emaily\n",
    "testovaci = [\n",
    "    \"Ahoj kdy se uvidime na kave\",\n",
    "    \"Zdarma vyhra kliknete na odkaz\",\n",
    "    \"Posli mi prosim cislo na kolegu\",\n",
    "    \"Pujcka bez uroku nabidka kliknete\"\n",
    "]\n",
    "\n",
    "for email in testovaci:\n",
    "    print()\n",
    "    vysledek = filtr.klasifikuj(email, podrobne=True)\n",
    "    print(\"-\" * 40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Shrnutí kapitoly\n",
    "\n",
    "### Co jsme se naučili:\n",
    "\n",
    "1. **Bag of Words** - model, kde text je reprezentovan jako \"pytel slov\" bez ohledu na poradi\n",
    "\n",
    "2. **CountVectorizer** - prevadi text na matici vyskytu slov\n",
    "\n",
    "3. **Naivni Bayesuv klasifikator** - \"naivne\" predpoklada nezavislost slov, presto velmi efektivni\n",
    "\n",
    "4. **TF-IDF** - alternativa k Bag of Words, ktera zohlednuje dulezitost slov\n",
    "\n",
    "5. **Evaluace** - confusion matrix, precision, recall, F1-score\n",
    "\n",
    "### Praktické využití Naive Bayes:\n",
    "- **Spam filtry** - Gmail, Outlook\n",
    "- **Analyza sentimentu** - pozitivni/negativni recenze\n",
    "- **Kategorizace dokumentu** - sport, politika, kultura\n",
    "- **Doporucovaci systemy** - Netflix, Amazon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finalni vizualizace - jak Naive Bayes funguje\n",
    "print(\"=\" * 60)\n",
    "print(\"JAK NAIVE BAYES ROZHODUJE\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Priklad rozhodovani\n",
    "priklad_email = \"Vyhra zdarma kliknete\"\n",
    "print(f\"\\nEmail: '{priklad_email}'\")\n",
    "print(\"\\nProces rozhodovani:\")\n",
    "print(\"1. Rozdeleni na slova: ['vyhra', 'zdarma', 'kliknete']\")\n",
    "print(\"2. Pro kazde slovo se pocita P(slovo|spam) a P(slovo|ham)\")\n",
    "print(\"3. Nasobeni pravdepodobnosti (naivni predpoklad nezavislosti)\")\n",
    "print(\"4. Porovnani: P(spam|email) vs P(ham|email)\")\n",
    "\n",
    "# Demonstrace na realnem prikladu\n",
    "vysledek = filtr.klasifikuj(priklad_email)\n",
    "print(f\"\\n5. Vysledek: P(spam)={vysledek['p_spam']*100:.1f}% > P(ham)={vysledek['p_ham']*100:.1f}%\")\n",
    "print(f\"   => Email je klasifikovan jako {vysledek['kategorie'].upper()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Cviceni pro procviceni\n",
    "\n",
    "### Cviceni 1:\n",
    "Pridejte do datasetu dalsi emaily (spam i ham) a sledujte, jak se zmeni presnost modelu.\n",
    "\n",
    "### Cviceni 2:\n",
    "Porovnejte MultinomialNB s jinymi variantami (BernoulliNB, GaussianNB).\n",
    "\n",
    "### Cviceni 3:\n",
    "Implementujte filtr pro analyzu sentimentu (pozitivni/negativni recenze produktu)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prostor pro cviceni\n",
    "print(\"Cviceni 1: Pridejte dalsi emaily\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# Priklad - pridejte dalsi emaily do datasetu:\n",
    "nove_data = [\n",
    "    ('Specialni akce slevy nakupujte', 'spam'),\n",
    "    ('Posilam ti pozvanku na konferenci', 'ham'),\n",
    "]\n",
    "\n",
    "# Pridani do datasetu\n",
    "df_rozsireny = pd.concat([df, pd.DataFrame(nove_data, columns=['text', 'kategorie'])], ignore_index=True)\n",
    "print(f\"Puvodni pocet: {len(df)}\")\n",
    "print(f\"Rozsireny pocet: {len(df_rozsireny)}\")\n",
    "\n",
    "# Pretrenujte model a porovnejte vysledky..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Dalsi kroky\n",
    "\n",
    "V pristi kapitole se podivame na **neuronove site** - zaklad modernich AI systemu\n",
    "a hluboke uceni (Deep Learning).\n",
    "\n",
    "---\n",
    "\n",
    "*Kapitola 19 - Naivni Bayesuv klasifikator | Kurz AI pro zacatecniky*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}