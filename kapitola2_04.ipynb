{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üìù Sumarizace a generov√°n√≠ textu\n",
    "\n",
    "**Autor:** Praut s.r.o. - AI Integration & Business Automation\n",
    "\n",
    "## Co se nauƒç√≠te:\n",
    "- Automatick√° sumarizace dokument≈Ø\n",
    "- Generov√°n√≠ textu s r≈Øzn√Ωmi modely\n",
    "- Tvorba report≈Ø a shrnut√≠\n",
    "- Automatizace tvorby obsahu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q transformers accelerate torch sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline, AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "import torch\n",
    "\n",
    "device = 0 if torch.cuda.is_available() else -1\n",
    "print(f\"üñ•Ô∏è Device: {'GPU' if device == 0 else 'CPU'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Extraktivn√≠ vs. Abstraktivn√≠ sumarizace\n",
    "\n",
    "- **Extraktivn√≠**: Vyb√≠r√° kl√≠ƒçov√© vƒõty z p≈Øvodn√≠ho textu\n",
    "- **Abstraktivn√≠**: Generuje nov√Ω text shrnuj√≠c√≠ obsah"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BART model pro abstraktivn√≠ sumarizaci\n",
    "summarizer = pipeline(\"summarization\", \n",
    "                      model=\"facebook/bart-large-cnn\",\n",
    "                      device=device)\n",
    "\n",
    "clanek = \"\"\"\n",
    "Artificial intelligence is rapidly transforming the business landscape across industries. \n",
    "Companies are increasingly adopting AI technologies to streamline operations, enhance \n",
    "customer experiences, and gain competitive advantages. Machine learning algorithms can \n",
    "analyze vast amounts of data to identify patterns and make predictions that would be \n",
    "impossible for humans to detect manually.\n",
    "\n",
    "In the manufacturing sector, AI-powered robots are improving production efficiency and \n",
    "reducing errors. Predictive maintenance systems can anticipate equipment failures before \n",
    "they occur, saving companies millions in downtime costs. Quality control processes are \n",
    "being automated using computer vision, ensuring consistent product standards.\n",
    "\n",
    "The financial industry is leveraging AI for fraud detection, risk assessment, and \n",
    "algorithmic trading. Banks are using chatbots to handle routine customer inquiries, \n",
    "freeing up human agents for more complex issues. Personalized financial advice is \n",
    "being delivered through AI-driven robo-advisors.\n",
    "\n",
    "Healthcare is another sector seeing significant AI adoption. Diagnostic systems can \n",
    "analyze medical images with accuracy matching or exceeding human specialists. Drug \n",
    "discovery processes are being accelerated through AI simulations. Patient monitoring \n",
    "systems can detect anomalies and alert medical staff in real-time.\n",
    "\"\"\"\n",
    "\n",
    "souhrn = summarizer(clanek, max_length=100, min_length=30, do_sample=False)\n",
    "\n",
    "print(f\"üìÑ P≈Øvodn√≠ text: {len(clanek)} znak≈Ø\")\n",
    "print(f\"üìã Souhrn: {len(souhrn[0]['summary_text'])} znak≈Ø\\n\")\n",
    "print(f\"‚ú® {souhrn[0]['summary_text']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. R≈Øzn√© d√©lky sumarizace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kr√°tk√Ω souhrn (1-2 vƒõty)\n",
    "kratky = summarizer(clanek, max_length=50, min_length=20)\n",
    "print(\"üìå KR√ÅTK√ù souhrn:\")\n",
    "print(f\"   {kratky[0]['summary_text']}\\n\")\n",
    "\n",
    "# St≈ôedn√≠ souhrn\n",
    "stredni = summarizer(clanek, max_length=100, min_length=50)\n",
    "print(\"üìù ST≈òEDN√ç souhrn:\")\n",
    "print(f\"   {stredni[0]['summary_text']}\\n\")\n",
    "\n",
    "# Dlouh√Ω souhrn\n",
    "dlouhy = summarizer(clanek, max_length=200, min_length=100)\n",
    "print(\"üìÑ DLOUH√ù souhrn:\")\n",
    "print(f\"   {dlouhy[0]['summary_text']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. T5 model - flexibilnƒõj≈°√≠ sumarizace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# T5 model\n",
    "t5_summarizer = pipeline(\"summarization\", \n",
    "                         model=\"t5-base\",\n",
    "                         device=device)\n",
    "\n",
    "# T5 pou≈æ√≠v√° prefix \"summarize:\"\n",
    "text_pro_t5 = clanek\n",
    "\n",
    "t5_souhrn = t5_summarizer(text_pro_t5, max_length=80, min_length=20)\n",
    "print(\"üî∑ T5 souhrn:\")\n",
    "print(f\"   {t5_souhrn[0]['summary_text']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Generov√°n√≠ textu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPT-2 pro generov√°n√≠ textu\n",
    "generator = pipeline(\"text-generation\", \n",
    "                     model=\"gpt2-medium\",\n",
    "                     device=device)\n",
    "\n",
    "prompt = \"The future of artificial intelligence in business will\"\n",
    "\n",
    "# Generov√°n√≠ s r≈Øzn√Ωmi parametry\n",
    "print(\"üé≤ Kreativn√≠ generov√°n√≠ (vysok√° temperature):\")\n",
    "kreativni = generator(prompt, max_length=100, temperature=0.9, do_sample=True, num_return_sequences=1)\n",
    "print(f\"   {kreativni[0]['generated_text']}\\n\")\n",
    "\n",
    "print(\"üéØ Konzervativn√≠ generov√°n√≠ (n√≠zk√° temperature):\")\n",
    "konzervativni = generator(prompt, max_length=100, temperature=0.3, do_sample=True, num_return_sequences=1)\n",
    "print(f\"   {konzervativni[0]['generated_text']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# V√≠ce variant\n",
    "print(\"üìö V√≠cen√°sobn√© generov√°n√≠ (3 varianty):\\n\")\n",
    "\n",
    "varianty = generator(\n",
    "    \"Automation in business helps companies to\",\n",
    "    max_length=60,\n",
    "    num_return_sequences=3,\n",
    "    do_sample=True,\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "for i, var in enumerate(varianty, 1):\n",
    "    print(f\"Varianta {i}: {var['generated_text']}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Praktick√° automatizace: Gener√°tor newsletteru"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generuj_newsletter_sekci(tema, body):\n",
    "    \"\"\"Generuje sekci newsletteru z bullet point≈Ø.\"\"\"\n",
    "    \n",
    "    # Shrnut√≠ bod≈Ø\n",
    "    text = f\"{tema}. \" + \" \".join(body)\n",
    "    souhrn = summarizer(text, max_length=100, min_length=30)\n",
    "    \n",
    "    return souhrn[0]['summary_text']\n",
    "\n",
    "# Data pro newsletter\n",
    "newsletter_data = {\n",
    "    \"AI novinky\": [\n",
    "        \"OpenAI released GPT-4 with improved reasoning capabilities.\",\n",
    "        \"Google announced Gemini multimodal AI model.\",\n",
    "        \"Meta open-sourced Llama 3 for research and commercial use.\"\n",
    "    ],\n",
    "    \"Produktov√© updaty\": [\n",
    "        \"New dashboard with real-time analytics is now available.\",\n",
    "        \"Integration with Slack and Teams has been improved.\",\n",
    "        \"Mobile app now supports offline mode.\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "print(\"üì∞ AUTOMATICKY GENEROVAN√ù NEWSLETTER\\n\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "for sekce, body in newsletter_data.items():\n",
    "    souhrn = generuj_newsletter_sekci(sekce, body)\n",
    "    print(f\"\\nüìå {sekce.upper()}\")\n",
    "    print(f\"   {souhrn}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Sumarizace dlouh√Ωch dokument≈Ø"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sumarizuj_dlouhy_dokument(text, max_chunk_length=1000):\n",
    "    \"\"\"Sumarizuje dlouh√Ω dokument po ƒç√°stech.\"\"\"\n",
    "    \n",
    "    # Rozdƒõlen√≠ na ƒç√°sti (paragraphs)\n",
    "    paragrafy = [p.strip() for p in text.split('\\n\\n') if p.strip()]\n",
    "    \n",
    "    # Slouƒçen√≠ do chunk≈Ø\n",
    "    chunky = []\n",
    "    current_chunk = \"\"\n",
    "    \n",
    "    for para in paragrafy:\n",
    "        if len(current_chunk) + len(para) < max_chunk_length:\n",
    "            current_chunk += para + \" \"\n",
    "        else:\n",
    "            if current_chunk:\n",
    "                chunky.append(current_chunk.strip())\n",
    "            current_chunk = para + \" \"\n",
    "    \n",
    "    if current_chunk:\n",
    "        chunky.append(current_chunk.strip())\n",
    "    \n",
    "    # Sumarizace ka≈æd√©ho chunku\n",
    "    souhrny = []\n",
    "    for i, chunk in enumerate(chunky):\n",
    "        if len(chunk) > 100:  # Minim√°ln√≠ d√©lka pro sumarizaci\n",
    "            souhrn = summarizer(chunk, max_length=60, min_length=20)\n",
    "            souhrny.append(souhrn[0]['summary_text'])\n",
    "            print(f\"   ‚úì ƒå√°st {i+1}/{len(chunky)} zpracov√°na\")\n",
    "    \n",
    "    # Fin√°ln√≠ souhrn\n",
    "    if len(souhrny) > 1:\n",
    "        combined = \" \".join(souhrny)\n",
    "        final = summarizer(combined, max_length=150, min_length=50)\n",
    "        return final[0]['summary_text']\n",
    "    elif souhrny:\n",
    "        return souhrny[0]\n",
    "    return \"Text je p≈ô√≠li≈° kr√°tk√Ω pro sumarizaci.\"\n",
    "\n",
    "# Test na dlouh√©m dokumentu\n",
    "dlouhy_dokument = clanek * 3  # Simulace del≈°√≠ho textu\n",
    "\n",
    "print(f\"üìÑ Zpracov√°v√°m dokument ({len(dlouhy_dokument)} znak≈Ø)...\\n\")\n",
    "vysledek = sumarizuj_dlouhy_dokument(dlouhy_dokument)\n",
    "print(f\"\\nüìã Fin√°ln√≠ souhrn:\\n{vysledek}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Automatick√© generov√°n√≠ report≈Ø"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def generuj_report(data_dict):\n",
    "    \"\"\"Generuje textov√Ω report z dat.\"\"\"\n",
    "    \n",
    "    # Konverze dat na text\n",
    "    text_parts = []\n",
    "    for metrika, hodnota in data_dict.items():\n",
    "        text_parts.append(f\"The {metrika} is {hodnota}.\")\n",
    "    \n",
    "    raw_text = \" \".join(text_parts)\n",
    "    \n",
    "    # Generov√°n√≠ interpretace\n",
    "    prompt = f\"Business report summary: {raw_text} In conclusion,\"\n",
    "    \n",
    "    report = generator(prompt, max_length=150, do_sample=True, temperature=0.5)\n",
    "    \n",
    "    return report[0]['generated_text']\n",
    "\n",
    "# Simulace business dat\n",
    "mesicni_data = {\n",
    "    \"revenue\": \"$1.2 million, up 15% from last month\",\n",
    "    \"customer satisfaction score\": \"4.5 out of 5\",\n",
    "    \"new customers acquired\": \"250, exceeding target by 20%\",\n",
    "    \"employee retention rate\": \"95%\",\n",
    "    \"operational efficiency\": \"improved by 12%\"\n",
    "}\n",
    "\n",
    "print(\"üìä MƒöS√çƒåN√ç BUSINESS REPORT\\n\")\n",
    "print(\"=\" * 50)\n",
    "print(\"\\nüìà Kl√≠ƒçov√© metriky:\")\n",
    "for metrika, hodnota in mesicni_data.items():\n",
    "    print(f\"   ‚Ä¢ {metrika.title()}: {hodnota}\")\n",
    "\n",
    "print(\"\\nüìù Automatick√Ω souhrn:\")\n",
    "report = generuj_report(mesicni_data)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Parafr√°zov√°n√≠ textu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PEGASUS pro parafr√°zov√°n√≠\n",
    "paraphraser = pipeline(\"text2text-generation\", \n",
    "                       model=\"tuner007/pegasus_paraphrase\",\n",
    "                       device=device)\n",
    "\n",
    "originalni = \"The company achieved significant growth in the last quarter due to increased market demand.\"\n",
    "\n",
    "parafr√°ze = paraphraser(originalni, num_return_sequences=3, num_beams=5, max_length=60)\n",
    "\n",
    "print(f\"üìù Origin√°l: {originalni}\\n\")\n",
    "print(\"üîÑ Parafr√°ze:\")\n",
    "for i, p in enumerate(parafr√°ze, 1):\n",
    "    print(f\"   {i}. {p['generated_text']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## üèÅ Shrnut√≠\n",
    "\n",
    "- ‚úÖ BART a T5 pro sumarizaci\n",
    "- ‚úÖ GPT-2 pro generov√°n√≠ textu\n",
    "- ‚úÖ Zpracov√°n√≠ dlouh√Ωch dokument≈Ø po ƒç√°stech\n",
    "- ‚úÖ Automatick√© generov√°n√≠ report≈Ø a newsletter≈Ø\n",
    "- ‚úÖ Parafr√°zov√°n√≠ textu\n",
    "\n",
    "**Dal≈°√≠ notebook:** P≈ôeklad a v√≠cejazyƒçn√© modely"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "accelerator": "GPU",
  "colab": {
   "provenance": [],
   "gpuType": "T4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
