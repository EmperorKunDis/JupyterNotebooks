{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ‚ùì Question Answering a vyhled√°v√°n√≠ v dokumentech\n",
    "\n",
    "**Autor:** Praut s.r.o. - AI Integration & Business Automation\n",
    "\n",
    "## Co se nauƒç√≠te:\n",
    "- Extraktivn√≠ QA (nalezen√≠ odpovƒõdi v textu)\n",
    "- Generativn√≠ QA\n",
    "- Vyhled√°v√°n√≠ v dokumentech\n",
    "- Automatizace FAQ a helpdesku"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q transformers accelerate torch faiss-cpu sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "import torch\n",
    "\n",
    "device = 0 if torch.cuda.is_available() else -1\n",
    "print(f\"üñ•Ô∏è Device: {'GPU' if device == 0 else 'CPU'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Extraktivn√≠ Question Answering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# QA pipeline\n",
    "qa = pipeline(\"question-answering\", \n",
    "              model=\"deepset/roberta-base-squad2\",\n",
    "              device=device)\n",
    "\n",
    "# Kontext (znalostn√≠ b√°ze)\n",
    "kontext = \"\"\"\n",
    "Praut s.r.o. is a Czech company specializing in AI integration and business automation. \n",
    "The company was founded in Cheb and focuses on implementing artificial intelligence \n",
    "into business processes for Czech firms. Services include AI automation, custom development, \n",
    "cloud and server deployment, employee training, and system design.\n",
    "\n",
    "The company works with modern technology stacks including Django, Angular, PostgreSQL, \n",
    "Redis, Celery, and various AI providers. PostHub is the company's flagship SaaS product \n",
    "for social media content automation.\n",
    "\n",
    "Working hours are Monday to Friday, 9:00 AM to 5:00 PM. The support team can be reached \n",
    "at support@praut.cz. Emergency support is available 24/7 for enterprise customers.\n",
    "\"\"\"\n",
    "\n",
    "otazky = [\n",
    "    \"Where is Praut s.r.o. located?\",\n",
    "    \"What services does the company offer?\",\n",
    "    \"What is PostHub?\",\n",
    "    \"What are the working hours?\",\n",
    "    \"How can I contact support?\"\n",
    "]\n",
    "\n",
    "print(\"‚ùì Automatick√© odpov√≠d√°n√≠ na ot√°zky:\\n\")\n",
    "for otazka in otazky:\n",
    "    odpoved = qa(question=otazka, context=kontext)\n",
    "    print(f\"Q: {otazka}\")\n",
    "    print(f\"A: {odpoved['answer']} (confidence: {odpoved['score']:.1%})\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. QA s v√≠ce kontexty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datab√°ze dokument≈Ø\n",
    "dokumenty = [\n",
    "    {\n",
    "        \"title\": \"Pricing\",\n",
    "        \"content\": \"\"\"Our pricing plans include: Starter at $29/month for small businesses, \n",
    "        Professional at $99/month for growing teams, and Enterprise with custom pricing \n",
    "        for large organizations. All plans include 14-day free trial.\"\"\"\n",
    "    },\n",
    "    {\n",
    "        \"title\": \"Features\",\n",
    "        \"content\": \"\"\"Key features include: AI-powered content generation, multi-platform \n",
    "        social media scheduling, analytics dashboard, team collaboration tools, \n",
    "        and API access for custom integrations.\"\"\"\n",
    "    },\n",
    "    {\n",
    "        \"title\": \"Support\",\n",
    "        \"content\": \"\"\"Support options: Email support with 24h response time for all plans, \n",
    "        live chat available for Professional and Enterprise, dedicated account manager \n",
    "        for Enterprise customers. Knowledge base available at docs.example.com.\"\"\"\n",
    "    }\n",
    "]\n",
    "\n",
    "def najdi_odpoved(otazka, dokumenty):\n",
    "    \"\"\"Prohled√° v≈°echny dokumenty a najde nejlep≈°√≠ odpovƒõƒè.\"\"\"\n",
    "    nejlepsi = None\n",
    "    \n",
    "    for doc in dokumenty:\n",
    "        odpoved = qa(question=otazka, context=doc['content'])\n",
    "        if nejlepsi is None or odpoved['score'] > nejlepsi['score']:\n",
    "            nejlepsi = {\n",
    "                **odpoved,\n",
    "                'source': doc['title']\n",
    "            }\n",
    "    \n",
    "    return nejlepsi\n",
    "\n",
    "# Test\n",
    "test_otazky = [\n",
    "    \"How much does the Professional plan cost?\",\n",
    "    \"What features are included?\",\n",
    "    \"How fast is email support?\"\n",
    "]\n",
    "\n",
    "print(\"üîç Vyhled√°v√°n√≠ v dokumentech:\\n\")\n",
    "for otazka in test_otazky:\n",
    "    vysledek = najdi_odpoved(otazka, dokumenty)\n",
    "    print(f\"Q: {otazka}\")\n",
    "    print(f\"A: {vysledek['answer']}\")\n",
    "    print(f\"   üìÑ Zdroj: {vysledek['source']} | Confidence: {vysledek['score']:.1%}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Semantic Search s Sentence Transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "\n",
    "# Embedding model\n",
    "embedder = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# FAQ datab√°ze\n",
    "faq = [\n",
    "    {\"q\": \"How do I reset my password?\", \"a\": \"Go to Settings > Security > Reset Password.\"},\n",
    "    {\"q\": \"Can I cancel my subscription?\", \"a\": \"Yes, you can cancel anytime from Account Settings.\"},\n",
    "    {\"q\": \"How to export my data?\", \"a\": \"Use the Export feature in Dashboard > Data > Export.\"},\n",
    "    {\"q\": \"Is there a mobile app?\", \"a\": \"Yes, available for iOS and Android.\"},\n",
    "    {\"q\": \"How to add team members?\", \"a\": \"Go to Team > Invite Members and enter their emails.\"},\n",
    "    {\"q\": \"What payment methods do you accept?\", \"a\": \"We accept credit cards, PayPal, and bank transfers.\"},\n",
    "    {\"q\": \"How to integrate with Slack?\", \"a\": \"Navigate to Integrations > Slack and click Connect.\"},\n",
    "    {\"q\": \"Can I get a refund?\", \"a\": \"Refunds are available within 30 days of purchase.\"}\n",
    "]\n",
    "\n",
    "# Vytvo≈ôen√≠ embeddings pro FAQ\n",
    "faq_otazky = [f['q'] for f in faq]\n",
    "faq_embeddings = embedder.encode(faq_otazky, convert_to_numpy=True)\n",
    "\n",
    "def semantic_search(dotaz, top_k=3):\n",
    "    \"\"\"Najde nejrelevantnƒõj≈°√≠ FAQ polo≈æky.\"\"\"\n",
    "    dotaz_embedding = embedder.encode([dotaz], convert_to_numpy=True)[0]\n",
    "    \n",
    "    # V√Ωpoƒçet podobnosti (cosine)\n",
    "    similarities = np.dot(faq_embeddings, dotaz_embedding) / (\n",
    "        np.linalg.norm(faq_embeddings, axis=1) * np.linalg.norm(dotaz_embedding)\n",
    "    )\n",
    "    \n",
    "    # Top-k v√Ωsledky\n",
    "    top_indices = np.argsort(similarities)[::-1][:top_k]\n",
    "    \n",
    "    return [(faq[i], similarities[i]) for i in top_indices]\n",
    "\n",
    "# Test\n",
    "uzivatelske_dotazy = [\n",
    "    \"I forgot my password\",\n",
    "    \"How to connect Slack?\",\n",
    "    \"I want my money back\"\n",
    "]\n",
    "\n",
    "print(\"üîé Semantic FAQ Search:\\n\")\n",
    "for dotaz in uzivatelske_dotazy:\n",
    "    vysledky = semantic_search(dotaz, top_k=1)\n",
    "    nejlepsi = vysledky[0]\n",
    "    print(f\"‚ùì Dotaz: {dotaz}\")\n",
    "    print(f\"   Nalezeno: {nejlepsi[0]['q']}\")\n",
    "    print(f\"   üí° Odpovƒõƒè: {nejlepsi[0]['a']}\")\n",
    "    print(f\"   Relevance: {nejlepsi[1]:.1%}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Automatick√Ω FAQ Bot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FAQBot:\n",
    "    def __init__(self, faq_data, threshold=0.6):\n",
    "        self.faq = faq_data\n",
    "        self.threshold = threshold\n",
    "        self.embedder = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "        self.faq_embeddings = self.embedder.encode(\n",
    "            [f['q'] for f in self.faq], \n",
    "            convert_to_numpy=True\n",
    "        )\n",
    "    \n",
    "    def odpovez(self, dotaz):\n",
    "        \"\"\"Odpov√≠ na dotaz nebo po≈æ√°d√° o up≈ôesnƒõn√≠.\"\"\"\n",
    "        dotaz_emb = self.embedder.encode([dotaz], convert_to_numpy=True)[0]\n",
    "        \n",
    "        similarities = np.dot(self.faq_embeddings, dotaz_emb) / (\n",
    "            np.linalg.norm(self.faq_embeddings, axis=1) * np.linalg.norm(dotaz_emb)\n",
    "        )\n",
    "        \n",
    "        max_idx = np.argmax(similarities)\n",
    "        max_sim = similarities[max_idx]\n",
    "        \n",
    "        if max_sim >= self.threshold:\n",
    "            return {\n",
    "                'status': 'found',\n",
    "                'answer': self.faq[max_idx]['a'],\n",
    "                'matched_question': self.faq[max_idx]['q'],\n",
    "                'confidence': float(max_sim)\n",
    "            }\n",
    "        else:\n",
    "            # Nab√≠dni podobn√© ot√°zky\n",
    "            top_3 = np.argsort(similarities)[::-1][:3]\n",
    "            suggestions = [self.faq[i]['q'] for i in top_3]\n",
    "            return {\n",
    "                'status': 'unclear',\n",
    "                'message': 'Nena≈°el jsem p≈ôesnou odpovƒõƒè. Mysleli jste:',\n",
    "                'suggestions': suggestions\n",
    "            }\n",
    "\n",
    "# Inicializace bota\n",
    "bot = FAQBot(faq)\n",
    "\n",
    "# Simulace konverzace\n",
    "print(\"ü§ñ FAQ Bot Demo:\\n\")\n",
    "\n",
    "konverzace = [\n",
    "    \"How can I change my password?\",\n",
    "    \"something about teams\",\n",
    "    \"refund policy\"\n",
    "]\n",
    "\n",
    "for dotaz in konverzace:\n",
    "    print(f\"üë§ User: {dotaz}\")\n",
    "    odpoved = bot.odpovez(dotaz)\n",
    "    \n",
    "    if odpoved['status'] == 'found':\n",
    "        print(f\"ü§ñ Bot: {odpoved['answer']}\")\n",
    "        print(f\"   (Matched: {odpoved['matched_question']}, {odpoved['confidence']:.1%})\")\n",
    "    else:\n",
    "        print(f\"ü§ñ Bot: {odpoved['message']}\")\n",
    "        for i, sug in enumerate(odpoved['suggestions'], 1):\n",
    "            print(f\"   {i}. {sug}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Document QA s dlouh√Ωmi texty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def qa_dlouhy_dokument(otazka, dokument, chunk_size=500, overlap=50):\n",
    "    \"\"\"QA pro dlouh√© dokumenty - rozdƒõl√≠ na chunky.\"\"\"\n",
    "    \n",
    "    # Rozdƒõlen√≠ na chunky\n",
    "    words = dokument.split()\n",
    "    chunky = []\n",
    "    \n",
    "    for i in range(0, len(words), chunk_size - overlap):\n",
    "        chunk = ' '.join(words[i:i + chunk_size])\n",
    "        if chunk:\n",
    "            chunky.append(chunk)\n",
    "    \n",
    "    # QA na ka≈æd√©m chunku\n",
    "    nejlepsi_odpoved = None\n",
    "    \n",
    "    for i, chunk in enumerate(chunky):\n",
    "        try:\n",
    "            odpoved = qa(question=otazka, context=chunk)\n",
    "            if nejlepsi_odpoved is None or odpoved['score'] > nejlepsi_odpoved['score']:\n",
    "                nejlepsi_odpoved = {\n",
    "                    **odpoved,\n",
    "                    'chunk_index': i\n",
    "                }\n",
    "        except:\n",
    "            continue\n",
    "    \n",
    "    return nejlepsi_odpoved\n",
    "\n",
    "# Dlouh√Ω dokument\n",
    "dlouhy_text = \"\"\"\n",
    "Chapter 1: Introduction to AI\n",
    "\n",
    "Artificial Intelligence (AI) refers to the simulation of human intelligence in machines. \n",
    "The field was founded at a workshop at Dartmouth College in 1956. Key figures include \n",
    "John McCarthy, who coined the term, and Alan Turing, who proposed the Turing Test.\n",
    "\n",
    "Chapter 2: Machine Learning Fundamentals\n",
    "\n",
    "Machine learning is a subset of AI that enables systems to learn from data. The main types \n",
    "are supervised learning, unsupervised learning, and reinforcement learning. Popular algorithms \n",
    "include neural networks, decision trees, and support vector machines.\n",
    "\n",
    "Chapter 3: Deep Learning Revolution\n",
    "\n",
    "Deep learning uses neural networks with many layers. The breakthrough came in 2012 when \n",
    "AlexNet won the ImageNet competition. Key architectures include CNNs for images, RNNs for \n",
    "sequences, and Transformers for various tasks.\n",
    "\n",
    "Chapter 4: Natural Language Processing\n",
    "\n",
    "NLP enables computers to understand human language. BERT, introduced by Google in 2018, \n",
    "revolutionized the field. GPT models from OpenAI demonstrated impressive text generation \n",
    "capabilities. The latest models like GPT-4 show emergent abilities.\n",
    "\"\"\"\n",
    "\n",
    "otazky_dlouhy = [\n",
    "    \"When was AI founded?\",\n",
    "    \"What are the types of machine learning?\",\n",
    "    \"When did BERT come out?\"\n",
    "]\n",
    "\n",
    "print(\"üìö QA na dlouh√©m dokumentu:\\n\")\n",
    "for otazka in otazky_dlouhy:\n",
    "    odpoved = qa_dlouhy_dokument(otazka, dlouhy_text)\n",
    "    print(f\"Q: {otazka}\")\n",
    "    print(f\"A: {odpoved['answer']} ({odpoved['score']:.1%})\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Batch zpracov√°n√≠ FAQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Simulace support ticket≈Ø\n",
    "tickety = pd.DataFrame({\n",
    "    'id': range(1, 8),\n",
    "    'dotaz': [\n",
    "        \"Can't log in to my account\",\n",
    "        \"Need to add more users to team\",\n",
    "        \"Export data to CSV\",\n",
    "        \"Connect with Slack workspace\",\n",
    "        \"Upgrade subscription plan\",\n",
    "        \"Delete my account\",\n",
    "        \"Mobile app not working\"\n",
    "    ]\n",
    "})\n",
    "\n",
    "# Automatick√© odpov√≠d√°n√≠\n",
    "odpovedi = []\n",
    "for _, row in tickety.iterrows():\n",
    "    result = bot.odpovez(row['dotaz'])\n",
    "    odpovedi.append({\n",
    "        'auto_reply': result.get('answer', 'P≈ôed√°no oper√°torovi'),\n",
    "        'confidence': result.get('confidence', 0),\n",
    "        'auto_resolved': result['status'] == 'found' and result.get('confidence', 0) > 0.7\n",
    "    })\n",
    "\n",
    "tickety['auto_reply'] = [o['auto_reply'] for o in odpovedi]\n",
    "tickety['confidence'] = [o['confidence'] for o in odpovedi]\n",
    "tickety['auto_resolved'] = [o['auto_resolved'] for o in odpovedi]\n",
    "\n",
    "print(\"üìä Automatick√© zpracov√°n√≠ ticket≈Ø:\\n\")\n",
    "print(tickety[['id', 'dotaz', 'auto_resolved', 'confidence']].to_string(index=False))\n",
    "\n",
    "print(f\"\\n‚úÖ Automaticky vy≈ôe≈°eno: {tickety['auto_resolved'].sum()}/{len(tickety)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## üèÅ Shrnut√≠\n",
    "\n",
    "- ‚úÖ Extraktivn√≠ QA s RoBERTa\n",
    "- ‚úÖ Semantic search pro FAQ\n",
    "- ‚úÖ Automatick√Ω FAQ bot\n",
    "- ‚úÖ QA na dlouh√Ωch dokumentech\n",
    "- ‚úÖ Automatizace support ticket≈Ø\n",
    "\n",
    "**Dal≈°√≠ notebook:** Whisper - p≈ôevod ≈ôeƒçi na text"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "accelerator": "GPU",
  "colab": {
   "provenance": [],
   "gpuType": "T4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
