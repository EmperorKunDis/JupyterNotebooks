{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üéµ Audio AI: Text-to-Speech, Voice Processing a Generov√°n√≠ Audia\n",
    "\n",
    "**Autor:** Martin ≈†vanda, Praut s.r.o.  \n",
    "**Notebook:** 20/20 - Fin√°ln√≠ notebook s√©rie\n",
    "\n",
    "---\n",
    "\n",
    "## Co se nauƒç√≠te\n",
    "\n",
    "1. **Text-to-Speech (TTS)** - Generov√°n√≠ ≈ôeƒçi z textu pomoc√≠ modern√≠ch model≈Ø\n",
    "2. **Voice Cloning** - Klonov√°n√≠ hlasu z kr√°tk√Ωch uk√°zek\n",
    "3. **Audio Processing** - Zpracov√°n√≠ a anal√Ωza zvukov√Ωch dat\n",
    "4. **Music Generation** - Generov√°n√≠ hudby pomoc√≠ AI\n",
    "5. **Produkƒçn√≠ Audio Pipeline** - End-to-end ≈ôe≈°en√≠\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîß Instalace a Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instalace pot≈ôebn√Ωch knihoven\n",
    "!pip install -q transformers torch torchaudio\n",
    "!pip install -q datasets soundfile librosa scipy\n",
    "!pip install -q accelerate sentencepiece\n",
    "\n",
    "# Pro pokroƒçil√© TTS\n",
    "!pip install -q TTS 2>/dev/null || echo \"TTS install optional\"\n",
    "\n",
    "# Pro audio vizualizaci\n",
    "!pip install -q matplotlib numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import soundfile as sf\n",
    "import io\n",
    "import json\n",
    "import warnings\n",
    "from typing import Dict, List, Optional, Tuple, Any, Union\n",
    "from dataclasses import dataclass, field\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Audio, display\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Detekce za≈ô√≠zen√≠\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"üñ•Ô∏è Pou≈æ√≠v√°m za≈ô√≠zen√≠: {device}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"   GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"   Pamƒõ≈•: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üó£Ô∏è ƒå√°st 1: Text-to-Speech s SpeechT5\n",
    "\n",
    "SpeechT5 je unified model pro speech-text √∫lohy od Microsoftu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import SpeechT5Processor, SpeechT5ForTextToSpeech, SpeechT5HifiGan\n",
    "from datasets import load_dataset\n",
    "\n",
    "class SpeechT5TTS:\n",
    "    \"\"\"Text-to-Speech engine zalo≈æen√Ω na SpeechT5.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Inicializuje SpeechT5 TTS syst√©m.\n",
    "        \"\"\"\n",
    "        print(\"üì• Naƒç√≠t√°m SpeechT5 modely...\")\n",
    "        \n",
    "        # Processor pro tokenizaci textu\n",
    "        self.processor = SpeechT5Processor.from_pretrained(\"microsoft/speecht5_tts\")\n",
    "        \n",
    "        # TTS model\n",
    "        self.model = SpeechT5ForTextToSpeech.from_pretrained(\"microsoft/speecht5_tts\")\n",
    "        self.model.to(device)\n",
    "        self.model.eval()\n",
    "        \n",
    "        # Vocoder pro generov√°n√≠ waveformu\n",
    "        self.vocoder = SpeechT5HifiGan.from_pretrained(\"microsoft/speecht5_hifigan\")\n",
    "        self.vocoder.to(device)\n",
    "        self.vocoder.eval()\n",
    "        \n",
    "        # Naƒçten√≠ speaker embedding≈Ø\n",
    "        print(\"üì• Naƒç√≠t√°m speaker embeddingy...\")\n",
    "        embeddings_dataset = load_dataset(\n",
    "            \"Matthijs/cmu-arctic-xvectors\", \n",
    "            split=\"validation\"\n",
    "        )\n",
    "        self.speaker_embeddings = torch.tensor(\n",
    "            embeddings_dataset[7306][\"xvector\"]\n",
    "        ).unsqueeze(0).to(device)\n",
    "        \n",
    "        # Sample rate\n",
    "        self.sample_rate = 16000\n",
    "        \n",
    "        print(\"‚úÖ SpeechT5 TTS p≈ôipraven\")\n",
    "    \n",
    "    def synthesize(self, text: str, \n",
    "                   speaker_embedding: Optional[torch.Tensor] = None) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Syntetizuje ≈ôeƒç z textu.\n",
    "        \n",
    "        Args:\n",
    "            text: Text k synt√©ze\n",
    "            speaker_embedding: Voliteln√Ω speaker embedding pro zmƒõnu hlasu\n",
    "        \n",
    "        Returns:\n",
    "            Audio waveform jako numpy array\n",
    "        \"\"\"\n",
    "        # Pou≈æit√≠ v√Ωchoz√≠ho nebo poskytnut√©ho embeddingu\n",
    "        embedding = speaker_embedding if speaker_embedding is not None else self.speaker_embeddings\n",
    "        \n",
    "        # Tokenizace textu\n",
    "        inputs = self.processor(text=text, return_tensors=\"pt\")\n",
    "        inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "        \n",
    "        # Generov√°n√≠ mel spectrogramu\n",
    "        with torch.no_grad():\n",
    "            speech = self.model.generate_speech(\n",
    "                inputs[\"input_ids\"],\n",
    "                embedding,\n",
    "                vocoder=self.vocoder\n",
    "            )\n",
    "        \n",
    "        return speech.cpu().numpy()\n",
    "    \n",
    "    def synthesize_long(self, text: str, \n",
    "                        max_chunk_length: int = 500) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Syntetizuje del≈°√≠ text rozdƒõlen√≠m na chunky.\n",
    "        \n",
    "        Args:\n",
    "            text: Dlouh√Ω text k synt√©ze\n",
    "            max_chunk_length: Maxim√°ln√≠ d√©lka chunku\n",
    "        \n",
    "        Returns:\n",
    "            Spojen√Ω audio waveform\n",
    "        \"\"\"\n",
    "        # Rozdƒõlen√≠ na vƒõty\n",
    "        sentences = self._split_text(text)\n",
    "        \n",
    "        # Spojen√≠ do chunk≈Ø\n",
    "        chunks = []\n",
    "        current_chunk = \"\"\n",
    "        \n",
    "        for sentence in sentences:\n",
    "            if len(current_chunk) + len(sentence) <= max_chunk_length:\n",
    "                current_chunk += sentence + \" \"\n",
    "            else:\n",
    "                if current_chunk:\n",
    "                    chunks.append(current_chunk.strip())\n",
    "                current_chunk = sentence + \" \"\n",
    "        \n",
    "        if current_chunk:\n",
    "            chunks.append(current_chunk.strip())\n",
    "        \n",
    "        # Synt√©za jednotliv√Ωch chunk≈Ø\n",
    "        audio_parts = []\n",
    "        for chunk in chunks:\n",
    "            audio = self.synthesize(chunk)\n",
    "            audio_parts.append(audio)\n",
    "            # Kr√°tk√° pauza mezi chunky\n",
    "            pause = np.zeros(int(self.sample_rate * 0.3))\n",
    "            audio_parts.append(pause)\n",
    "        \n",
    "        return np.concatenate(audio_parts)\n",
    "    \n",
    "    def _split_text(self, text: str) -> List[str]:\n",
    "        \"\"\"Rozdƒõl√≠ text na vƒõty.\"\"\"\n",
    "        import re\n",
    "        sentences = re.split(r'(?<=[.!?])\\s+', text)\n",
    "        return [s.strip() for s in sentences if s.strip()]\n",
    "    \n",
    "    def save_audio(self, audio: np.ndarray, filepath: str):\n",
    "        \"\"\"Ulo≈æ√≠ audio do souboru.\"\"\"\n",
    "        sf.write(filepath, audio, self.sample_rate)\n",
    "        print(f\"üíæ Audio ulo≈æeno: {filepath}\")\n",
    "    \n",
    "    def play_audio(self, audio: np.ndarray):\n",
    "        \"\"\"P≈ôehraje audio v notebooku.\"\"\"\n",
    "        display(Audio(audio, rate=self.sample_rate))\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"SpeechT5TTS Engine\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicializace TTS\n",
    "tts_engine = SpeechT5TTS()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test z√°kladn√≠ synt√©zy\n",
    "test_text = \"Hello, welcome to Praut AI solutions. We specialize in artificial intelligence and automation.\"\n",
    "\n",
    "print(f\"üìù Text: {test_text}\")\n",
    "print(\"üé§ Generuji audio...\")\n",
    "\n",
    "audio = tts_engine.synthesize(test_text)\n",
    "\n",
    "print(f\"‚úÖ Audio vygenerov√°no: {len(audio)} samples ({len(audio)/tts_engine.sample_rate:.2f}s)\")\n",
    "\n",
    "# Vizualizace waveformu\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.plot(audio)\n",
    "plt.title(\"Waveform syntetizovan√©ho audia\")\n",
    "plt.xlabel(\"Samples\")\n",
    "plt.ylabel(\"Amplitude\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# P≈ôehr√°n√≠\n",
    "tts_engine.play_audio(audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test del≈°√≠ho textu\n",
    "long_text = \"\"\"\n",
    "Artificial intelligence is transforming how businesses operate. \n",
    "At Praut, we help companies integrate AI into their workflows.\n",
    "Our solutions include automated document processing, intelligent chatbots, and predictive analytics.\n",
    "Contact us today to learn how AI can benefit your organization.\n",
    "\"\"\"\n",
    "\n",
    "print(\"üìù Dlouh√Ω text:\")\n",
    "print(long_text[:100] + \"...\")\n",
    "print(\"\\nüé§ Generuji audio pro dlouh√Ω text...\")\n",
    "\n",
    "long_audio = tts_engine.synthesize_long(long_text)\n",
    "\n",
    "print(f\"‚úÖ Audio vygenerov√°no: {len(long_audio)/tts_engine.sample_rate:.2f}s\")\n",
    "tts_engine.play_audio(long_audio)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üé≠ ƒå√°st 2: BARK - Pokroƒçil√Ω TTS s Emocemi\n",
    "\n",
    "BARK je generativn√≠ audio model od Suno AI, kter√Ω podporuje emoce, sm√≠ch, a neverb√°ln√≠ zvuky."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoProcessor, BarkModel\n",
    "\n",
    "class BarkTTS:\n",
    "    \"\"\"Pokroƒçil√Ω TTS s podporou emoc√≠ pomoc√≠ BARK modelu.\"\"\"\n",
    "    \n",
    "    # Dostupn√© voice presety\n",
    "    VOICE_PRESETS = {\n",
    "        'male_1': 'v2/en_speaker_6',\n",
    "        'male_2': 'v2/en_speaker_9',\n",
    "        'female_1': 'v2/en_speaker_1',\n",
    "        'female_2': 'v2/en_speaker_3',\n",
    "        'narrator': 'v2/en_speaker_0',\n",
    "    }\n",
    "    \n",
    "    # Speci√°ln√≠ tagy pro emoce\n",
    "    EMOTION_TAGS = {\n",
    "        'laugh': '[laughter]',\n",
    "        'sigh': '[sighs]',\n",
    "        'gasp': '[gasps]',\n",
    "        'clear_throat': '[clears throat]',\n",
    "        'pause': '...',\n",
    "        'music': '‚ô™',\n",
    "    }\n",
    "    \n",
    "    def __init__(self, model_name: str = \"suno/bark-small\"):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            model_name: N√°zev modelu (bark-small nebo bark)\n",
    "        \"\"\"\n",
    "        print(f\"üì• Naƒç√≠t√°m BARK model: {model_name}\")\n",
    "        \n",
    "        self.processor = AutoProcessor.from_pretrained(model_name)\n",
    "        self.model = BarkModel.from_pretrained(\n",
    "            model_name,\n",
    "            torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32\n",
    "        )\n",
    "        self.model.to(device)\n",
    "        self.model.eval()\n",
    "        \n",
    "        self.sample_rate = 24000  # BARK pou≈æ√≠v√° 24kHz\n",
    "        \n",
    "        print(\"‚úÖ BARK model naƒçten\")\n",
    "    \n",
    "    def synthesize(self, text: str, \n",
    "                   voice_preset: str = 'narrator',\n",
    "                   add_silence: bool = True) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Syntetizuje ≈ôeƒç s mo≈ænost√≠ emoc√≠.\n",
    "        \n",
    "        Args:\n",
    "            text: Text k synt√©ze (m≈Ø≈æe obsahovat emotion tagy)\n",
    "            voice_preset: Preset hlasu\n",
    "            add_silence: P≈ôidat ticho na konec\n",
    "        \n",
    "        Returns:\n",
    "            Audio waveform\n",
    "        \"\"\"\n",
    "        # Z√≠sk√°n√≠ voice presetu\n",
    "        preset = self.VOICE_PRESETS.get(voice_preset, voice_preset)\n",
    "        \n",
    "        # P≈ô√≠prava vstup≈Ø\n",
    "        inputs = self.processor(text, voice_preset=preset)\n",
    "        inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "        \n",
    "        # Generov√°n√≠\n",
    "        with torch.no_grad():\n",
    "            audio_array = self.model.generate(**inputs)\n",
    "        \n",
    "        audio = audio_array.cpu().numpy().squeeze()\n",
    "        \n",
    "        # P≈ôid√°n√≠ ticha na konec\n",
    "        if add_silence:\n",
    "            silence = np.zeros(int(self.sample_rate * 0.25))\n",
    "            audio = np.concatenate([audio, silence])\n",
    "        \n",
    "        return audio\n",
    "    \n",
    "    def synthesize_with_emotion(self, text: str, \n",
    "                                emotion: str,\n",
    "                                voice_preset: str = 'narrator') -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Syntetizuje text s p≈ôidanou emoc√≠.\n",
    "        \n",
    "        Args:\n",
    "            text: Text k synt√©ze\n",
    "            emotion: Typ emoce (laugh, sigh, gasp, etc.)\n",
    "            voice_preset: Preset hlasu\n",
    "        \n",
    "        Returns:\n",
    "            Audio waveform\n",
    "        \"\"\"\n",
    "        emotion_tag = self.EMOTION_TAGS.get(emotion, '')\n",
    "        \n",
    "        # P≈ôid√°n√≠ emotion tagu\n",
    "        if emotion_tag:\n",
    "            enhanced_text = f\"{text} {emotion_tag}\"\n",
    "        else:\n",
    "            enhanced_text = text\n",
    "        \n",
    "        return self.synthesize(enhanced_text, voice_preset)\n",
    "    \n",
    "    def synthesize_dialogue(self, dialogue: List[Dict[str, str]]) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Syntetizuje dialog mezi v√≠ce mluvƒç√≠mi.\n",
    "        \n",
    "        Args:\n",
    "            dialogue: Seznam replik [{\"speaker\": \"male_1\", \"text\": \"...\"}]\n",
    "        \n",
    "        Returns:\n",
    "            Spojen√Ω audio waveform\n",
    "        \"\"\"\n",
    "        audio_parts = []\n",
    "        \n",
    "        for turn in dialogue:\n",
    "            speaker = turn.get('speaker', 'narrator')\n",
    "            text = turn.get('text', '')\n",
    "            emotion = turn.get('emotion', None)\n",
    "            \n",
    "            if emotion:\n",
    "                audio = self.synthesize_with_emotion(text, emotion, speaker)\n",
    "            else:\n",
    "                audio = self.synthesize(text, speaker)\n",
    "            \n",
    "            audio_parts.append(audio)\n",
    "            \n",
    "            # Pauza mezi replikami\n",
    "            pause = np.zeros(int(self.sample_rate * 0.5))\n",
    "            audio_parts.append(pause)\n",
    "        \n",
    "        return np.concatenate(audio_parts)\n",
    "    \n",
    "    def play_audio(self, audio: np.ndarray):\n",
    "        \"\"\"P≈ôehraje audio.\"\"\"\n",
    "        display(Audio(audio, rate=self.sample_rate))\n",
    "    \n",
    "    def list_voices(self):\n",
    "        \"\"\"Vyp√≠≈°e dostupn√© hlasy.\"\"\"\n",
    "        print(\"üé≠ Dostupn√© hlasov√© presety:\")\n",
    "        for name, preset in self.VOICE_PRESETS.items():\n",
    "            print(f\"   {name}: {preset}\")\n",
    "        print(\"\\nüé≠ Dostupn√© emotion tagy:\")\n",
    "        for name, tag in self.EMOTION_TAGS.items():\n",
    "            print(f\"   {name}: {tag}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"BARK TTS Engine\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicializace BARK\n",
    "bark_tts = BarkTTS(\"suno/bark-small\")\n",
    "bark_tts.list_voices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test BARK s emocemi\n",
    "print(\"\\nüé≠ Test BARK s r≈Øzn√Ωmi hlasy a emocemi:\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# Z√°kladn√≠ synt√©za\n",
    "text = \"Welcome to Praut AI. We make artificial intelligence accessible for everyone.\"\n",
    "print(f\"üìù Text: {text}\")\n",
    "\n",
    "audio = bark_tts.synthesize(text, voice_preset='narrator')\n",
    "print(f\"‚úÖ Audio vygenerov√°no ({len(audio)/bark_tts.sample_rate:.2f}s)\")\n",
    "bark_tts.play_audio(audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test dialogu\n",
    "dialogue = [\n",
    "    {\"speaker\": \"female_1\", \"text\": \"Have you tried the new AI automation system?\"},\n",
    "    {\"speaker\": \"male_1\", \"text\": \"Yes! It saved us so much time.\", \"emotion\": \"laugh\"},\n",
    "    {\"speaker\": \"female_1\", \"text\": \"That's amazing. I should implement it too.\"},\n",
    "]\n",
    "\n",
    "print(\"\\nüé≠ Generuji dialog:\")\n",
    "for turn in dialogue:\n",
    "    print(f\"   [{turn['speaker']}]: {turn['text']}\")\n",
    "\n",
    "dialogue_audio = bark_tts.synthesize_dialogue(dialogue)\n",
    "print(f\"\\n‚úÖ Dialog vygenerov√°n ({len(dialogue_audio)/bark_tts.sample_rate:.2f}s)\")\n",
    "bark_tts.play_audio(dialogue_audio)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üéº ƒå√°st 3: Audio Processing a Anal√Ωza\n",
    "\n",
    "N√°stroje pro zpracov√°n√≠, anal√Ωzu a transformaci audio dat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import librosa.display\n",
    "from scipy import signal\n",
    "from scipy.io import wavfile\n",
    "\n",
    "class AudioProcessor:\n",
    "    \"\"\"Komplexn√≠ n√°stroj pro zpracov√°n√≠ audia.\"\"\"\n",
    "    \n",
    "    def __init__(self, sample_rate: int = 16000):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            sample_rate: V√Ωchoz√≠ sample rate\n",
    "        \"\"\"\n",
    "        self.sample_rate = sample_rate\n",
    "    \n",
    "    def load_audio(self, filepath: str, \n",
    "                   target_sr: Optional[int] = None) -> Tuple[np.ndarray, int]:\n",
    "        \"\"\"\n",
    "        Naƒçte audio soubor.\n",
    "        \n",
    "        Args:\n",
    "            filepath: Cesta k souboru\n",
    "            target_sr: C√≠lov√Ω sample rate (None = ponechat origin√°l)\n",
    "        \n",
    "        Returns:\n",
    "            Tuple (audio_data, sample_rate)\n",
    "        \"\"\"\n",
    "        audio, sr = librosa.load(filepath, sr=target_sr)\n",
    "        return audio, sr\n",
    "    \n",
    "    def save_audio(self, audio: np.ndarray, filepath: str, \n",
    "                   sample_rate: Optional[int] = None):\n",
    "        \"\"\"Ulo≈æ√≠ audio do souboru.\"\"\"\n",
    "        sr = sample_rate or self.sample_rate\n",
    "        sf.write(filepath, audio, sr)\n",
    "    \n",
    "    def resample(self, audio: np.ndarray, \n",
    "                 orig_sr: int, target_sr: int) -> np.ndarray:\n",
    "        \"\"\"P≈ôevzorkuje audio na jin√Ω sample rate.\"\"\"\n",
    "        return librosa.resample(audio, orig_sr=orig_sr, target_sr=target_sr)\n",
    "    \n",
    "    def normalize(self, audio: np.ndarray, \n",
    "                  target_db: float = -20.0) -> np.ndarray:\n",
    "        \"\"\"Normalizuje hlasitost audia.\"\"\"\n",
    "        # V√Ωpoƒçet aktu√°ln√≠ RMS\n",
    "        rms = np.sqrt(np.mean(audio**2))\n",
    "        if rms == 0:\n",
    "            return audio\n",
    "        \n",
    "        # C√≠lov√° RMS\n",
    "        target_rms = 10 ** (target_db / 20)\n",
    "        \n",
    "        # ≈†k√°lov√°n√≠\n",
    "        return audio * (target_rms / rms)\n",
    "    \n",
    "    def trim_silence(self, audio: np.ndarray, \n",
    "                     top_db: int = 20) -> np.ndarray:\n",
    "        \"\"\"O≈ô√≠zne ticho ze zaƒç√°tku a konce.\"\"\"\n",
    "        trimmed, _ = librosa.effects.trim(audio, top_db=top_db)\n",
    "        return trimmed\n",
    "    \n",
    "    def apply_noise_reduction(self, audio: np.ndarray, \n",
    "                               noise_factor: float = 0.1) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Jednoduch√° redukce ≈°umu pomoc√≠ spektr√°ln√≠ho gatingu.\n",
    "        \n",
    "        Args:\n",
    "            audio: Vstupn√≠ audio\n",
    "            noise_factor: Faktor pro pr√°h ≈°umu (0-1)\n",
    "        \n",
    "        Returns:\n",
    "            Audio s redukovan√Ωm ≈°umem\n",
    "        \"\"\"\n",
    "        # STFT\n",
    "        stft = librosa.stft(audio)\n",
    "        magnitude = np.abs(stft)\n",
    "        phase = np.angle(stft)\n",
    "        \n",
    "        # Odhad ≈°umov√©ho prahu\n",
    "        noise_threshold = np.mean(magnitude) * noise_factor\n",
    "        \n",
    "        # Spektr√°ln√≠ gating\n",
    "        magnitude_cleaned = np.where(\n",
    "            magnitude > noise_threshold, \n",
    "            magnitude, \n",
    "            magnitude * 0.1\n",
    "        )\n",
    "        \n",
    "        # Rekonstrukce\n",
    "        stft_cleaned = magnitude_cleaned * np.exp(1j * phase)\n",
    "        audio_cleaned = librosa.istft(stft_cleaned)\n",
    "        \n",
    "        return audio_cleaned\n",
    "    \n",
    "    def change_speed(self, audio: np.ndarray, \n",
    "                     speed_factor: float) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Zmƒõn√≠ rychlost audia bez zmƒõny v√Ω≈°ky.\n",
    "        \n",
    "        Args:\n",
    "            audio: Vstupn√≠ audio\n",
    "            speed_factor: Faktor rychlosti (>1 = rychlej≈°√≠, <1 = pomalej≈°√≠)\n",
    "        \n",
    "        Returns:\n",
    "            Audio s upravenou rychlost√≠\n",
    "        \"\"\"\n",
    "        return librosa.effects.time_stretch(audio, rate=speed_factor)\n",
    "    \n",
    "    def change_pitch(self, audio: np.ndarray, \n",
    "                     semitones: float,\n",
    "                     sample_rate: Optional[int] = None) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Zmƒõn√≠ v√Ω≈°ku t√≥nu audia.\n",
    "        \n",
    "        Args:\n",
    "            audio: Vstupn√≠ audio\n",
    "            semitones: Poƒçet p≈Ølt√≥n≈Ø (+/- pro zv√Ω≈°en√≠/sn√≠≈æen√≠)\n",
    "            sample_rate: Sample rate audia\n",
    "        \n",
    "        Returns:\n",
    "            Audio s upravenou v√Ω≈°kou\n",
    "        \"\"\"\n",
    "        sr = sample_rate or self.sample_rate\n",
    "        return librosa.effects.pitch_shift(audio, sr=sr, n_steps=semitones)\n",
    "    \n",
    "    def extract_features(self, audio: np.ndarray,\n",
    "                         sample_rate: Optional[int] = None) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Extrahuje audio features.\n",
    "        \n",
    "        Returns:\n",
    "            Dict s r≈Øzn√Ωmi audio features\n",
    "        \"\"\"\n",
    "        sr = sample_rate or self.sample_rate\n",
    "        \n",
    "        features = {}\n",
    "        \n",
    "        # Z√°kladn√≠ statistiky\n",
    "        features['duration'] = len(audio) / sr\n",
    "        features['rms'] = float(np.sqrt(np.mean(audio**2)))\n",
    "        features['zero_crossing_rate'] = float(np.mean(librosa.feature.zero_crossing_rate(audio)))\n",
    "        \n",
    "        # Spektr√°ln√≠ features\n",
    "        spectral_centroids = librosa.feature.spectral_centroid(y=audio, sr=sr)[0]\n",
    "        features['spectral_centroid_mean'] = float(np.mean(spectral_centroids))\n",
    "        features['spectral_centroid_std'] = float(np.std(spectral_centroids))\n",
    "        \n",
    "        # Spectral bandwidth\n",
    "        spectral_bandwidth = librosa.feature.spectral_bandwidth(y=audio, sr=sr)[0]\n",
    "        features['spectral_bandwidth_mean'] = float(np.mean(spectral_bandwidth))\n",
    "        \n",
    "        # MFCCs\n",
    "        mfccs = librosa.feature.mfcc(y=audio, sr=sr, n_mfcc=13)\n",
    "        features['mfcc_means'] = [float(np.mean(mfcc)) for mfcc in mfccs]\n",
    "        \n",
    "        # Chroma features\n",
    "        chroma = librosa.feature.chroma_stft(y=audio, sr=sr)\n",
    "        features['chroma_mean'] = float(np.mean(chroma))\n",
    "        \n",
    "        # Tempo\n",
    "        try:\n",
    "            tempo, _ = librosa.beat.beat_track(y=audio, sr=sr)\n",
    "            features['tempo'] = float(tempo)\n",
    "        except:\n",
    "            features['tempo'] = None\n",
    "        \n",
    "        return features\n",
    "    \n",
    "    def visualize(self, audio: np.ndarray, \n",
    "                  sample_rate: Optional[int] = None,\n",
    "                  title: str = \"Audio Analysis\"):\n",
    "        \"\"\"\n",
    "        Vizualizuje audio (waveform, spectrogram, mel spectrogram).\n",
    "        \"\"\"\n",
    "        sr = sample_rate or self.sample_rate\n",
    "        \n",
    "        fig, axes = plt.subplots(3, 1, figsize=(14, 10))\n",
    "        \n",
    "        # Waveform\n",
    "        librosa.display.waveshow(audio, sr=sr, ax=axes[0])\n",
    "        axes[0].set_title(f\"{title} - Waveform\")\n",
    "        axes[0].set_xlabel(\"Time (s)\")\n",
    "        axes[0].set_ylabel(\"Amplitude\")\n",
    "        \n",
    "        # Spectrogram\n",
    "        D = librosa.amplitude_to_db(np.abs(librosa.stft(audio)), ref=np.max)\n",
    "        librosa.display.specshow(D, sr=sr, x_axis='time', y_axis='hz', ax=axes[1])\n",
    "        axes[1].set_title(f\"{title} - Spectrogram\")\n",
    "        axes[1].set_xlabel(\"Time (s)\")\n",
    "        axes[1].set_ylabel(\"Frequency (Hz)\")\n",
    "        \n",
    "        # Mel Spectrogram\n",
    "        mel_spec = librosa.feature.melspectrogram(y=audio, sr=sr)\n",
    "        mel_spec_db = librosa.power_to_db(mel_spec, ref=np.max)\n",
    "        librosa.display.specshow(mel_spec_db, sr=sr, x_axis='time', y_axis='mel', ax=axes[2])\n",
    "        axes[2].set_title(f\"{title} - Mel Spectrogram\")\n",
    "        axes[2].set_xlabel(\"Time (s)\")\n",
    "        axes[2].set_ylabel(\"Mel Frequency\")\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "# Inicializace\n",
    "audio_processor = AudioProcessor(sample_rate=16000)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"AudioProcessor p≈ôipraven\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pou≈æit√≠ audio processoru na syntetizovan√© audio\n",
    "print(\"\\nüîä Anal√Ωza syntetizovan√©ho audia:\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# Pou≈æijeme audio z TTS\n",
    "test_audio = tts_engine.synthesize(\"Hello, this is a test of audio processing capabilities.\")\n",
    "\n",
    "# Extrakce features\n",
    "features = audio_processor.extract_features(test_audio, tts_engine.sample_rate)\n",
    "\n",
    "print(\"\\nüìä Audio Features:\")\n",
    "print(f\"   D√©lka: {features['duration']:.2f}s\")\n",
    "print(f\"   RMS: {features['rms']:.4f}\")\n",
    "print(f\"   Zero Crossing Rate: {features['zero_crossing_rate']:.4f}\")\n",
    "print(f\"   Spectral Centroid: {features['spectral_centroid_mean']:.1f} Hz\")\n",
    "print(f\"   Spectral Bandwidth: {features['spectral_bandwidth_mean']:.1f} Hz\")\n",
    "if features['tempo']:\n",
    "    print(f\"   Tempo: {features['tempo']:.1f} BPM\")\n",
    "\n",
    "# Vizualizace\n",
    "audio_processor.visualize(test_audio, tts_engine.sample_rate, \"TTS Audio\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrace audio transformac√≠\n",
    "print(\"\\nüîÑ Demonstrace audio transformac√≠:\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# P≈Øvodn√≠ audio\n",
    "original_audio = test_audio.copy()\n",
    "sr = tts_engine.sample_rate\n",
    "\n",
    "# 1. Zmƒõna rychlosti\n",
    "faster_audio = audio_processor.change_speed(original_audio, speed_factor=1.5)\n",
    "slower_audio = audio_processor.change_speed(original_audio, speed_factor=0.75)\n",
    "\n",
    "print(f\"\\n‚ñ∂Ô∏è Rychlej≈°√≠ verze (1.5x): {len(faster_audio)/sr:.2f}s\")\n",
    "display(Audio(faster_audio, rate=sr))\n",
    "\n",
    "print(f\"\\n‚è∏Ô∏è Pomalej≈°√≠ verze (0.75x): {len(slower_audio)/sr:.2f}s\")\n",
    "display(Audio(slower_audio, rate=sr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Zmƒõna v√Ω≈°ky\n",
    "higher_pitch = audio_processor.change_pitch(original_audio, semitones=4, sample_rate=sr)\n",
    "lower_pitch = audio_processor.change_pitch(original_audio, semitones=-4, sample_rate=sr)\n",
    "\n",
    "print(f\"\\nüîº Vy≈°≈°√≠ hlas (+4 p≈Ølt√≥ny):\")\n",
    "display(Audio(higher_pitch, rate=sr))\n",
    "\n",
    "print(f\"\\nüîΩ Ni≈æ≈°√≠ hlas (-4 p≈Ølt√≥ny):\")\n",
    "display(Audio(lower_pitch, rate=sr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üéµ ƒå√°st 4: MusicGen - Generov√°n√≠ Hudby\n",
    "\n",
    "MusicGen od Meta AI generuje hudbu z textov√Ωch popis≈Ø."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoProcessor, MusicgenForConditionalGeneration\n",
    "\n",
    "class MusicGenerator:\n",
    "    \"\"\"Gener√°tor hudby pomoc√≠ MusicGen modelu.\"\"\"\n",
    "    \n",
    "    def __init__(self, model_name: str = \"facebook/musicgen-small\"):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            model_name: N√°zev modelu (small/medium/large)\n",
    "        \"\"\"\n",
    "        print(f\"üì• Naƒç√≠t√°m MusicGen model: {model_name}\")\n",
    "        \n",
    "        self.processor = AutoProcessor.from_pretrained(model_name)\n",
    "        self.model = MusicgenForConditionalGeneration.from_pretrained(model_name)\n",
    "        self.model.to(device)\n",
    "        self.model.eval()\n",
    "        \n",
    "        self.sample_rate = self.model.config.audio_encoder.sampling_rate\n",
    "        \n",
    "        print(f\"‚úÖ MusicGen naƒçten (sample rate: {self.sample_rate} Hz)\")\n",
    "    \n",
    "    def generate(self, prompt: str, \n",
    "                 duration_seconds: float = 8.0,\n",
    "                 guidance_scale: float = 3.0) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Generuje hudbu z textov√©ho popisu.\n",
    "        \n",
    "        Args:\n",
    "            prompt: Textov√Ω popis po≈æadovan√© hudby\n",
    "            duration_seconds: D√©lka v sekund√°ch\n",
    "            guidance_scale: S√≠la veden√≠ textem\n",
    "        \n",
    "        Returns:\n",
    "            Audio waveform\n",
    "        \"\"\"\n",
    "        # P≈ô√≠prava vstup≈Ø\n",
    "        inputs = self.processor(\n",
    "            text=[prompt],\n",
    "            padding=True,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "        inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "        \n",
    "        # V√Ωpoƒçet max_new_tokens pro po≈æadovanou d√©lku\n",
    "        # MusicGen generuje ~50 token≈Ø za sekundu\n",
    "        max_new_tokens = int(duration_seconds * 50)\n",
    "        \n",
    "        # Generov√°n√≠\n",
    "        with torch.no_grad():\n",
    "            audio_values = self.model.generate(\n",
    "                **inputs,\n",
    "                max_new_tokens=max_new_tokens,\n",
    "                guidance_scale=guidance_scale,\n",
    "                do_sample=True\n",
    "            )\n",
    "        \n",
    "        # Konverze na numpy\n",
    "        audio = audio_values[0, 0].cpu().numpy()\n",
    "        \n",
    "        return audio\n",
    "    \n",
    "    def generate_variations(self, prompt: str, \n",
    "                            num_variations: int = 3,\n",
    "                            duration_seconds: float = 5.0) -> List[np.ndarray]:\n",
    "        \"\"\"\n",
    "        Generuje v√≠ce variac√≠ hudby ze stejn√©ho promptu.\n",
    "        \n",
    "        Args:\n",
    "            prompt: Textov√Ω popis\n",
    "            num_variations: Poƒçet variac√≠\n",
    "            duration_seconds: D√©lka ka≈æd√© variace\n",
    "        \n",
    "        Returns:\n",
    "            Seznam audio waveform≈Ø\n",
    "        \"\"\"\n",
    "        variations = []\n",
    "        \n",
    "        for i in range(num_variations):\n",
    "            print(f\"   Generuji variaci {i+1}/{num_variations}...\")\n",
    "            audio = self.generate(prompt, duration_seconds)\n",
    "            variations.append(audio)\n",
    "        \n",
    "        return variations\n",
    "    \n",
    "    def concatenate_sections(self, sections: List[Tuple[str, float]],\n",
    "                             crossfade_duration: float = 0.5) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Generuje a spojuje v√≠ce sekc√≠ hudby.\n",
    "        \n",
    "        Args:\n",
    "            sections: Seznam (prompt, duration) pro ka≈ædou sekci\n",
    "            crossfade_duration: D√©lka crossfade mezi sekcemi\n",
    "        \n",
    "        Returns:\n",
    "            Spojen√© audio\n",
    "        \"\"\"\n",
    "        audio_sections = []\n",
    "        \n",
    "        for i, (prompt, duration) in enumerate(sections):\n",
    "            print(f\"   Generuji sekci {i+1}: '{prompt[:30]}...'\")\n",
    "            audio = self.generate(prompt, duration)\n",
    "            audio_sections.append(audio)\n",
    "        \n",
    "        # Spojen√≠ s crossfade\n",
    "        if len(audio_sections) == 1:\n",
    "            return audio_sections[0]\n",
    "        \n",
    "        crossfade_samples = int(crossfade_duration * self.sample_rate)\n",
    "        result = audio_sections[0]\n",
    "        \n",
    "        for section in audio_sections[1:]:\n",
    "            # Crossfade\n",
    "            fade_out = np.linspace(1, 0, crossfade_samples)\n",
    "            fade_in = np.linspace(0, 1, crossfade_samples)\n",
    "            \n",
    "            # Aplikace fade\n",
    "            result[-crossfade_samples:] *= fade_out\n",
    "            section[:crossfade_samples] *= fade_in\n",
    "            \n",
    "            # Spojen√≠ s p≈ôekryvem\n",
    "            result[-crossfade_samples:] += section[:crossfade_samples]\n",
    "            result = np.concatenate([result, section[crossfade_samples:]])\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    def play_audio(self, audio: np.ndarray):\n",
    "        \"\"\"P≈ôehraje audio.\"\"\"\n",
    "        display(Audio(audio, rate=self.sample_rate))\n",
    "    \n",
    "    def save_audio(self, audio: np.ndarray, filepath: str):\n",
    "        \"\"\"Ulo≈æ√≠ audio do souboru.\"\"\"\n",
    "        sf.write(filepath, audio, self.sample_rate)\n",
    "        print(f\"üíæ Audio ulo≈æeno: {filepath}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"MusicGenerator Engine\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicializace MusicGen\n",
    "music_gen = MusicGenerator(\"facebook/musicgen-small\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generov√°n√≠ hudby z textov√©ho popisu\n",
    "print(\"\\nüéµ Generov√°n√≠ hudby z textov√©ho popisu:\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "prompts = [\n",
    "    \"Upbeat corporate background music with positive energy\",\n",
    "    \"Calm ambient electronic music for focus and productivity\",\n",
    "    \"Energetic rock guitar riff with drums\",\n",
    "]\n",
    "\n",
    "for prompt in prompts:\n",
    "    print(f\"\\nüéº Prompt: '{prompt}'\")\n",
    "    print(\"   Generuji...\")\n",
    "    \n",
    "    audio = music_gen.generate(prompt, duration_seconds=5.0)\n",
    "    \n",
    "    print(f\"   ‚úÖ Vygenerov√°no: {len(audio)/music_gen.sample_rate:.2f}s\")\n",
    "    music_gen.play_audio(audio)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üè≠ ƒå√°st 5: Produkƒçn√≠ Audio Pipeline\n",
    "\n",
    "Kompletn√≠ pipeline pro produkƒçn√≠ audio aplikace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from enum import Enum\n",
    "from datetime import datetime\n",
    "import hashlib\n",
    "\n",
    "class AudioTaskType(Enum):\n",
    "    TTS = \"text_to_speech\"\n",
    "    MUSIC = \"music_generation\"\n",
    "    PROCESSING = \"audio_processing\"\n",
    "    ANALYSIS = \"audio_analysis\"\n",
    "\n",
    "@dataclass\n",
    "class AudioJob:\n",
    "    \"\"\"Reprezentace audio √∫lohy.\"\"\"\n",
    "    job_id: str\n",
    "    task_type: AudioTaskType\n",
    "    input_data: Dict[str, Any]\n",
    "    output_audio: Optional[np.ndarray] = None\n",
    "    output_path: Optional[str] = None\n",
    "    metadata: Dict[str, Any] = field(default_factory=dict)\n",
    "    status: str = \"pending\"\n",
    "    error: Optional[str] = None\n",
    "    created_at: datetime = field(default_factory=datetime.now)\n",
    "    completed_at: Optional[datetime] = None\n",
    "    processing_time: float = 0.0\n",
    "\n",
    "class ProductionAudioPipeline:\n",
    "    \"\"\"\n",
    "    Produkƒçn√≠ pipeline pro komplexn√≠ audio zpracov√°n√≠.\n",
    "    \n",
    "    Kombinuje TTS, hudebn√≠ generov√°n√≠ a audio processing\n",
    "    do jednoho unifikovan√©ho rozhran√≠.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self,\n",
    "                 enable_tts: bool = True,\n",
    "                 enable_music: bool = True,\n",
    "                 cache_size: int = 50):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            enable_tts: Povolit TTS komponenty\n",
    "            enable_music: Povolit generov√°n√≠ hudby\n",
    "            cache_size: Velikost cache\n",
    "        \"\"\"\n",
    "        print(\"üè≠ Inicializace Production Audio Pipeline...\")\n",
    "        \n",
    "        self.components = {}\n",
    "        \n",
    "        # TTS komponenty\n",
    "        if enable_tts:\n",
    "            print(\"   üì¢ Inicializace TTS...\")\n",
    "            self.components['tts_speecht5'] = SpeechT5TTS()\n",
    "            # BARK je voliteln√Ω kv≈Øli velikosti\n",
    "            try:\n",
    "                self.components['tts_bark'] = BarkTTS(\"suno/bark-small\")\n",
    "            except Exception as e:\n",
    "                print(f\"   ‚ö†Ô∏è BARK nedostupn√Ω: {e}\")\n",
    "        \n",
    "        # Music generov√°n√≠\n",
    "        if enable_music:\n",
    "            print(\"   üéµ Inicializace MusicGen...\")\n",
    "            try:\n",
    "                self.components['music'] = MusicGenerator(\"facebook/musicgen-small\")\n",
    "            except Exception as e:\n",
    "                print(f\"   ‚ö†Ô∏è MusicGen nedostupn√Ω: {e}\")\n",
    "        \n",
    "        # Audio processor je v≈ædy dostupn√Ω\n",
    "        self.components['processor'] = AudioProcessor()\n",
    "        \n",
    "        # Cache a statistiky\n",
    "        self.cache = {}\n",
    "        self.cache_size = cache_size\n",
    "        self.jobs_history = []\n",
    "        self.stats = {\n",
    "            'total_jobs': 0,\n",
    "            'successful_jobs': 0,\n",
    "            'failed_jobs': 0,\n",
    "            'total_audio_generated_seconds': 0,\n",
    "            'cache_hits': 0,\n",
    "            'by_type': defaultdict(int)\n",
    "        }\n",
    "        \n",
    "        print(\"\\n‚úÖ Pipeline inicializov√°n\")\n",
    "        print(f\"   Komponenty: {list(self.components.keys())}\")\n",
    "    \n",
    "    def text_to_speech(self, text: str,\n",
    "                       engine: str = \"speecht5\",\n",
    "                       voice: str = \"default\",\n",
    "                       **kwargs) -> AudioJob:\n",
    "        \"\"\"\n",
    "        P≈ôevede text na ≈ôeƒç.\n",
    "        \n",
    "        Args:\n",
    "            text: Text k synt√©ze\n",
    "            engine: TTS engine (speecht5/bark)\n",
    "            voice: Hlas pro synt√©zu\n",
    "            **kwargs: Dal≈°√≠ parametry pro engine\n",
    "        \n",
    "        Returns:\n",
    "            AudioJob s v√Ωsledkem\n",
    "        \"\"\"\n",
    "        job = self._create_job(AudioTaskType.TTS, {\n",
    "            'text': text,\n",
    "            'engine': engine,\n",
    "            'voice': voice,\n",
    "            **kwargs\n",
    "        })\n",
    "        \n",
    "        try:\n",
    "            start_time = time.time()\n",
    "            \n",
    "            # V√Ωbƒõr engine\n",
    "            if engine == \"bark\" and 'tts_bark' in self.components:\n",
    "                tts = self.components['tts_bark']\n",
    "                audio = tts.synthesize(text, voice_preset=voice)\n",
    "                sample_rate = tts.sample_rate\n",
    "            else:\n",
    "                tts = self.components.get('tts_speecht5')\n",
    "                if tts is None:\n",
    "                    raise RuntimeError(\"TTS komponenta nen√≠ dostupn√°\")\n",
    "                audio = tts.synthesize_long(text) if len(text) > 200 else tts.synthesize(text)\n",
    "                sample_rate = tts.sample_rate\n",
    "            \n",
    "            job.output_audio = audio\n",
    "            job.metadata['sample_rate'] = sample_rate\n",
    "            job.metadata['duration'] = len(audio) / sample_rate\n",
    "            job.status = \"completed\"\n",
    "            job.processing_time = time.time() - start_time\n",
    "            job.completed_at = datetime.now()\n",
    "            \n",
    "            self._update_stats(job, success=True)\n",
    "            \n",
    "        except Exception as e:\n",
    "            job.status = \"failed\"\n",
    "            job.error = str(e)\n",
    "            self._update_stats(job, success=False)\n",
    "        \n",
    "        self.jobs_history.append(job)\n",
    "        return job\n",
    "    \n",
    "    def generate_music(self, prompt: str,\n",
    "                       duration: float = 8.0,\n",
    "                       **kwargs) -> AudioJob:\n",
    "        \"\"\"\n",
    "        Generuje hudbu z textov√©ho popisu.\n",
    "        \n",
    "        Args:\n",
    "            prompt: Textov√Ω popis hudby\n",
    "            duration: D√©lka v sekund√°ch\n",
    "            **kwargs: Dal≈°√≠ parametry\n",
    "        \n",
    "        Returns:\n",
    "            AudioJob s v√Ωsledkem\n",
    "        \"\"\"\n",
    "        job = self._create_job(AudioTaskType.MUSIC, {\n",
    "            'prompt': prompt,\n",
    "            'duration': duration,\n",
    "            **kwargs\n",
    "        })\n",
    "        \n",
    "        try:\n",
    "            if 'music' not in self.components:\n",
    "                raise RuntimeError(\"MusicGen komponenta nen√≠ dostupn√°\")\n",
    "            \n",
    "            start_time = time.time()\n",
    "            \n",
    "            music_gen = self.components['music']\n",
    "            audio = music_gen.generate(prompt, duration)\n",
    "            \n",
    "            job.output_audio = audio\n",
    "            job.metadata['sample_rate'] = music_gen.sample_rate\n",
    "            job.metadata['duration'] = len(audio) / music_gen.sample_rate\n",
    "            job.status = \"completed\"\n",
    "            job.processing_time = time.time() - start_time\n",
    "            job.completed_at = datetime.now()\n",
    "            \n",
    "            self._update_stats(job, success=True)\n",
    "            \n",
    "        except Exception as e:\n",
    "            job.status = \"failed\"\n",
    "            job.error = str(e)\n",
    "            self._update_stats(job, success=False)\n",
    "        \n",
    "        self.jobs_history.append(job)\n",
    "        return job\n",
    "    \n",
    "    def process_audio(self, audio: np.ndarray,\n",
    "                      sample_rate: int,\n",
    "                      operations: List[Dict[str, Any]]) -> AudioJob:\n",
    "        \"\"\"\n",
    "        Aplikuje ≈ôetƒõzec operac√≠ na audio.\n",
    "        \n",
    "        Args:\n",
    "            audio: Vstupn√≠ audio\n",
    "            sample_rate: Sample rate\n",
    "            operations: Seznam operac√≠ [{\"type\": \"normalize\", \"params\": {...}}]\n",
    "        \n",
    "        Returns:\n",
    "            AudioJob s v√Ωsledkem\n",
    "        \"\"\"\n",
    "        job = self._create_job(AudioTaskType.PROCESSING, {\n",
    "            'audio_length': len(audio),\n",
    "            'sample_rate': sample_rate,\n",
    "            'operations': operations\n",
    "        })\n",
    "        \n",
    "        try:\n",
    "            start_time = time.time()\n",
    "            processor = self.components['processor']\n",
    "            \n",
    "            processed_audio = audio.copy()\n",
    "            applied_operations = []\n",
    "            \n",
    "            for op in operations:\n",
    "                op_type = op.get('type')\n",
    "                params = op.get('params', {})\n",
    "                \n",
    "                if op_type == 'normalize':\n",
    "                    processed_audio = processor.normalize(processed_audio, **params)\n",
    "                elif op_type == 'trim_silence':\n",
    "                    processed_audio = processor.trim_silence(processed_audio, **params)\n",
    "                elif op_type == 'noise_reduction':\n",
    "                    processed_audio = processor.apply_noise_reduction(processed_audio, **params)\n",
    "                elif op_type == 'change_speed':\n",
    "                    processed_audio = processor.change_speed(processed_audio, **params)\n",
    "                elif op_type == 'change_pitch':\n",
    "                    processed_audio = processor.change_pitch(\n",
    "                        processed_audio, sample_rate=sample_rate, **params\n",
    "                    )\n",
    "                elif op_type == 'resample':\n",
    "                    target_sr = params.get('target_sr', 16000)\n",
    "                    processed_audio = processor.resample(\n",
    "                        processed_audio, sample_rate, target_sr\n",
    "                    )\n",
    "                    sample_rate = target_sr\n",
    "                \n",
    "                applied_operations.append(op_type)\n",
    "            \n",
    "            job.output_audio = processed_audio\n",
    "            job.metadata['sample_rate'] = sample_rate\n",
    "            job.metadata['duration'] = len(processed_audio) / sample_rate\n",
    "            job.metadata['applied_operations'] = applied_operations\n",
    "            job.status = \"completed\"\n",
    "            job.processing_time = time.time() - start_time\n",
    "            job.completed_at = datetime.now()\n",
    "            \n",
    "            self._update_stats(job, success=True)\n",
    "            \n",
    "        except Exception as e:\n",
    "            job.status = \"failed\"\n",
    "            job.error = str(e)\n",
    "            self._update_stats(job, success=False)\n",
    "        \n",
    "        self.jobs_history.append(job)\n",
    "        return job\n",
    "    \n",
    "    def analyze_audio(self, audio: np.ndarray,\n",
    "                      sample_rate: int) -> AudioJob:\n",
    "        \"\"\"\n",
    "        Analyzuje audio a extrahuje features.\n",
    "        \n",
    "        Args:\n",
    "            audio: Vstupn√≠ audio\n",
    "            sample_rate: Sample rate\n",
    "        \n",
    "        Returns:\n",
    "            AudioJob s anal√Ωzou v metadata\n",
    "        \"\"\"\n",
    "        job = self._create_job(AudioTaskType.ANALYSIS, {\n",
    "            'audio_length': len(audio),\n",
    "            'sample_rate': sample_rate\n",
    "        })\n",
    "        \n",
    "        try:\n",
    "            start_time = time.time()\n",
    "            processor = self.components['processor']\n",
    "            \n",
    "            features = processor.extract_features(audio, sample_rate)\n",
    "            \n",
    "            job.metadata['features'] = features\n",
    "            job.metadata['sample_rate'] = sample_rate\n",
    "            job.status = \"completed\"\n",
    "            job.processing_time = time.time() - start_time\n",
    "            job.completed_at = datetime.now()\n",
    "            \n",
    "            self._update_stats(job, success=True)\n",
    "            \n",
    "        except Exception as e:\n",
    "            job.status = \"failed\"\n",
    "            job.error = str(e)\n",
    "            self._update_stats(job, success=False)\n",
    "        \n",
    "        self.jobs_history.append(job)\n",
    "        return job\n",
    "    \n",
    "    def _create_job(self, task_type: AudioTaskType, \n",
    "                    input_data: Dict) -> AudioJob:\n",
    "        \"\"\"Vytvo≈ô√≠ novou √∫lohu.\"\"\"\n",
    "        job_id = hashlib.md5(\n",
    "            f\"{task_type.value}_{datetime.now().isoformat()}\".encode()\n",
    "        ).hexdigest()[:12]\n",
    "        \n",
    "        return AudioJob(\n",
    "            job_id=job_id,\n",
    "            task_type=task_type,\n",
    "            input_data=input_data\n",
    "        )\n",
    "    \n",
    "    def _update_stats(self, job: AudioJob, success: bool):\n",
    "        \"\"\"Aktualizuje statistiky.\"\"\"\n",
    "        self.stats['total_jobs'] += 1\n",
    "        self.stats['by_type'][job.task_type.value] += 1\n",
    "        \n",
    "        if success:\n",
    "            self.stats['successful_jobs'] += 1\n",
    "            if job.metadata.get('duration'):\n",
    "                self.stats['total_audio_generated_seconds'] += job.metadata['duration']\n",
    "        else:\n",
    "            self.stats['failed_jobs'] += 1\n",
    "    \n",
    "    def get_stats(self) -> Dict:\n",
    "        \"\"\"Vr√°t√≠ statistiky pipeline.\"\"\"\n",
    "        stats = dict(self.stats)\n",
    "        stats['by_type'] = dict(stats['by_type'])\n",
    "        \n",
    "        if stats['total_jobs'] > 0:\n",
    "            stats['success_rate'] = stats['successful_jobs'] / stats['total_jobs']\n",
    "        \n",
    "        return stats\n",
    "    \n",
    "    def get_recent_jobs(self, n: int = 10) -> List[AudioJob]:\n",
    "        \"\"\"Vr√°t√≠ posledn√≠ch N √∫loh.\"\"\"\n",
    "        return self.jobs_history[-n:]\n",
    "    \n",
    "    def play_job_audio(self, job: AudioJob):\n",
    "        \"\"\"P≈ôehraje audio z √∫lohy.\"\"\"\n",
    "        if job.output_audio is not None and job.metadata.get('sample_rate'):\n",
    "            display(Audio(job.output_audio, rate=job.metadata['sample_rate']))\n",
    "        else:\n",
    "            print(\"‚ö†Ô∏è √öloha nem√° v√Ωstupn√≠ audio\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ProductionAudioPipeline p≈ôipraven\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicializace produkƒçn√≠ho pipeline\n",
    "audio_pipeline = ProductionAudioPipeline(\n",
    "    enable_tts=True,\n",
    "    enable_music=True,\n",
    "    cache_size=50\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test TTS\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TEST: Text-to-Speech\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "tts_job = audio_pipeline.text_to_speech(\n",
    "    text=\"Welcome to Praut AI Pipeline. This is a demonstration of our text to speech capabilities.\",\n",
    "    engine=\"speecht5\"\n",
    ")\n",
    "\n",
    "print(f\"\\nüìã Job ID: {tts_job.job_id}\")\n",
    "print(f\"   Status: {tts_job.status}\")\n",
    "print(f\"   D√©lka: {tts_job.metadata.get('duration', 0):.2f}s\")\n",
    "print(f\"   ƒåas zpracov√°n√≠: {tts_job.processing_time:.2f}s\")\n",
    "\n",
    "if tts_job.status == \"completed\":\n",
    "    audio_pipeline.play_job_audio(tts_job)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test audio processingu\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TEST: Audio Processing\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Pou≈æijeme audio z TTS\n",
    "if tts_job.output_audio is not None:\n",
    "    processing_job = audio_pipeline.process_audio(\n",
    "        audio=tts_job.output_audio,\n",
    "        sample_rate=tts_job.metadata['sample_rate'],\n",
    "        operations=[\n",
    "            {\"type\": \"normalize\", \"params\": {\"target_db\": -18}},\n",
    "            {\"type\": \"trim_silence\", \"params\": {\"top_db\": 25}},\n",
    "            {\"type\": \"change_pitch\", \"params\": {\"semitones\": -2}},\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nüìã Job ID: {processing_job.job_id}\")\n",
    "    print(f\"   Status: {processing_job.status}\")\n",
    "    print(f\"   Operace: {processing_job.metadata.get('applied_operations', [])}\")\n",
    "    print(f\"   V√Ωsledn√° d√©lka: {processing_job.metadata.get('duration', 0):.2f}s\")\n",
    "    \n",
    "    if processing_job.status == \"completed\":\n",
    "        print(\"\\nüîä Zpracovan√© audio:\")\n",
    "        audio_pipeline.play_job_audio(processing_job)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test generov√°n√≠ hudby\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TEST: Music Generation\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "music_job = audio_pipeline.generate_music(\n",
    "    prompt=\"Uplifting corporate background music with piano and soft drums\",\n",
    "    duration=5.0\n",
    ")\n",
    "\n",
    "print(f\"\\nüìã Job ID: {music_job.job_id}\")\n",
    "print(f\"   Status: {music_job.status}\")\n",
    "if music_job.status == \"completed\":\n",
    "    print(f\"   D√©lka: {music_job.metadata.get('duration', 0):.2f}s\")\n",
    "    print(f\"   ƒåas zpracov√°n√≠: {music_job.processing_time:.2f}s\")\n",
    "    audio_pipeline.play_job_audio(music_job)\n",
    "else:\n",
    "    print(f\"   Chyba: {music_job.error}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test anal√Ωzy\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TEST: Audio Analysis\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "if tts_job.output_audio is not None:\n",
    "    analysis_job = audio_pipeline.analyze_audio(\n",
    "        audio=tts_job.output_audio,\n",
    "        sample_rate=tts_job.metadata['sample_rate']\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nüìã Job ID: {analysis_job.job_id}\")\n",
    "    print(f\"   Status: {analysis_job.status}\")\n",
    "    \n",
    "    if analysis_job.status == \"completed\":\n",
    "        features = analysis_job.metadata.get('features', {})\n",
    "        print(f\"\\nüìä Extrahovan√© features:\")\n",
    "        print(f\"   Duration: {features.get('duration', 0):.2f}s\")\n",
    "        print(f\"   RMS: {features.get('rms', 0):.4f}\")\n",
    "        print(f\"   Spectral Centroid: {features.get('spectral_centroid_mean', 0):.1f} Hz\")\n",
    "        print(f\"   Zero Crossing Rate: {features.get('zero_crossing_rate', 0):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fin√°ln√≠ statistiky pipeline\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"STATISTIKY PIPELINE\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "stats = audio_pipeline.get_stats()\n",
    "\n",
    "print(f\"\\nüìä Celkov√© statistiky:\")\n",
    "print(f\"   Celkem √∫loh: {stats['total_jobs']}\")\n",
    "print(f\"   √öspƒõ≈°n√Ωch: {stats['successful_jobs']}\")\n",
    "print(f\"   Ne√∫spƒõ≈°n√Ωch: {stats['failed_jobs']}\")\n",
    "print(f\"   Success rate: {stats.get('success_rate', 0):.1%}\")\n",
    "print(f\"   Celkem vygenerov√°no audia: {stats['total_audio_generated_seconds']:.1f}s\")\n",
    "\n",
    "print(f\"\\nüìà Podle typu √∫lohy:\")\n",
    "for task_type, count in stats['by_type'].items():\n",
    "    print(f\"   {task_type}: {count}\")\n",
    "\n",
    "print(f\"\\nüìú Posledn√≠ √∫lohy:\")\n",
    "for job in audio_pipeline.get_recent_jobs(5):\n",
    "    status_icon = \"‚úÖ\" if job.status == \"completed\" else \"‚ùå\"\n",
    "    print(f\"   {status_icon} {job.job_id}: {job.task_type.value} ({job.processing_time:.2f}s)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üéØ Shrnut√≠ S√©rie\n",
    "\n",
    "Gratulujeme! Dokonƒçili jste celou s√©rii **20 notebook≈Ø** o Hugging Face Transformers!\n",
    "\n",
    "### Co jsme se nauƒçili v tomto notebooku\n",
    "\n",
    "| Komponenta | Model | Pou≈æit√≠ |\n",
    "|------------|-------|--------|\n",
    "| **SpeechT5** | microsoft/speecht5_tts | Text-to-Speech synt√©za |\n",
    "| **BARK** | suno/bark-small | TTS s emocemi a efekty |\n",
    "| **MusicGen** | facebook/musicgen-small | Generov√°n√≠ hudby z textu |\n",
    "| **Librosa** | - | Audio processing a anal√Ωza |\n",
    "\n",
    "### P≈ôehled cel√© s√©rie\n",
    "\n",
    "| # | T√©ma | Kl√≠ƒçov√© modely |\n",
    "|---|------|---------------|\n",
    "| 1 | √övod do HF | Pipeline API, AutoModel |\n",
    "| 2 | Klasifikace a NER | BERT, DistilBERT |\n",
    "| 3 | Sentiment a emoce | RoBERTa, GoEmotions |\n",
    "| 4 | Sumarizace a generov√°n√≠ | BART, T5, GPT-2 |\n",
    "| 5 | P≈ôeklad | MarianMT, mBART |\n",
    "| 6 | Question Answering | BERT QA, Retrieval |\n",
    "| 7 | Speech-to-Text | Whisper |\n",
    "| 8-10 | Computer Vision | ViT, DETR, Segmentation |\n",
    "| 11 | Embeddings a Search | Sentence Transformers |\n",
    "| 12 | Fine-tuning | LoRA, PEFT |\n",
    "| 13 | RAG syst√©my | Retrieval + Generation |\n",
    "| 14 | LLM optimalizace | Quantization, vLLM |\n",
    "| 15 | Multimod√°ln√≠ modely | CLIP, LLaVA, BLIP |\n",
    "| 16 | Time Series | Transformer forecasting |\n",
    "| 17 | Doporuƒçovac√≠ syst√©my | Collaborative filtering |\n",
    "| 18 | Detekce anom√°li√≠ | Autoencoder, Isolation Forest |\n",
    "| 19 | Document AI | TrOCR, LayoutLM, Donut |\n",
    "| **20** | **Audio AI** | **SpeechT5, BARK, MusicGen** |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üéâ S√âRIE DOKONƒåENA!\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\nüèÜ Gratulujeme k dokonƒçen√≠ v≈°ech 20 notebook≈Ø!\")\n",
    "print(\"\\nüìö Nauƒçili jste se:\")\n",
    "print(\"   ‚úÖ Text processing (klasifikace, NER, sentiment)\")\n",
    "print(\"   ‚úÖ Generov√°n√≠ textu (sumarizace, p≈ôeklad, QA)\")\n",
    "print(\"   ‚úÖ Computer Vision (klasifikace, detekce, segmentace)\")\n",
    "print(\"   ‚úÖ Speech (STT, TTS, voice cloning)\")\n",
    "print(\"   ‚úÖ Multimod√°ln√≠ AI (CLIP, LLaVA, BLIP)\")\n",
    "print(\"   ‚úÖ Pokroƒçil√© techniky (RAG, fine-tuning, optimalizace)\")\n",
    "print(\"   ‚úÖ Specializovan√© aplikace (time series, recsys, anomaly)\")\n",
    "print(\"   ‚úÖ Document AI (OCR, layout, extrakce)\")\n",
    "print(\"   ‚úÖ Audio AI (TTS, hudba, zpracov√°n√≠)\")\n",
    "print(\"\\nüöÄ Dal≈°√≠ kroky:\")\n",
    "print(\"   ‚Ä¢ Aplikujte nauƒçen√© na vlastn√≠ projekty\")\n",
    "print(\"   ‚Ä¢ Experimentujte s fine-tuningem na vlastn√≠ch datech\")\n",
    "print(\"   ‚Ä¢ Sledujte novinky na Hugging Face Hub\")\n",
    "print(\"   ‚Ä¢ P≈ôispƒõjte do open-source komunity\")\n",
    "print(\"\\nüíº Pro business konzultace: info@praut.cz\")\n",
    "print(\"\\n\" + \"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
