{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Kapitola 23: Train/Test Split - Jak AI zkousime\n",
        "\n",
        "## Proc nemuzeme zkouset AI na datech, na kterych se ucila?\n",
        "\n",
        "Predstavte si studenta, ktery se uci na zkousku. Ma k dispozici 100 otazek s odpoveďmi. Co se stane, kdyz se je **vsechny nauci nazpamet** a pak ho zkousite **ze stejnych otazek**?\n",
        "\n",
        "Bude mit 100% uspesnost! Ale co kdyz mu date **nove otazky**, ktere nikdy nevidel? Mozna se zhroutí...\n",
        "\n",
        "**Presne stejny problem ma AI:**\n",
        "- Pokud trenujeme model na vsech datech\n",
        "- A pak ho testujeme na stejnych datech\n",
        "- Vysledky budou **prilis optimisticke**\n",
        "\n",
        "---\n",
        "\n",
        "### Co se naucime:\n",
        "1. **Train/Test Split** - jak rozdelit data na trenovaci a testovaci\n",
        "2. **Overfitting** - kdy se model \"nauci nazpamet\" misto zobecneni\n",
        "3. **Cross-validation** - robustnejsi zpusob testovani\n",
        "4. **Validation set** - proc potrebujeme i treti sadu dat\n",
        "5. **Prakticke priklady** - jak to vse udelat v Pythonu"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Instalace a import knihoven"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Instalace knihoven (pro Google Colab)\n",
        "!pip install pandas numpy matplotlib seaborn scikit-learn -q\n",
        "\n",
        "print(\"Knihovny nainstalovany!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import knihoven\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
        "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score, mean_squared_error, r2_score\n",
        "from sklearn.datasets import make_classification, load_iris\n",
        "\n",
        "# Nastaveni vizualizaci\n",
        "plt.style.use('seaborn-v0_8-whitegrid')\n",
        "plt.rcParams['figure.figsize'] = (10, 6)\n",
        "np.random.seed(42)  # Pro reprodukovatelnost\n",
        "\n",
        "print(\"Vsechny knihovny uspesne nacteny!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Proc potrebujeme delit data?\n",
        "\n",
        "### Problem: Model, ktery se \"nauci nazpamet\"\n",
        "\n",
        "Ukazeme si na jednoduchern prikladu, co se stane, kdyz model trenujeme a testujeme na stejnych datech."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Vytvorime jednoducha data - predikce ceny domu podle plochy\n",
        "np.random.seed(42)\n",
        "\n",
        "# Plocha domu (m2)\n",
        "plocha = np.random.uniform(50, 200, 50)\n",
        "\n",
        "# Cena = 50000 * plocha + nahodny sum\n",
        "cena = 50000 * plocha + np.random.normal(0, 500000, 50)\n",
        "\n",
        "# DataFrame\n",
        "domy = pd.DataFrame({'plocha_m2': plocha, 'cena_kc': cena})\n",
        "\n",
        "print(\"Nase data o domech:\")\n",
        "print(domy.head(10))\n",
        "\n",
        "# Vizualizace\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.scatter(domy['plocha_m2'], domy['cena_kc']/1000000, c='coral', s=80, alpha=0.7)\n",
        "plt.xlabel('Plocha (m2)')\n",
        "plt.ylabel('Cena (mil. Kc)')\n",
        "plt.title('Vztah mezi plochou a cenou domu')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# SPATNY PRISTUP: Trenujeme a testujeme na stejnych datech\n",
        "print(\"=\" * 60)\n",
        "print(\"SPATNY PRISTUP: Trenovani a testovani na STEJNYCH datech\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "X = domy[['plocha_m2']]\n",
        "y = domy['cena_kc']\n",
        "\n",
        "# Trenujeme model na VSECH datech\n",
        "model = LinearRegression()\n",
        "model.fit(X, y)\n",
        "\n",
        "# Testujeme na STEJNYCH datech\n",
        "predikce = model.predict(X)\n",
        "\n",
        "# Vypocitame chybu (MSE) a R2 skore\n",
        "mse = mean_squared_error(y, predikce)\n",
        "r2 = r2_score(y, predikce)\n",
        "\n",
        "print(f\"\\nVysledky na TRENOVACICH datech:\")\n",
        "print(f\"  R2 skore: {r2:.4f}\")\n",
        "print(f\"  Prumerna chyba: {np.sqrt(mse)/1000:.0f} tis. Kc\")\n",
        "print(\"\\n>>> Pozor! Toto je PRILIS OPTIMISTICKE!\")\n",
        "print(\">>> Model videl vsechna tato data behem uceni.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Train/Test Split - Spravny pristup\n",
        "\n",
        "Rozdelime data na dve casti:\n",
        "- **Trenovaci sada (Train set)** - model se na nich uci\n",
        "- **Testovaci sada (Test set)** - model je nikdy nevidel, pouzijeme pro hodnoceni\n",
        "\n",
        "### Typicke pomery rozdeleni:\n",
        "- **80/20** - 80% trenovaci, 20% testovaci (nejcastejsi)\n",
        "- **70/30** - 70% trenovaci, 30% testovaci\n",
        "- **90/10** - pro velke datasety"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# SPRAVNY PRISTUP: Rozdelime data\n",
        "print(\"=\" * 60)\n",
        "print(\"SPRAVNY PRISTUP: Train/Test Split\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "X = domy[['plocha_m2']]\n",
        "y = domy['cena_kc']\n",
        "\n",
        "# Rozdelime na 80% trenovaci, 20% testovaci\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, \n",
        "    test_size=0.2,      # 20% pro test\n",
        "    random_state=42     # Pro reprodukovatelnost\n",
        ")\n",
        "\n",
        "print(f\"\\nRozdeleni dat:\")\n",
        "print(f\"  Trenovaci sada: {len(X_train)} vzorku ({len(X_train)/len(X)*100:.0f}%)\")\n",
        "print(f\"  Testovaci sada: {len(X_test)} vzorku ({len(X_test)/len(X)*100:.0f}%)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Trenujeme model POUZE na trenovacich datech\n",
        "model = LinearRegression()\n",
        "model.fit(X_train, y_train)  # Ucime se POUZE na train datech\n",
        "\n",
        "# Predikce na TRENOVACICH datech\n",
        "pred_train = model.predict(X_train)\n",
        "r2_train = r2_score(y_train, pred_train)\n",
        "mse_train = mean_squared_error(y_train, pred_train)\n",
        "\n",
        "# Predikce na TESTOVACICH datech (model je nikdy nevidel!)\n",
        "pred_test = model.predict(X_test)\n",
        "r2_test = r2_score(y_test, pred_test)\n",
        "mse_test = mean_squared_error(y_test, pred_test)\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"POROVNANI VYSLEDKU\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"\\nVysledky na TRENOVACICH datech:\")\n",
        "print(f\"  R2 skore: {r2_train:.4f}\")\n",
        "print(f\"  Prumerna chyba: {np.sqrt(mse_train)/1000:.0f} tis. Kc\")\n",
        "\n",
        "print(f\"\\nVysledky na TESTOVACICH datech (NEVIDENA DATA):\")\n",
        "print(f\"  R2 skore: {r2_test:.4f}\")\n",
        "print(f\"  Prumerna chyba: {np.sqrt(mse_test)/1000:.0f} tis. Kc\")\n",
        "\n",
        "print(\"\\n>>> Testovaci skore je REALISTICKE - ukazuje, jak model funguje\")\n",
        "print(\">>> na datech, ktere nikdy nevidel!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Vizualizace rozdeleni\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "# Levy graf - rozdeleni dat\n",
        "axes[0].scatter(X_train, y_train/1000000, c='blue', s=80, alpha=0.7, label=f'Train ({len(X_train)})')\n",
        "axes[0].scatter(X_test, y_test/1000000, c='red', s=80, alpha=0.7, label=f'Test ({len(X_test)})')\n",
        "\n",
        "# Pridame regresni primku\n",
        "x_line = np.linspace(X['plocha_m2'].min(), X['plocha_m2'].max(), 100).reshape(-1, 1)\n",
        "y_line = model.predict(x_line)\n",
        "axes[0].plot(x_line, y_line/1000000, 'g--', linewidth=2, label='Model')\n",
        "\n",
        "axes[0].set_xlabel('Plocha (m2)')\n",
        "axes[0].set_ylabel('Cena (mil. Kc)')\n",
        "axes[0].set_title('Train/Test Split vizualizace')\n",
        "axes[0].legend()\n",
        "\n",
        "# Pravy graf - porovnani skore\n",
        "kategorie = ['Train skore', 'Test skore']\n",
        "skore = [r2_train, r2_test]\n",
        "barvy = ['blue', 'red']\n",
        "bars = axes[1].bar(kategorie, skore, color=barvy, alpha=0.7, edgecolor='black')\n",
        "axes[1].set_ylabel('R2 Skore')\n",
        "axes[1].set_title('Porovnani Train vs Test skore')\n",
        "axes[1].set_ylim(0, 1)\n",
        "\n",
        "# Pridame hodnoty na sloupce\n",
        "for bar, s in zip(bars, skore):\n",
        "    axes[1].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.02, \n",
        "                 f'{s:.3f}', ha='center', fontsize=12)\n",
        "\n",
        "plt.suptitle('Spravny pristup: Trenuj na train, testuj na test', fontsize=14, fontweight='bold')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Overfitting - Kdyz se model \"nauci nazpamet\"\n",
        "\n",
        "**Overfitting** nastava, kdyz model:\n",
        "- Ma VYBORNE vysledky na trenovacich datech\n",
        "- Ma SPATNE vysledky na testovacich datech\n",
        "\n",
        "To znamena, ze model se \"naucil nazpamet\" trenovaci data, misto aby pochopil obecne vzory.\n",
        "\n",
        "### Vizualni ukazka: KNN s ruznymi hodnotami K"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Vytvorime klasifikacni ulohu\n",
        "from sklearn.datasets import make_moons\n",
        "\n",
        "# Vytvorime \"mesicovita\" data\n",
        "X, y = make_moons(n_samples=200, noise=0.3, random_state=42)\n",
        "\n",
        "# Rozdelime data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "print(f\"Trenovaci data: {len(X_train)} vzorku\")\n",
        "print(f\"Testovaci data: {len(X_test)} vzorku\")\n",
        "\n",
        "# Vizualizace\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.scatter(X_train[:, 0], X_train[:, 1], c=y_train, cmap='coolwarm', s=60, alpha=0.7, label='Train')\n",
        "plt.scatter(X_test[:, 0], X_test[:, 1], c=y_test, cmap='coolwarm', s=60, alpha=0.7, marker='s', label='Test')\n",
        "plt.xlabel('Feature 1')\n",
        "plt.ylabel('Feature 2')\n",
        "plt.title('Klasifikacni uloha - \"Mesice\"')\n",
        "plt.colorbar(label='Trida')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Porovname KNN s ruznymi hodnotami K\n",
        "print(\"=\" * 60)\n",
        "print(\"VLIV PARAMETRU K NA OVERFITTING\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "hodnoty_k = [1, 3, 5, 10, 20, 50]\n",
        "train_scores = []\n",
        "test_scores = []\n",
        "\n",
        "for k in hodnoty_k:\n",
        "    knn = KNeighborsClassifier(n_neighbors=k)\n",
        "    knn.fit(X_train, y_train)\n",
        "    \n",
        "    train_acc = accuracy_score(y_train, knn.predict(X_train))\n",
        "    test_acc = accuracy_score(y_test, knn.predict(X_test))\n",
        "    \n",
        "    train_scores.append(train_acc)\n",
        "    test_scores.append(test_acc)\n",
        "    \n",
        "    status = \"\"\n",
        "    if train_acc > test_acc + 0.1:\n",
        "        status = \"OVERFITTING!\"\n",
        "    elif test_acc > train_acc:\n",
        "        status = \"OK\"\n",
        "    else:\n",
        "        status = \"Dobry model\"\n",
        "    \n",
        "    print(f\"K={k:2d}: Train={train_acc:.3f}, Test={test_acc:.3f} --> {status}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Vizualizace overfitting vs underfitting\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "# Graf 1: Train vs Test skore\n",
        "axes[0].plot(hodnoty_k, train_scores, 'b-o', linewidth=2, markersize=8, label='Train skore')\n",
        "axes[0].plot(hodnoty_k, test_scores, 'r-s', linewidth=2, markersize=8, label='Test skore')\n",
        "axes[0].fill_between(hodnoty_k, train_scores, test_scores, alpha=0.2, color='purple')\n",
        "axes[0].set_xlabel('Hodnota K (pocet sousedu)')\n",
        "axes[0].set_ylabel('Presnost (Accuracy)')\n",
        "axes[0].set_title('Overfitting: Kdyz je Train >> Test')\n",
        "axes[0].legend()\n",
        "axes[0].axvline(x=5, color='green', linestyle='--', label='Optimalni K')\n",
        "\n",
        "# Anotace\n",
        "axes[0].annotate('OVERFITTING\\n(prilis slozity)', xy=(1, 0.95), fontsize=10, color='red')\n",
        "axes[0].annotate('UNDERFITTING\\n(prilis jednoduchy)', xy=(40, 0.75), fontsize=10, color='orange')\n",
        "\n",
        "# Graf 2: Rozdil mezi train a test\n",
        "rozdil = np.array(train_scores) - np.array(test_scores)\n",
        "barvy = ['red' if r > 0.05 else 'green' for r in rozdil]\n",
        "bars = axes[1].bar(range(len(hodnoty_k)), rozdil, color=barvy, alpha=0.7, edgecolor='black')\n",
        "axes[1].set_xticks(range(len(hodnoty_k)))\n",
        "axes[1].set_xticklabels([f'K={k}' for k in hodnoty_k])\n",
        "axes[1].set_ylabel('Train - Test skore')\n",
        "axes[1].set_title('Rozdil mezi Train a Test (mensi = lepsi)')\n",
        "axes[1].axhline(y=0.05, color='orange', linestyle='--', label='Hranice overfittingu')\n",
        "axes[1].legend()\n",
        "\n",
        "plt.suptitle('Jak poznat overfitting', fontsize=14, fontweight='bold')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Cross-Validation - Robustnejsi testovani\n",
        "\n",
        "**Problem s jednim rozdelenim:** Vysledky zavisi na tom, JAKE data jsou v train a test sade.\n",
        "\n",
        "**Reseni: K-Fold Cross-Validation**\n",
        "1. Rozdelime data na K casti (folds)\n",
        "2. Trenujeme K-krat, pokazde jinak\n",
        "3. Prumerujeme vysledky\n",
        "\n",
        "```\n",
        "5-Fold Cross-Validation:\n",
        "Fold 1: [TEST] [train] [train] [train] [train]\n",
        "Fold 2: [train] [TEST] [train] [train] [train]\n",
        "Fold 3: [train] [train] [TEST] [train] [train]\n",
        "Fold 4: [train] [train] [train] [TEST] [train]\n",
        "Fold 5: [train] [train] [train] [train] [TEST]\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Vizualizace K-Fold Cross-Validation\n",
        "print(\"=\" * 60)\n",
        "print(\"K-FOLD CROSS-VALIDATION VIZUALIZACE\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Vytvorime KFold objekt\n",
        "kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "fig, axes = plt.subplots(5, 1, figsize=(12, 6))\n",
        "\n",
        "for fold, (train_idx, test_idx) in enumerate(kfold.split(X)):\n",
        "    # Vytvorime vizualizaci pro kazdy fold\n",
        "    colors = ['lightblue'] * len(X)\n",
        "    for idx in test_idx:\n",
        "        colors[idx] = 'coral'\n",
        "    \n",
        "    axes[fold].bar(range(len(X)), [1]*len(X), color=colors, edgecolor='black', linewidth=0.5)\n",
        "    axes[fold].set_ylabel(f'Fold {fold+1}')\n",
        "    axes[fold].set_yticks([])\n",
        "    axes[fold].set_xlim(-1, len(X))\n",
        "    \n",
        "    # Anotace\n",
        "    train_pct = len(train_idx)/len(X)*100\n",
        "    test_pct = len(test_idx)/len(X)*100\n",
        "    axes[fold].text(len(X)+5, 0.5, f'Train: {train_pct:.0f}%, Test: {test_pct:.0f}%', \n",
        "                    fontsize=10, va='center')\n",
        "\n",
        "axes[0].set_title('5-Fold Cross-Validation: Modra=Train, Oranzova=Test')\n",
        "axes[-1].set_xlabel('Vzorky v datasetu')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Prakticky priklad cross-validation\n",
        "print(\"=\" * 60)\n",
        "print(\"PRAKTICKA CROSS-VALIDATION\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Pouzijeme Iris dataset\n",
        "iris = load_iris()\n",
        "X_iris = iris.data\n",
        "y_iris = iris.target\n",
        "\n",
        "print(f\"\\nIris dataset: {len(X_iris)} vzorku, {X_iris.shape[1]} priznaku\")\n",
        "\n",
        "# Vytvorime model\n",
        "model = KNeighborsClassifier(n_neighbors=5)\n",
        "\n",
        "# Spustime 5-fold cross-validation\n",
        "cv_scores = cross_val_score(model, X_iris, y_iris, cv=5)\n",
        "\n",
        "print(f\"\\nVysledky 5-fold cross-validation:\")\n",
        "for i, score in enumerate(cv_scores, 1):\n",
        "    print(f\"  Fold {i}: {score:.4f}\")\n",
        "\n",
        "print(f\"\\n\" + \"=\"*40)\n",
        "print(f\"Prumerne skore: {cv_scores.mean():.4f} (+/- {cv_scores.std()*2:.4f})\")\n",
        "print(\"=\"*40)\n",
        "print(\"\\n+/- ukazuje rozptyl - mensi = stabilnejsi model\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Porovnani ruznych hodnot K pomoci cross-validation\n",
        "print(\"=\" * 60)\n",
        "print(\"HLEDANI OPTIMALNIHO K POMOCI CROSS-VALIDATION\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "hodnoty_k = range(1, 31)\n",
        "cv_prumery = []\n",
        "cv_odchylky = []\n",
        "\n",
        "for k in hodnoty_k:\n",
        "    knn = KNeighborsClassifier(n_neighbors=k)\n",
        "    scores = cross_val_score(knn, X_iris, y_iris, cv=5)\n",
        "    cv_prumery.append(scores.mean())\n",
        "    cv_odchylky.append(scores.std())\n",
        "\n",
        "# Najdeme nejlepsi K\n",
        "nejlepsi_k = hodnoty_k[np.argmax(cv_prumery)]\n",
        "nejlepsi_skore = max(cv_prumery)\n",
        "\n",
        "print(f\"\\nNejlepsi K: {nejlepsi_k}\")\n",
        "print(f\"Nejlepsi prumerne skore: {nejlepsi_skore:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Vizualizace hledani optimalniho K\n",
        "plt.figure(figsize=(12, 6))\n",
        "\n",
        "plt.plot(hodnoty_k, cv_prumery, 'b-o', linewidth=2, markersize=6, label='Prumerne CV skore')\n",
        "plt.fill_between(hodnoty_k, \n",
        "                 np.array(cv_prumery) - np.array(cv_odchylky),\n",
        "                 np.array(cv_prumery) + np.array(cv_odchylky),\n",
        "                 alpha=0.2, color='blue', label='Smerodatna odchylka')\n",
        "\n",
        "# Oznacime nejlepsi K\n",
        "plt.axvline(x=nejlepsi_k, color='green', linestyle='--', linewidth=2, \n",
        "            label=f'Nejlepsi K={nejlepsi_k}')\n",
        "plt.scatter([nejlepsi_k], [nejlepsi_skore], c='green', s=200, zorder=5, marker='*')\n",
        "\n",
        "plt.xlabel('Hodnota K (pocet sousedu)')\n",
        "plt.ylabel('Prumerne CV skore')\n",
        "plt.title('Hledani optimalniho K pomoci 5-Fold Cross-Validation')\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "# Anotace oblasti\n",
        "plt.annotate('Overfitting\\n(K prilis male)', xy=(2, 0.95), fontsize=10, color='red')\n",
        "plt.annotate('Underfitting\\n(K prilis velke)', xy=(25, 0.93), fontsize=10, color='orange')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Train / Validation / Test Split\n",
        "\n",
        "Kdyz ladime hyperparametry (jako hodnotu K), potrebujeme **tri sady**:\n",
        "\n",
        "| Sada | Ucel | Procento |\n",
        "|------|------|----------|\n",
        "| **Train** | Uceni modelu | 60% |\n",
        "| **Validation** | Ladeni hyperparametru | 20% |\n",
        "| **Test** | Finalni hodnoceni | 20% |\n",
        "\n",
        "### Proc?\n",
        "- Pokud bychom ladili hyperparametry na test sade, mohli bychom \"prekrmit\" model na test data\n",
        "- Test sada musi zustat nedotcena az do finalniho hodnoceni"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train / Validation / Test Split\n",
        "print(\"=\" * 60)\n",
        "print(\"TRAIN / VALIDATION / TEST SPLIT\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Nejprve rozdelime na train+val a test\n",
        "X_temp, X_test, y_temp, y_test = train_test_split(\n",
        "    X_iris, y_iris, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# Pak rozdelime train+val na train a validation\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X_temp, y_temp, test_size=0.25, random_state=42  # 0.25 * 0.8 = 0.2\n",
        ")\n",
        "\n",
        "print(f\"\\nRozdeleni dat:\")\n",
        "print(f\"  Train:      {len(X_train)} vzorku ({len(X_train)/len(X_iris)*100:.0f}%)\")\n",
        "print(f\"  Validation: {len(X_val)} vzorku ({len(X_val)/len(X_iris)*100:.0f}%)\")\n",
        "print(f\"  Test:       {len(X_test)} vzorku ({len(X_test)/len(X_iris)*100:.0f}%)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Proces ladeni hyperparametru\n",
        "print(\"=\" * 60)\n",
        "print(\"LADENI HYPERPARAMETRU NA VALIDATION SADE\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "nejlepsi_k = None\n",
        "nejlepsi_val_skore = 0\n",
        "\n",
        "print(\"\\nHledame nejlepsi K:\")\n",
        "for k in range(1, 21):\n",
        "    knn = KNeighborsClassifier(n_neighbors=k)\n",
        "    knn.fit(X_train, y_train)  # Trenujeme na TRAIN\n",
        "    \n",
        "    val_skore = accuracy_score(y_val, knn.predict(X_val))  # Hodnotime na VALIDATION\n",
        "    \n",
        "    if val_skore > nejlepsi_val_skore:\n",
        "        nejlepsi_val_skore = val_skore\n",
        "        nejlepsi_k = k\n",
        "        print(f\"  K={k}: Validation skore = {val_skore:.4f} <-- NOVE NEJLEPSI!\")\n",
        "\n",
        "print(f\"\\nNejlepsi K: {nejlepsi_k}\")\n",
        "print(f\"Nejlepsi validation skore: {nejlepsi_val_skore:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Finalni hodnoceni na TEST sade\n",
        "print(\"=\" * 60)\n",
        "print(\"FINALNI HODNOCENI NA TEST SADE\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Trenujeme finalni model na TRAIN + VALIDATION\n",
        "X_train_final = np.vstack([X_train, X_val])\n",
        "y_train_final = np.hstack([y_train, y_val])\n",
        "\n",
        "finalni_model = KNeighborsClassifier(n_neighbors=nejlepsi_k)\n",
        "finalni_model.fit(X_train_final, y_train_final)\n",
        "\n",
        "# Hodnotime na TEST (model tato data NIKDY nevidel)\n",
        "test_skore = accuracy_score(y_test, finalni_model.predict(X_test))\n",
        "\n",
        "print(f\"\\nFinalni model: KNN s K={nejlepsi_k}\")\n",
        "print(f\"Validation skore: {nejlepsi_val_skore:.4f}\")\n",
        "print(f\"TEST SKORE: {test_skore:.4f}\")\n",
        "print(\"\\n>>> Test skore je nejrealistictejsi odhad vykonnosti modelu!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Shruti a kontrolni otazky\n",
        "\n",
        "### Co jsme se naucili:\n",
        "\n",
        "| Koncept | Popis |\n",
        "|---------|-------|\n",
        "| **Train/Test Split** | Rozdeleni dat na trenovaci a testovaci |\n",
        "| **Overfitting** | Model se nauci data nazpamet, nezobecnuje |\n",
        "| **Cross-Validation** | Opakované testovani pro robustni vysledky |\n",
        "| **Validation Set** | Pro ladeni hyperparametru |\n",
        "\n",
        "### Kontrolni otazky:\n",
        "\n",
        "1. **Proc nemuzeme trenovat a testovat na stejnych datech?**\n",
        "2. **Jak poznate overfitting z grafu Train vs Test skore?**\n",
        "3. **Kolik foldu je typicke pro cross-validation?**\n",
        "4. **Proc potrebujeme validation sadu krome test sady?**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Shrnujici vizualizace\n",
        "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
        "\n",
        "# 1. Train/Test Split\n",
        "sizes1 = [80, 20]\n",
        "labels1 = ['Train (80%)', 'Test (20%)']\n",
        "colors1 = ['lightblue', 'coral']\n",
        "axes[0].pie(sizes1, labels=labels1, colors=colors1, autopct='%1.0f%%', startangle=90)\n",
        "axes[0].set_title('1. Train/Test Split')\n",
        "\n",
        "# 2. Cross-Validation\n",
        "folds = 5\n",
        "for i in range(folds):\n",
        "    y_pos = i * 0.15\n",
        "    for j in range(folds):\n",
        "        color = 'coral' if j == i else 'lightblue'\n",
        "        axes[1].add_patch(plt.Rectangle((j*0.18, y_pos), 0.16, 0.12, \n",
        "                                        facecolor=color, edgecolor='black'))\n",
        "axes[1].set_xlim(-0.05, 1)\n",
        "axes[1].set_ylim(-0.05, 0.85)\n",
        "axes[1].set_aspect('equal')\n",
        "axes[1].axis('off')\n",
        "axes[1].set_title('2. K-Fold Cross-Validation')\n",
        "\n",
        "# 3. Train/Val/Test\n",
        "sizes3 = [60, 20, 20]\n",
        "labels3 = ['Train (60%)', 'Validation (20%)', 'Test (20%)']\n",
        "colors3 = ['lightblue', 'lightgreen', 'coral']\n",
        "axes[2].pie(sizes3, labels=labels3, colors=colors3, autopct='%1.0f%%', startangle=90)\n",
        "axes[2].set_title('3. Train/Val/Test Split')\n",
        "\n",
        "plt.suptitle('Metody rozdeleni dat pro ML', fontsize=14, fontweight='bold')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test vasich znalosti\n",
        "print(\"=\" * 60)\n",
        "print(\"KVIZ: TEST VASICH ZNALOSTI\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "otazky = [\n",
        "    {\n",
        "        \"otazka\": \"Proc delime data na train a test?\",\n",
        "        \"moznosti\": [\"A) Aby trenovani bylo rychlejsi\", \n",
        "                     \"B) Abychom zjistili, jak model funguje na novych datech\", \n",
        "                     \"C) Protoze nemame dost pameti\"],\n",
        "        \"spravne\": \"B\"\n",
        "    },\n",
        "    {\n",
        "        \"otazka\": \"Co je overfitting?\",\n",
        "        \"moznosti\": [\"A) Model ma spatne vysledky vsude\", \n",
        "                     \"B) Model funguje skvele na train, ale spatne na test\", \n",
        "                     \"C) Model se trénuje prilis pomalu\"],\n",
        "        \"spravne\": \"B\"\n",
        "    },\n",
        "    {\n",
        "        \"otazka\": \"K cemu slouzi cross-validation?\",\n",
        "        \"moznosti\": [\"A) K rychlejsimu trenovani\", \n",
        "                     \"B) K ziskani robustnejsiho odhadu vykonnosti\", \n",
        "                     \"C) K vizualizaci dat\"],\n",
        "        \"spravne\": \"B\"\n",
        "    }\n",
        "]\n",
        "\n",
        "for i, q in enumerate(otazky, 1):\n",
        "    print(f\"\\nOtazka {i}: {q['otazka']}\")\n",
        "    for m in q['moznosti']:\n",
        "        print(f\"  {m}\")\n",
        "    print(f\"  --> Spravna odpoved: {q['spravne']}\")\n",
        "\n",
        "print(f\"\\n\" + \"=\"*40)\n",
        "print(\"Vsechny odpovedi byly B - vzory v odpovídání jsou ale nebezpecne!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Vase vyzva\n",
        "\n",
        "Zkuste nasledujici experimenty:\n",
        "\n",
        "1. **Zmente pomer rozdeleni** - zkuste 70/30, 90/10 a sledujte, jak se meni vysledky\n",
        "2. **Pouzijte jiny model** - nahradte KNN za LogisticRegression\n",
        "3. **Experimentujte s poctem foldu** - zkuste 3-fold, 10-fold cross-validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Vas prostor pro experimentovani\n",
        "# -----------------------------\n",
        "\n",
        "# Tip 1: Zmente test_size\n",
        "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
        "\n",
        "# Tip 2: Zmente pocet foldu\n",
        "# cv_scores = cross_val_score(model, X, y, cv=10)  # 10-fold\n",
        "\n",
        "# Tip 3: Pouzijte jiny model\n",
        "# from sklearn.ensemble import RandomForestClassifier\n",
        "# model = RandomForestClassifier()\n",
        "\n",
        "print(\"Experimentujte s kodem vyse!\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
